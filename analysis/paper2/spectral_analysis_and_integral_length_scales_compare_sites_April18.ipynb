{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "from sublimpy import utils\n",
    "import glob\n",
    "import pytz\n",
    "import re\n",
    "from scipy.signal import welch, csd\n",
    "from scipy.stats import chi2\n",
    "from process_fast_data.fast_data_calculate_spectra_nomrd import calculate_mrd_for_df, fast_data_files_to_dataframe\n",
    "from sublimpy import extrautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"/storage/elilouis/sublimationofsnow/\"\n",
    "DATA_DIR = \"/storage/elilouis/sublimationofsnow/\"\n",
    "\n",
    "# DATES = pd.Series(['20230418', '20230419'])\n",
    "# DATE_LOCAL = '20230418'\n",
    "\n",
    "DATES = pd.Series(['20230409', '20230410'])\n",
    "DATE_LOCAL = '20230409'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAIL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastData(object):\n",
    "    data = None\n",
    "\n",
    "class FastDataSAIL(FastData):\n",
    "    @staticmethod\n",
    "    def open_raw(files):\n",
    "        files = sorted(files)\n",
    "        high_rate_dfs = []\n",
    "        for file in files:\n",
    "            # Regular expression. extract date\n",
    "            date = re.search(r\"gucecorM1\\.00\\.(\\d+)\\.\", file).group(1)\n",
    "            print(file)\n",
    "            df = pd.read_csv(file, skiprows=1, header=None).rename(\n",
    "                    columns = dict(\n",
    "                        zip(range(0,10), \n",
    "                        [\n",
    "                            'Timestamp',\n",
    "                            'u',\n",
    "                            'v',\n",
    "                            'w',\n",
    "                            'windspeed units (M = m/s)',\n",
    "                            'Speed of Sound',\n",
    "                            'Status (00 means okay)',\n",
    "                            'CO2 analog voltage output',\n",
    "                            'H20 analog voltage output',\n",
    "                            'Checksum',\n",
    "                        ])\n",
    "                    )\n",
    "                )\n",
    "            df['time'] = pd.to_datetime(\n",
    "                f'{date} ' + df['Timestamp'].str[:-3],\n",
    "                format=\"%Y%m%d %H:%M:%S.%f\"\n",
    "            )\n",
    "            high_rate_dfs.append(df)\n",
    "        return pd.concat(high_rate_dfs).set_index('time')\n",
    "    \n",
    "    @staticmethod\n",
    "    def double_rotation(df, u_col, v_col, w_col):\n",
    "        # FIRST ROTATION\n",
    "        mean_u = df[u_col].mean()\n",
    "        mean_v = df[v_col].mean()\n",
    "        theta = np.arctan2(mean_v, mean_u)\n",
    "        adj_u = df[u_col]*np.cos(theta) + df[v_col]*np.sin(theta)\n",
    "        adj_v = -df[u_col]*np.sin(theta) + df[v_col]*np.cos(theta)\n",
    "        df[u_col] = adj_u\n",
    "        df[v_col] = adj_v\n",
    "        print(\n",
    "            'Means after 1st rotation:',\n",
    "            df[u_col].mean(),\n",
    "            df[v_col].mean(),\n",
    "            df[w_col].mean(),\n",
    "        )\n",
    "\n",
    "        # SECOND ROTATION\n",
    "        mean_u = df[u_col].mean()\n",
    "        mean_w = df[w_col].mean()\n",
    "        phi = np.arctan2(mean_w, mean_u)\n",
    "        adj_u = df[u_col]*np.cos(phi) + df[w_col]*np.sin(phi)\n",
    "        adj_w = - df[u_col]*np.sin(phi) + df[w_col]*np.cos(phi)\n",
    "        df[u_col] = adj_u\n",
    "        df[w_col] = adj_w\n",
    "        print(\n",
    "            'Means after 2nd rotation:',\n",
    "            df[u_col].mean(),\n",
    "            df[v_col].mean(),\n",
    "            df[w_col].mean(),\n",
    "        )\n",
    "        return df\n",
    "    \n",
    "    def apply_direction_rotation(df, u_col, v_col, w_col, bearing):\n",
    "        # + Ugeo represents wind blowing to the East (confusingly known as a \"westerly\"). \n",
    "        # + Vgeo is wind to the North (a \"southerly\" ). This is right handed with respect to an upward +Wgeo.\n",
    "\n",
    "\n",
    "        # FIRST ROTATION\n",
    "        mean_u = df[u_col].mean()\n",
    "        mean_v = df[v_col].mean()\n",
    "        theta = np.arctan2(mean_v, mean_u)\n",
    "        adj_u = df[u_col]*np.cos(theta) + df[v_col]*np.sin(theta)\n",
    "        adj_v = -df[u_col]*np.sin(theta) + df[v_col]*np.cos(theta)\n",
    "        df[u_col] = adj_u\n",
    "        df[v_col] = adj_v\n",
    "        print(\n",
    "            'Means after 1st rotation:',\n",
    "            df[u_col].mean(),\n",
    "            df[v_col].mean(),\n",
    "            df[w_col].mean(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAIL EC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and wrangle the raw SAIL EC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 559M\n",
      "drwxr-xr-x.  7 elilouis elilouis 4.0K Jun  2 11:18 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxrwxr-x. 54 elilouis elilouis 4.0K Jun 18 12:26 \u001b[01;34m..\u001b[0m/\n",
      "-rw-r--r--.  1 elilouis elilouis  11K Jun 12 11:54 .DS_Store\n",
      "drwx------.  2 elilouis elilouis  12K Mar 11  2025 \u001b[01;34mgucecorM1.00.20230415.000000.raw\u001b[0m/\n",
      "-rw-r--r--.  1 elilouis elilouis 113M Mar 10  2025 gucecorM1.00.20230415.000000.raw.tar\n",
      "drwx------.  2 elilouis elilouis  12K Jun  2 11:18 \u001b[01;34mgucecorM1.00.20230416.000000.raw\u001b[0m/\n",
      "-rw-r--r--.  1 elilouis elilouis 113M Mar 10  2025 gucecorM1.00.20230416.000000.raw.tar\n",
      "drwx------.  2 elilouis elilouis  12K Jun  2 11:18 \u001b[01;34mgucecorM1.00.20230417.000000.raw\u001b[0m/\n",
      "-rw-r--r--.  1 elilouis elilouis 111M Mar 10  2025 gucecorM1.00.20230417.000000.raw.tar\n",
      "drwx------.  2 elilouis elilouis  12K Mar 11  2025 \u001b[01;34mgucecorM1.00.20230418.000000.raw\u001b[0m/\n",
      "-rw-r--r--.  1 elilouis elilouis 112M Mar 10  2025 gucecorM1.00.20230418.000000.raw.tar\n",
      "drwx------.  2 elilouis elilouis  12K Jun  2 11:18 \u001b[01;34mgucecorM1.00.20230419.000000.raw\u001b[0m/\n",
      "-rw-r--r--.  1 elilouis elilouis 113M Mar 10  2025 gucecorM1.00.20230419.000000.raw.tar\n"
     ]
    }
   ],
   "source": [
    "ls -lah /storage/elilouis/sublimationofsnow/sail_fast_ecor_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdate\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'date' is not defined"
     ]
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_data_files = DATES.apply(\n",
    "    lambda date: glob.glob(\n",
    "            os.path.join(\n",
    "                DATA_DIR, \n",
    "                f\"sail_fast_ecor_data/gucecorM1.00.{date}.000000.raw/**_sonic.raw\"\n",
    "            )\n",
    "        )\n",
    ").explode()\n",
    "fast_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fast_df_sail \u001b[38;5;241m=\u001b[39m \u001b[43mFastDataSAIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfast_data_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m fast_df_sail \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mmodify_df_timezone(fast_df_sail\u001b[38;5;241m.\u001b[39mreset_index(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS/Mountain\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m fast_df_sail \u001b[38;5;241m=\u001b[39m fast_df_sail\u001b[38;5;241m.\u001b[39mloc[DATE_LOCAL]\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mFastDataSAIL.open_raw\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m      8\u001b[0m high_rate_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Regular expression. extract date\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     date \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgucecorM1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.00\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.(\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[1;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mrename(\n\u001b[1;32m     14\u001b[0m             columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m             )\n\u001b[1;32m     29\u001b[0m         )\n",
      "File \u001b[0;32m~/mambaforge/envs/sublimationofsnow/lib/python3.12/re/__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'float'"
     ]
    }
   ],
   "source": [
    "fast_df_sail = FastDataSAIL.open_raw(fast_data_files)\n",
    "fast_df_sail = utils.modify_df_timezone(fast_df_sail.reset_index(), 'UTC', 'US/Mountain').set_index('time')\n",
    "fast_df_sail = fast_df_sail.loc[DATE_LOCAL]\n",
    "fast_df_sail = fast_df_sail.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sail[['u','v','w']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 30-minute mean u, v, w, and 30-min wind direction, plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sail = fast_df_sail.join(\n",
    "    fast_df_sail.groupby(pd.Grouper(freq='30min'))[['u', 'v', 'w']].transform('mean').rename(columns = {\n",
    "        'u': 'u_30min',\n",
    "        'v': 'v_30min',\n",
    "        'w': 'w_30min',\n",
    "    })\n",
    ")\n",
    "fast_df_sail = fast_df_sail.join(\n",
    "    fast_df_sail.groupby(pd.Grouper(freq='1min'))[['u', 'v', 'w']].transform('mean').rename(columns = {\n",
    "        'u': 'u_1min',\n",
    "        'v': 'v_1min',\n",
    "        'w': 'w_1min',\n",
    "    })\n",
    ")\n",
    "fast_df_sail['dir_30min'] = np.rad2deg(np.arctan2(-fast_df_sail['u_30min'], -fast_df_sail['v_30min']))\n",
    "fast_df_sail['dir_30min'] = fast_df_sail['dir_30min'].apply(lambda dir: dir if dir >= 0 else dir+360)\n",
    "\n",
    "fast_df_sail['dir_1min'] = np.rad2deg(np.arctan2(-fast_df_sail['u_1min'], -fast_df_sail['v_1min']))\n",
    "fast_df_sail['dir_1min'] = fast_df_sail['dir_1min'].apply(lambda dir: dir if dir >= 0 else dir+360)\n",
    "\n",
    "fig, axes = plt.subplots(2,1)\n",
    "fast_df_sail['dir_30min'].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[0], sharex=True)\n",
    "fast_df_sail['dir_1min'].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[0], sharex=True)\n",
    "fast_df_sail[['u_30min','v_30min','w_30min']].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[1])\n",
    "fast_df_sail[['u_1min','v_1min','w_1min']].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[1])\n",
    "axes[0].grid(axis='x')  # Add grid lines only for the x-axis\n",
    "axes[1].grid(axis='x')  # Add grid lines only for the x-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply double rotation to 30min chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_df_sail = fast_df_sail.groupby(pd.Grouper(freq='30min')).apply(lambda df: FastDataSAIL.double_rotation(df, 'u', 'v', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sail.index = fast_df_sail.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sail['u'] = fast_df_sail['u'].interpolate()\n",
    "fast_df_sail['v'] = fast_df_sail['v'].interpolate()\n",
    "fast_df_sail['w'] = fast_df_sail['w'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mrd_uw_sail = fast_df_sail.groupby(pd.Grouper(freq='180min'))[['u', 'v', 'w']].apply(\n",
    "#     lambda df: calculate_mrd_for_df(df.reset_index(), 'u', 'w', shift=2000, parallelism=20).assign(hour_group = f\"{df.index.min()} - {df.index.max()}\")\n",
    "# )\n",
    "\n",
    "mrd_uw_sail = calculate_mrd_for_df(\n",
    "    fast_df_sail[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations,\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_vw_sail = calculate_mrd_for_df(\n",
    "    fast_df_sail[['u', 'v', 'w']].reset_index(), \n",
    "    'v', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uv_sail = calculate_mrd_for_df(\n",
    "    fast_df_sail[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'v', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uu_sail = calculate_mrd_for_df(\n",
    "    fast_df_sail[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'u', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    ")\n",
    "mrd_vv_sail = calculate_mrd_for_df(\n",
    "    fast_df_sail[['u', 'v', 'w']].reset_index(), \n",
    "    'v', 'v', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    ")\n",
    "mrd_ww_sail = calculate_mrd_for_df(\n",
    "    fast_df_sail[['u', 'v', 'w']].reset_index(), \n",
    "    'w', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLASH EC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splash_files = np.array([\n",
    "    [f for f in glob.glob(\n",
    "        os.path.join(DATA_DIR, \"asfs/ASFS-50_Level2_SPLASH2021-2023/sledwind10hz.asfs50.level2.0.*.nc\")\n",
    "    ) if d in f]\n",
    "    for d in DATES\n",
    "]).flatten()\n",
    "fast_df_splash = xr.open_mfdataset(splash_files).to_dataframe().rename(columns={\n",
    "    'metek_u': 'u',\n",
    "    'metek_v': 'v',\n",
    "    'metek_w': 'w',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_splash = utils.modify_df_timezone(fast_df_splash.reset_index(), 'UTC', 'US/Mountain').set_index('time')\n",
    "fast_df_splash = fast_df_splash.loc[DATE_LOCAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_splash = fast_df_splash.join(\n",
    "    fast_df_splash.groupby(pd.Grouper(freq='30min'))[['u', 'v', 'w']].transform('mean').rename(columns = {\n",
    "        'u': 'u_30min',\n",
    "        'v': 'v_30min',\n",
    "        'w': 'w_30min',\n",
    "    })\n",
    ")\n",
    "fast_df_splash['dir_30min'] = np.rad2deg(np.arctan2(-fast_df_splash['u_30min'], -fast_df_splash['v_30min']))\n",
    "fast_df_splash['dir_30min'] = fast_df_splash['dir_30min'].apply(lambda dir: dir if dir >= 0 else dir+360)\n",
    "\n",
    "fast_df_splash = fast_df_splash.join(\n",
    "    fast_df_splash.groupby(pd.Grouper(freq='1min'))[['u', 'v', 'w']].transform('mean').rename(columns = {\n",
    "        'u': 'u_1min',\n",
    "        'v': 'v_1min',\n",
    "        'w': 'w_1min',\n",
    "    })\n",
    ")\n",
    "fast_df_splash['dir_1min'] = np.rad2deg(np.arctan2(-fast_df_splash['u_1min'], -fast_df_splash['v_1min']))\n",
    "fast_df_splash['dir_1min'] = fast_df_splash['dir_1min'].apply(lambda dir: dir if dir >= 0 else dir+360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_splash_30min = fast_df_splash.groupby(pd.Grouper(freq='1min')).mean()\n",
    "fig, axes = plt.subplots(2,1)\n",
    "fast_df_splash_30min['dir_30min'].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[0], sharex=True)\n",
    "fast_df_splash_30min['dir_1min'].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[0], sharex=True)\n",
    "fast_df_splash_30min[['u_30min','v_30min','w_30min']].loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800'].plot(ax=axes[1])\n",
    "axes[0].grid(axis='x')  # Add grid lines only for the x-axis\n",
    "axes[1].grid(axis='x')  # Add grid lines only for the x-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply double rotation to 3hr chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_df_splash = fast_df_splash.groupby(pd.Grouper(freq='30min')).apply(lambda df: FastDataSAIL.double_rotation(df, 'u', 'v', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_df_splash.index = fast_df_splash.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_splash['u'] = fast_df_splash['u'].interpolate()\n",
    "fast_df_splash['v'] = fast_df_splash['v'].interpolate()\n",
    "fast_df_splash['w'] = fast_df_splash['w'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uw_splash = calculate_mrd_for_df(\n",
    "    fast_df_splash[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_vw_splash = calculate_mrd_for_df(\n",
    "    fast_df_splash[['u', 'v', 'w']].reset_index(), \n",
    "    'v', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uv_splash = calculate_mrd_for_df(\n",
    "    fast_df_splash[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'v', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uu_splash = calculate_mrd_for_df(\n",
    "    fast_df_splash[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'u', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")\n",
    "mrd_vv_splash = calculate_mrd_for_df(\n",
    "    fast_df_splash[['u', 'v', 'w']].reset_index(), \n",
    "    'v', 'v', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")\n",
    "mrd_ww_splash = calculate_mrd_for_df(\n",
    "    fast_df_splash[['u', 'v', 'w']].reset_index(), \n",
    "    'w', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOS EC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open data, average from 20hz to 10hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_file_list = sorted(np.array([\n",
    "    [f for f in glob.glob(\n",
    "        os.path.join(DATA_DIR, \"sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_v2_**.nc\")\n",
    "    ) if d in f]\n",
    "    for d in DATES\n",
    "]).flatten())\n",
    "sos_file_list = sos_file_list[6:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos_all_data = fast_data_files_to_dataframe(\n",
    "    sos_file_list,\n",
    "    rotation='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos_all_data = utils.modify_df_timezone(fast_df_sos_all_data, 'UTC', 'US/Mountain')\n",
    "fast_df_sos_all_data = fast_df_sos_all_data.set_index('time').loc[DATE_LOCAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos = fast_df_sos_all_data[['u_3m_c', 'v_3m_c', 'w_3m_c']].rename(columns={\n",
    "    'u_3m_c': 'u',\n",
    "    'v_3m_c': 'v',\n",
    "    'w_3m_c': 'w',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resample the sos data from 20hz to 10hz with a simple block mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos = fast_df_sos.resample('0.1S').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos['dir'] = np.rad2deg(np.arctan2(-fast_df_sos['u'], -fast_df_sos['v']))\n",
    "\n",
    "# Create 30min avgs\n",
    "fast_df_sos = fast_df_sos.join(\n",
    "    fast_df_sos.groupby(pd.Grouper(freq='30min'))[['u', 'v', 'w']].transform('mean').rename(columns = {\n",
    "        'u': 'u_30min',\n",
    "        'v': 'v_30min',\n",
    "        'w': 'w_30min',\n",
    "    })\n",
    ")\n",
    "fast_df_sos['dir_30min'] = np.rad2deg(np.arctan2(-fast_df_sos['u_30min'], -fast_df_sos['v_30min']))\n",
    "fast_df_sos['dir_30min'] = fast_df_sos['dir_30min'].apply(lambda dir: dir if dir >= 0 else dir+360)\n",
    "\n",
    "# Create 1min avgs\n",
    "fast_df_sos = fast_df_sos.join(\n",
    "    fast_df_sos.groupby(pd.Grouper(freq='1min'))[['u', 'v', 'w']].transform('mean').rename(columns = {\n",
    "        'u': 'u_1min',\n",
    "        'v': 'v_1min',\n",
    "        'w': 'w_1min',\n",
    "    })\n",
    ")\n",
    "fast_df_sos['dir_1min'] = np.rad2deg(np.arctan2(-fast_df_sos['u_1min'], -fast_df_sos['v_1min']))\n",
    "fast_df_sos['dir_1min'] = fast_df_sos['dir_1min'].apply(lambda dir: dir if dir >= 0 else dir+360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos_1min = fast_df_sos.groupby(pd.Grouper(freq='1min')).mean()\n",
    "fig, axes = plt.subplots(4,1)\n",
    "fast_df_sos_1min['dir_30min'].plot(ax=axes[0], sharex=True)\n",
    "fast_df_sos_1min[['u_30min','v_30min','w_30min']].plot(ax=axes[1])\n",
    "fast_df_sos_1min[['u_1min','v_1min','w_1min']].plot(ax=axes[2])\n",
    "fast_df_sos_1min['dir_1min'].plot(ax=axes[3], sharex=True)\n",
    "axes[0].grid(axis='x')  # Add grid lines only for the x-axis\n",
    "axes[1].grid(axis='x')  # Add grid lines only for the x-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos_1min = fast_df_sos.groupby(pd.Grouper(freq='1min')).mean()\n",
    "fig, axes = plt.subplots(figsize=(12,1.5))\n",
    "fast_df_sos_1min['dir_1min'].plot(ax=axes, sharex=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply rotation into a given wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def project_winds(u, v):\n",
    "#     # Convert -45 degrees to radians\n",
    "#     angle = np.radians(-45)\n",
    "#     print(angle)\n",
    "#     # Define the rotation matrix\n",
    "#     rotation_matrix = np.array([\n",
    "#         [np.cos(angle), -np.sin(angle)],\n",
    "#         [np.sin(angle), np.cos(angle)]\n",
    "#     ])\n",
    "#     print(rotation_matrix)\n",
    "#     # Original wind vector\n",
    "#     wind_vector = np.array([u, v])\n",
    "#     print(wind_vector)\n",
    "#     # Projected wind vector\n",
    "#     projected_vector = rotation_matrix @ wind_vector\n",
    "#     print(projected_vector)\n",
    "#     return projected_vector\n",
    "\n",
    "# # Example usage\n",
    "# u = 10  # Westerly wind component\n",
    "# v = 5   # Southerly wind component\n",
    "# projected = project_winds(u, v)\n",
    "# print(\"Projected winds:\", projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = fast_df_sos.loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1501']\n",
    "# u, v = project_winds(\n",
    "#     src['u'],\n",
    "#     src['v']\n",
    "# )\n",
    "# src['u_proj'] = u \n",
    "# src['v_proj'] = v\n",
    "# src['dir_proj'] = np.rad2deg(np.arctan2(-src['u_proj'], -src['v_proj']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src[['u', 'v', 'dir']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src[['u_proj', 'v_proj', 'dir_proj']].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply double rotation to 3hr chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_df_sos = fast_df_sos.groupby(pd.Grouper(freq='30min')).apply(lambda df: FastDataSAIL.double_rotation(df, 'u', 'v', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_df_sos.index = fast_df_sos.index.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos['u'] = fast_df_sos['u'].interpolate()\n",
    "fast_df_sos['v'] = fast_df_sos['v'].interpolate()\n",
    "fast_df_sos['w'] = fast_df_sos['w'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate TKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos['tke'] = 0.5 * ( fast_df_sos['u']**2 + fast_df_sos['v']**2 + fast_df_sos['w']**2 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate MRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uw_sos = calculate_mrd_for_df(\n",
    "    fast_df_sos[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_vw_sos = calculate_mrd_for_df(\n",
    "    fast_df_sos[['u', 'v', 'w']].reset_index(), \n",
    "    'v', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uv_sos = calculate_mrd_for_df(\n",
    "    fast_df_sos[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'v', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations,\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_ww_sos = calculate_mrd_for_df(\n",
    "    fast_df_sos[['u', 'v', 'w']].reset_index(), \n",
    "    'w', 'w', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")\n",
    "mrd_uu_sos = calculate_mrd_for_df(\n",
    "    fast_df_sos[['u', 'v', 'w']].reset_index(), \n",
    "    'u', 'u', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")\n",
    "mrd_vv_sos = calculate_mrd_for_df(\n",
    "    fast_df_sos[['u', 'v', 'w']].reset_index(), \n",
    "    'v', 'v', \n",
    "    shift=1200, # 2 minute sliding window\n",
    "    parallelism=20, \n",
    "    M=14, # 27.31 minute long calculations\n",
    "    double_rotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot three sites comparison plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\overline{u'w'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1, figsize=(6,9), sharex=True, sharey=True)\n",
    "\n",
    "# AVP\n",
    "src = mrd_uw_splash.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-0.2, vmax=0.2, ax=axes[0])\n",
    "axes[0].set_title('AVP')\n",
    "\n",
    "# GOT\n",
    "src = mrd_uw_sail.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-0.2, vmax=0.2, ax=axes[1])\n",
    "axes[1].set_title('GOT')\n",
    "\n",
    "# KPS\n",
    "src = mrd_uw_sos.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-0.2, vmax=0.2, ax=axes[2])\n",
    "axes[2].set_title('KPS')\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(r\"$Co(\\overline{u'w'})$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\overline{v'w'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1, figsize=(6,9), sharex=True, sharey=True)\n",
    "\n",
    "# AVP\n",
    "src = mrd_vw_splash.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-0.01, vmax=0.01, ax=axes[0])\n",
    "axes[0].set_title('AVP')\n",
    "\n",
    "# GOT\n",
    "src = mrd_vw_sail.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-0.01, vmax=0.01, ax=axes[1])\n",
    "axes[1].set_title('GOT')\n",
    "\n",
    "# KPS\n",
    "src = mrd_vw_sos.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-0.01, vmax=0.01, ax=axes[2])\n",
    "axes[2].set_title('KPS')\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(r\"$Co(\\overline{u'w'})$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\overline{u'v'}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,1, figsize=(6,9), sharex=True, sharey=True)\n",
    "\n",
    "# AVP\n",
    "src = mrd_uv_splash.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-1, vmax=1, ax=axes[0])\n",
    "axes[0].set_title('AVP')\n",
    "\n",
    "# GOT\n",
    "src = mrd_uv_sail.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-1, vmax=1, ax=axes[1])\n",
    "axes[1].set_title('GOT')\n",
    "\n",
    "# KPS\n",
    "src = mrd_uv_sos.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='RdBu_r', levels=21, vmin=-1, vmax=1, ax=axes[2])\n",
    "axes[2].set_title('KPS')\n",
    "for ax in axes:\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(r\"$Co(\\overline{u'w'})$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_uv = pd.concat([\n",
    "    mrd_uv_splash[(mrd_uv_splash.start_time > '20230418 1500') & (mrd_uv_splash.start_time < '20230418 1700')].assign(\n",
    "        site = 'splash'\n",
    "    ),\n",
    "    mrd_uv_sail[(mrd_uv_sail.start_time > '20230418 1500') & (mrd_uv_sail.start_time < '20230418 1700')].assign(\n",
    "        site = 'sail'\n",
    "    ),\n",
    "    mrd_uv_sos[(mrd_uv_sos.start_time > '20230418 1500') & (mrd_uv_sos.start_time < '20230418 1700')].assign(\n",
    "        site ='sos' \n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_line = alt.Chart().mark_rule(color='red').encode(y=alt.datum(0))\n",
    "\n",
    "(\n",
    "    horizontal_line + alt.Chart(\n",
    "        src.reset_index()\n",
    "    ).mark_boxplot(\n",
    "        opacity=0.5\n",
    "    ).encode(\n",
    "        alt.X('tau:Q').scale(type='log'),\n",
    "        alt.Y('Co:Q'),\n",
    "        alt.Color('site:N')\n",
    "    )\n",
    ").configure_axis(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    mrd_uw_splash.set_index('start_time').loc[f'{DATE_LOCAL} 1200': f'{DATE_LOCAL} 1600']\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('median(Co):Q'),\n",
    ") + alt.Chart(\n",
    "    mrd_uw_sail.set_index('start_time').loc[f'{DATE_LOCAL} 1200': f'{DATE_LOCAL} 1600']\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('median(Co):Q'),\n",
    ") + alt.Chart(\n",
    "    mrd_uw_sos.set_index('start_time').loc[f'{DATE_LOCAL} 1200': f'{DATE_LOCAL} 1600']\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('median(Co):Q'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uu_sos = fast_df_sos.groupby(pd.Grouper(freq='180min'))[['u', 'v', 'w']].apply(\n",
    "    lambda df: calculate_mrd_for_df(df.reset_index(), 'u', 'u', shift=2000, parallelism=20).assign(hour_group = f\"{df.index.min()} - {df.index.max()}\")\n",
    ")\n",
    "mrd_vv_sos = fast_df_sos.groupby(pd.Grouper(freq='180min'))[['u', 'v', 'w']].apply(\n",
    "    lambda df: calculate_mrd_for_df(df.reset_index(), 'v', 'v', shift=2000, parallelism=20).assign(hour_group = f\"{df.index.min()} - {df.index.max()}\")\n",
    ")\n",
    "mrd_ww_sos = fast_df_sos.groupby(pd.Grouper(freq='180min'))[['u', 'v', 'w']].apply(\n",
    "    lambda df: calculate_mrd_for_df(df.reset_index(), 'w', 'w', shift=2000, parallelism=20).assign(hour_group = f\"{df.index.min()} - {df.index.max()}\")\n",
    ")\n",
    "\n",
    "mrd_wtke_sos = fast_df_sos.groupby(pd.Grouper(freq='180min'))[['u', 'v', 'w', 'tke']].apply(\n",
    "    lambda df: calculate_mrd_for_df(df.reset_index(), 'w', 'tke', shift=2000, parallelism=20).assign(hour_group = f\"{df.index.min()} - {df.index.max()}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_wtke_sos = calculate_mrd_for_df(fast_df_sos.reset_index(), 'w', 'tke', M=15, shift=1200, parallelism=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = mrd_wtke_sos.copy()\n",
    "src['midpoint_time'] = src['start_time'] + (src['end_time'] - src['start_time']) / 2\n",
    "src = src[src.start_time.dt.hour >= 12]\n",
    "src = src.reset_index()\n",
    "ds = src.set_index(['midpoint_time', 'tau']).to_xarray()\n",
    "ds['Co'].plot.contourf(x='midpoint_time', y='tau', cmap='PuOr', levels=20, figsize=(10,4))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    mrd_uu_sos.reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('mean(Co):Q'),\n",
    "    alt.Color('hour_group:O').scale(scheme='purpleorange'),\n",
    ").properties(width=200, height=200, title='3m uu') | alt.Chart(\n",
    "    mrd_vv_sos.reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('mean(Co):Q'),\n",
    "    alt.Color('hour_group:O').scale(scheme='purpleorange'),\n",
    ").properties(width=200, height=200, title='3m vv') | alt.Chart(\n",
    "    mrd_ww_sos.reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('mean(Co):Q'),\n",
    "    alt.Color('hour_group:O').scale(scheme='purpleorange'),\n",
    ").properties(width=200, height=200, title='3m ww')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uw_sos = fast_df_sos.groupby(pd.Grouper(freq='180min'))[['u', 'v', 'w']].apply(\n",
    "    lambda df: calculate_mrd_for_df(df.reset_index(), 'u', 'w', shift=2000, parallelism=20).assign(hour_group = f\"{df.index.min()} - {df.index.max()}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uw_sos.hour_group = mrd_uw_sos.hour_group.str.replace('2023-04-09 ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_mrd_sos_chart = alt.Chart(\n",
    "    mrd_uw_sos.reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('mean(Co):Q').scale(domain = [-0.1, 0.05]),\n",
    "    alt.Color('hour_group:O'),\n",
    ").properties(width=200, height=200, title='sos')\n",
    "daily_mrd_sos_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uw_sos['time_range'] = mrd_uw_sos.apply(\n",
    "    lambda row: str(row['start_time'].time()) + ' - ' + str(row['end_time'].time()),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrd_uw_sos.hour_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = mrd_uw_sos.query(\"\"\"\n",
    "        hour_group == '2023-04-18 15:00:00 - 2023-04-18 17:59:59.950000'\n",
    "    \"\"\").reset_index()\n",
    "alt.Chart(\n",
    "    src.reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('Co:Q'),\n",
    "    alt.Color('time_range:O').scale(scheme='purpleorange'),\n",
    ").properties(width=500, height=500, title='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = mrd_uw_sos.query(\"\"\"\n",
    "        hour_group == '2023-04-18 18:00:00 - 2023-04-18 20:59:59.950000'\n",
    "    \"\"\").reset_index()\n",
    "alt.Chart(\n",
    "    src.reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('Co:Q'),\n",
    "    alt.Color('time_range:O').scale(scheme='purpleorange'),\n",
    ").properties(width=500, height=500, title='sos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    daily_mrd_splash_chart & daily_mrd_sail_chart & daily_mrd_sos_chart\n",
    ").resolve_scale(\n",
    "    color='independent',\n",
    "    x='shared',\n",
    "    y='shared'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate MRDs for April 18 1500-1800, at SOS, multiple heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_df_sos_1500_1800 = fast_df_sos_all_data.loc[f'{DATE_LOCAL} 1500': f'{DATE_LOCAL} 1800']\n",
    "# fast_df_sos_1500_1800 = fast_df_sos_all_data.loc[f'{DATE_LOCAL} 1800': f'{DATE_LOCAL} 2100']\n",
    "# fast_df_sos_1500_1800 = fast_df_sos_all_data.loc[f'{DATE_LOCAL} 1200': f'{DATE_LOCAL} 1500']\n",
    "# fast_df_sos_1500_1800 = fast_df_sos_all_data.loc[f'{DATE_LOCAL} 0000': f'{DATE_LOCAL} 0300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrds_df_ls = []\n",
    "for h in [3,5,10,15,20]:\n",
    "    print(f\"Processing height: {h}m\")\n",
    "    fast_df_sos_oneheight = fast_df_sos_1500_1800[[f'u_{h}m_c', f'v_{h}m_c', f'w_{h}m_c']].rename(columns={\n",
    "        f'u_{h}m_c': 'u',\n",
    "        f'v_{h}m_c': 'v',\n",
    "        f'w_{h}m_c': 'w',\n",
    "    })\n",
    "    fast_df_sos_oneheight = FastDataSAIL.double_rotation(fast_df_sos_oneheight, 'u', 'v', 'w')\n",
    "    fast_df_sos_oneheight['u'] = fast_df_sos_oneheight['u'].interpolate()\n",
    "    fast_df_sos_oneheight['v'] = fast_df_sos_oneheight['v'].interpolate()\n",
    "    fast_df_sos_oneheight['w'] = fast_df_sos_oneheight['w'].interpolate()\n",
    "    mrds_df_ls.append(\n",
    "        calculate_mrd_for_df(\n",
    "            fast_df_sos_oneheight.reset_index(), 'u', 'w', shift=2000, parallelism=20\n",
    "        ).assign(\n",
    "            height = h\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    pd.concat(mrds_df_ls).query(\"height > 2\")\n",
    ").mark_line(point=True).encode(\n",
    "    alt.X('tau:Q').scale(type='log'),\n",
    "    alt.Y('Co:Q'),\n",
    "    alt.Color('start_time:O'),\n",
    "    alt.Row('height:O'),\n",
    "    tooltip = 'height:O',\n",
    ").properties(height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate into pre-determined wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_rotation(df, u_col, v_col, w_col):\n",
    "        # FIRST ROTATION\n",
    "        mean_u = df[u_col].mean()\n",
    "        mean_v = df[v_col].mean()\n",
    "        theta = np.arctan2(mean_v, mean_u)\n",
    "        adj_u = df[u_col]*np.cos(theta) + df[v_col]*np.sin(theta)\n",
    "        adj_v = -df[u_col]*np.sin(theta) + df[v_col]*np.cos(theta)\n",
    "        df[u_col] = adj_u\n",
    "        df[v_col] = adj_v\n",
    "        print(\n",
    "            'Means after 1st rotation:',\n",
    "            df[u_col].mean(),\n",
    "            df[v_col].mean(),\n",
    "            df[w_col].mean(),\n",
    "        )\n",
    "\n",
    "        # SECOND ROTATION\n",
    "        mean_u = df[u_col].mean()\n",
    "        mean_w = df[w_col].mean()\n",
    "        phi = np.arctan2(mean_w, mean_u)\n",
    "        adj_u = df[u_col]*np.cos(phi) + df[w_col]*np.sin(phi)\n",
    "        adj_w = - df[u_col]*np.sin(phi) + df[w_col]*np.cos(phi)\n",
    "        df[u_col] = adj_u\n",
    "        df[w_col] = adj_w\n",
    "        print(\n",
    "            'Means after 2nd rotation:',\n",
    "            df[u_col].mean(),\n",
    "            df[v_col].mean(),\n",
    "            df[w_col].mean(),\n",
    "        )\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_file_list = sorted(np.array([\n",
    "    [f for f in glob.glob(\n",
    "        os.path.join(DATA_DIR, \"sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_v2_**.nc\")\n",
    "    ) if d in f]\n",
    "    for d in DATES\n",
    "]).flatten())\n",
    "\n",
    "fast_df_sos_all_data = fast_data_files_to_dataframe(sos_file_list, rotation='none')\n",
    "fast_df_sos_all_data = utils.modify_df_timezone(fast_df_sos_all_data, 'UTC', 'US/Mountain')\n",
    "fast_df_sos_all_data = fast_df_sos_all_data.set_index('time').loc[DATE_LOCAL]\n",
    "fast_df_sos = fast_df_sos_all_data[['u_3m_c', 'v_3m_c', 'w_3m_c']].rename(columns={\n",
    "    'u_3m_c': 'u',\n",
    "    'v_3m_c': 'v',\n",
    "    'w_3m_c': 'w',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate integral length scales for all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For discreet periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root(result, autocorr_col, time_col):\n",
    "    # Assuming `data` is your DataFrame\n",
    "    # Replace `data` with the actual DataFrame variable\n",
    "    column_0 = result[autocorr_col]  # Extract column 0\n",
    "    lag_s = result[time_col]     # Extract 'lag (s)' column\n",
    "\n",
    "    # Find indices where column 0 changes sign\n",
    "    sign_changes = np.where(np.diff(np.sign(column_0)))[0]\n",
    "\n",
    "    if len(sign_changes) > 0:\n",
    "        # Get the first root\n",
    "        idx = sign_changes[0]\n",
    "        print(f\"The first root is at lag (s): {lag_s[idx]}\")\n",
    "        return idx\n",
    "        # # Linear interpolation to find the root\n",
    "        # x1, x2 = lag_s.iloc[idx], lag_s.iloc[idx + 1]\n",
    "        # y1, y2 = column_0.iloc[idx], column_0.iloc[idx + 1]\n",
    "        # root = x1 - y1 * (x2 - x1) / (y2 - y1)\n",
    "        print(f\"The first root is at lag (s): {root}\")\n",
    "    else:\n",
    "        print(\"No root found in column 0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_period in [\n",
    "    ('20230418 0000', '20230418 0301'),\n",
    "    ('20230418 0301', '20230418 0601'),\n",
    "    ('20230418 0601', '20230418 0901'),\n",
    "    ('20230418 0901', '20230418 1201'),\n",
    "    ('20230418 1201', '20230418 1501'),\n",
    "    ('20230418 1501', '20230418 1801'),\n",
    "    ('20230418 1801', '20230418 2101'),\n",
    "    ('20230418 2101', '20230418 2359'),\n",
    "]:\n",
    "    # SAIL\n",
    "    src_sail = fast_df_sail.loc[time_period[0]: time_period[1]]\n",
    "    src_sail = src_sail.assign(\n",
    "        spd = np.sqrt(src_sail['u']**2 + src_sail['v']**2)\n",
    "    )\n",
    "    spd_corr_result_sail = np.correlate(\n",
    "        src_sail['spd'] - src_sail['spd'].mean(), \n",
    "        src_sail['spd'] - src_sail['spd'].mean(), \n",
    "        mode='full'\n",
    "    )\n",
    "    result_sail = spd_corr_result_sail[spd_corr_result_sail.size // 2:]\n",
    "    result_sail = pd.DataFrame({\"R\": result_sail / float(result_sail.max())})\n",
    "    result_sail['lag (s)'] = result_sail.index/10\n",
    "\n",
    "    first_root_sail = find_root(result_sail, 'R',  'lag (s)')\n",
    "    integral_result_sail = np.trapz(\n",
    "        result_sail['R'].loc[:first_root_sail],\n",
    "        result_sail['lag (s)'].loc[:first_root_sail],\n",
    "    )\n",
    "    integral_length_scale_sail = (integral_result_sail * src_sail['spd'].mean())\n",
    "    print(f'The integration result_sail is: {integral_result_sail}')\n",
    "    print(f'The mean wind speed is: {src_sail['spd'].mean()}')\n",
    "    print(f\"The integral length scale is: {integral_length_scale_sail}\")\n",
    "\n",
    "\n",
    "    # SPLASH\n",
    "    src_splash = fast_df_splash.loc[time_period[0]: time_period[1]]\n",
    "    src_splash = src_splash.assign(\n",
    "        spd = np.sqrt(src_splash['u']**2 + src_splash['v']**2)\n",
    "    )\n",
    "    spd_corr_result_splash = np.correlate(\n",
    "        src_splash['spd'] - src_splash['spd'].mean(), \n",
    "        src_splash['spd'] - src_splash['spd'].mean(), \n",
    "        mode='full'\n",
    "    )\n",
    "    result_splash = spd_corr_result_splash[spd_corr_result_splash.size // 2:]\n",
    "    result_splash = pd.DataFrame({\"R\": result_splash / float(result_splash.max())})\n",
    "    result_splash['lag (s)'] = result_splash.index/10\n",
    "\n",
    "    first_root_splash = find_root(result_splash, 'R',  'lag (s)')\n",
    "    integral_result_splash = np.trapz(\n",
    "        result_splash['R'].loc[:first_root_splash],\n",
    "        result_splash['lag (s)'].loc[:first_root_splash],\n",
    "    )\n",
    "    integral_length_scale_splash = (integral_result_splash * src_splash['spd'].mean())\n",
    "    print(f'The integration result_splash is: {integral_result_splash}')\n",
    "    print(f'The mean wind speed is: {src_splash['spd'].mean()}')\n",
    "    print(f\"The integral length scale is: {integral_length_scale_splash}\")\n",
    "\n",
    "\n",
    "    # SOS\n",
    "    src_sos = fast_df_sos.loc[time_period[0]: time_period[1]]\n",
    "    src_sos = src_sos.assign(\n",
    "        spd = np.sqrt(src_sos['u']**2 + src_sos['v']**2)\n",
    "    )\n",
    "    spd_corr_result_sos = np.correlate(\n",
    "        src_sos['spd'] - src_sos['spd'].mean(), \n",
    "        src_sos['spd'] - src_sos['spd'].mean(), \n",
    "        mode='full'\n",
    "    )\n",
    "    result_sos = spd_corr_result_sos[spd_corr_result_sos.size // 2:]\n",
    "    result_sos = pd.DataFrame({\"R\": result_sos / float(result_sos.max())})\n",
    "    result_sos['lag (s)'] = result_sos.index/20\n",
    "\n",
    "    first_root_sos = find_root(result_sos, 'R',  'lag (s)')\n",
    "    integral_result_sos = np.trapz(\n",
    "        result_sos['R'].loc[:first_root_sos],\n",
    "        result_sos['lag (s)'].loc[:first_root_sos],\n",
    "    )\n",
    "    integral_length_scale_sos = integral_result_sos * src_sos['spd'].mean()\n",
    "    print(f'The integration result_sos is: {integral_result_sos}')\n",
    "    print(f'The mean wind speed is: {src_sos['spd'].mean()}')\n",
    "    print(f\"The integral length scale is: {integral_length_scale_sos}\")\n",
    "\n",
    "    plt.plot(result_sail['lag (s)'], result_sail[\"R\"], label='Gothic (SAIL)')\n",
    "    plt.plot(result_splash['lag (s)'], result_splash[\"R\"], label='Avery Picnic (SPLASH)')\n",
    "    plt.plot(result_sos['lag (s)'], result_sos[\"R\"], label='Kettle Ponds (SOS)')\n",
    "    plt.text(x=1800, y=1, s = f\"Lsail = {round(integral_length_scale_sail,0)}\")\n",
    "    plt.text(x=1800, y=0.95, s = f\"Lsplash = {round(integral_length_scale_splash,0)}\")\n",
    "    plt.text(x=1800, y=0.9, s = f\"Lsos = {round(integral_length_scale_sos,0)}\")\n",
    "    plt.title(time_period)\n",
    "    plt.axhline(0)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For entire day, using moving window averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sail_wholeday = fast_df_sail.assign(\n",
    "    spd = np.sqrt(fast_df_sail['u']**2 + fast_df_sail['v']**2)\n",
    ")\n",
    "src_sail_wholeday['spd_fluc'] = src_sail_wholeday['spd'] - src_sail_wholeday['spd'].rolling(window='30min').mean()\n",
    "spd_corr_result_sail_wholeday = np.correlate(\n",
    "    src_sail_wholeday['spd_fluc'],\n",
    "    src_sail_wholeday['spd_fluc'],\n",
    "    mode='full'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_splash_wholeday = fast_df_splash.assign(\n",
    "    spd = np.sqrt(fast_df_splash['u']**2 + fast_df_splash['v']**2)\n",
    ")\n",
    "src_splash_wholeday['spd_fluc'] = src_splash_wholeday['spd'] - src_splash_wholeday['spd'].rolling(window='30min').mean()\n",
    "spd_corr_result_splash_wholeday = np.correlate(\n",
    "    src_splash_wholeday['spd_fluc'],\n",
    "    src_splash_wholeday['spd_fluc'],\n",
    "    mode='full'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sos_wholeday = fast_df_sos.assign(\n",
    "    spd = np.sqrt(fast_df_sos['u']**2 + fast_df_sos['v']**2)\n",
    ")\n",
    "src_sos_wholeday['spd_fluc'] = src_sos_wholeday['spd'] - src_sos_wholeday['spd'].rolling(window='30min').mean()\n",
    "spd_corr_result_sos_wholeday = np.correlate(\n",
    "    src_sos_wholeday['spd_fluc'],\n",
    "    src_sos_wholeday['spd_fluc'],\n",
    "    mode='full'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sail = spd_corr_result_sail_wholeday[spd_corr_result_sail_wholeday.size // 2:]\n",
    "result_sail = pd.DataFrame({\"R\": result_sail / float(result_sail.max())})\n",
    "result_sail['lag_s'] = result_sail.index/10\n",
    "first_root_sail = find_root(result_sail, 'R',  'lag_s')\n",
    "integral_result_sail = np.trapz(\n",
    "    result_sail['R'].loc[:first_root_sail],\n",
    "    result_sail['lag_s'].loc[:first_root_sail],\n",
    ")\n",
    "integral_length_scale_sail = (integral_result_sail * src_sail['spd'].mean())\n",
    "\n",
    "\n",
    "result_splash = spd_corr_result_splash_wholeday[spd_corr_result_splash_wholeday.size // 2:]\n",
    "result_splash = pd.DataFrame({\"R\": result_splash / float(result_splash.max())})\n",
    "result_splash['lag_s'] = result_splash.index/10\n",
    "first_root_splash = find_root(result_splash, 'R',  'lag_s')\n",
    "integral_result_splash = np.trapz(\n",
    "    result_splash['R'].loc[:first_root_splash],\n",
    "    result_splash['lag_s'].loc[:first_root_splash],\n",
    ")\n",
    "integral_length_scale_splash = (integral_result_splash * src_splash['spd'].mean())\n",
    "\n",
    "\n",
    "result_sos = spd_corr_result_sos_wholeday[spd_corr_result_sos_wholeday.size // 2:]\n",
    "result_sos = pd.DataFrame({\"R\": result_sos / float(result_sos.max())})\n",
    "result_sos['lag_s'] = result_sos.index/20\n",
    "first_root_sos = find_root(result_sos, 'R',  'lag_s')\n",
    "integral_result_sos = np.trapz(\n",
    "    result_sos['R'].loc[:first_root_sos],\n",
    "    result_sos['lag_s'].loc[:first_root_sos],\n",
    ")\n",
    "integral_length_scale_sos = (integral_result_sos * src_sos['spd'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(result_sail.query(\"lag_s < 5000\")).transform_filter(\n",
    "    alt.datum.lag_s > 0\n",
    ").mark_line().encode(\n",
    "    alt.X('lag_s:Q').scale(type='log'),\n",
    "    alt.Y('R:Q')\n",
    ").properties(title=f'L = {round(integral_length_scale_sail, 1)}') | alt.Chart(result_splash.query(\"lag_s < 5000\")).transform_filter(\n",
    "    alt.datum.lag_s > 0\n",
    ").mark_line().encode(\n",
    "    alt.X('lag_s:Q').scale(type='log'),\n",
    "    alt.Y('R:Q')\n",
    ").properties(title=f'L = {round(integral_length_scale_splash, 1)}') | alt.Chart(result_sos.query(\"lag_s < 5000\")).transform_filter(\n",
    "    alt.datum.lag_s > 0\n",
    ").mark_line().encode(\n",
    "    alt.X('lag_s:Q').scale(type='log'),\n",
    "    alt.Y('R:Q')\n",
    ").properties(title=f'L = {round(integral_length_scale_sos, 1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2b11a00ad1b97cabcd9cc9209b8824a0fcaf6ffe37b5243943912873b5dcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
