{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "from sublimpy import utils\n",
    "from sublimpy import tidy\n",
    "from sublimpy import extrautils\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_16.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_17.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_18.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_19.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_20.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_21.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_22.nc',\n",
       " '/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/isfs_sos_qc_geo_tiltcor_hr_20230503_23.nc']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(\"/Users/elischwat/Development/data/sublimationofsnow/sosqc_fast/*.nc\")\n",
    "file_list = [ f for f in file_list if '_20230503_' in f]\n",
    "file_list = sorted(file_list)[16:]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_mfdataset(file_list, concat_dim=\"time\", combine=\"nested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[[\n",
    "    'base_time',\n",
    "    'u_3m_c',\t'v_3m_c',\t'w_3m_c',\t'h2o_3m_c',\t\t'tc_3m_c',\n",
    "    'u_3m_d',\t'v_3m_d',\t'w_3m_d',\t'h2o_3m_d',\t\t'tc_3m_d',\n",
    "    'u_3m_ue',\t'v_3m_ue',\t'w_3m_ue',\t'h2o_3m_ue',\t'tc_3m_ue',\n",
    "    'u_3m_uw',\t'v_3m_uw',\t'w_3m_uw',\t'h2o_3m_uw',\t'tc_3m_uw',\n",
    "    'u_5m_c',\t'v_5m_c',\t'w_5m_c',\t'h2o_5m_c',\t\t'tc_5m_c',\n",
    "    'u_10m_c',\t'v_10m_c',\t'w_10m_c',\t'h2o_10m_c',\t'tc_10m_c',\n",
    "    'u_10m_d',\t'v_10m_d',\t'w_10m_d',\t'h2o_10m_d',\t'tc_10m_d',\n",
    "    'u_10m_ue',\t'v_10m_ue',\t'w_10m_ue',\t'h2o_10m_ue',\t'tc_10m_ue',\n",
    "    'u_10m_uw',\t'v_10m_uw',\t'w_10m_uw',\t'h2o_10m_uw',\t'tc_10m_uw',\n",
    "    'u_15m_c',\t'v_15m_c',\t'w_15m_c',\t'h2o_15m_c',\t'tc_15m_c',\n",
    "    'u_20m_c',\t'v_20m_c',\t'w_20m_c',\t'h2o_20m_c',\t'tc_20m_c',\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planar fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_file = \"/Users/elischwat/Development/data/sublimationofsnow/monthly_planar_fits.csv\"\n",
    "weekly_file = \"/Users/elischwat/Development/data/sublimationofsnow/weekly_planar_fits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x_/2h52bcjx2px15bhmdpdd748h0000gn/T/ipykernel_31044/3479049279.py:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  fits_df = pd.read_csv(monthly_file, delim_whitespace=True)\n",
      "/var/folders/x_/2h52bcjx2px15bhmdpdd748h0000gn/T/ipykernel_31044/3479049279.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  weeklyfits_df = pd.read_csv(weekly_file, delim_whitespace=True)\n"
     ]
    }
   ],
   "source": [
    "fits_df = pd.read_csv(monthly_file, delim_whitespace=True)\n",
    "weeklyfits_df = pd.read_csv(weekly_file, delim_whitespace=True)\n",
    "\n",
    "fits_df['height'] = fits_df['height'].str.replace('_', '.').astype('float')\n",
    "weeklyfits_df['start_date'] = pd.to_datetime(weeklyfits_df['start_date'], format='%Y%m%d')\n",
    "weeklyfits_df['end_date'] = pd.to_datetime(weeklyfits_df['end_date'], format='%Y%m%d')\n",
    "\n",
    "fits_df['W_f'] = fits_df.apply(\n",
    "    lambda row: [row['W_f_1'], row['W_f_2'], row['W_f_3']],\n",
    "    axis=1\n",
    ").drop(columns=['W_f_1', 'W_f_2', 'W_f_3'])\n",
    "weeklyfits_df['W_f'] = weeklyfits_df.apply(\n",
    "    lambda row: [row['W_f_1'], row['W_f_2'], row['W_f_3']],\n",
    "    axis=1\n",
    ").drop(columns=['W_f_1', 'W_f_2', 'W_f_3'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create timestamp\n",
    "To use the datam, its necessary to combine 3 columns of data from the dataset to get the full timestamp. This is demonstrated below. The 'time' column actually only incudes the second and minute information. For all datapoints, the hour according to the 'time' column is 1.  The 'base_time' column indicates the hour of the day. The 'sample' column indicates the 20hz sample number. \n",
    "\n",
    "We demonstrate this in the plots below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-657c3792d8204fa885ef4e470f896063.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-657c3792d8204fa885ef4e470f896063.vega-embed details,\n",
       "  #altair-viz-657c3792d8204fa885ef4e470f896063.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-657c3792d8204fa885ef4e470f896063\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-657c3792d8204fa885ef4e470f896063\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-657c3792d8204fa885ef4e470f896063\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"vconcat\": [{\"data\": {\"url\": \"altair-data-25cb27ad3743cd2be76cafe99967902e.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"tick\", \"thickness\": 5}, \"encoding\": {\"x\": {\"field\": \"sample\", \"title\": \"sample (n = 20)\", \"type\": \"quantitative\"}}, \"width\": 600}, {\"data\": {\"url\": \"altair-data-27b4f2ece2399b9c23e13ff964d1b9f8.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"tick\", \"thickness\": 1}, \"encoding\": {\"x\": {\"axis\": {\"format\": \"%H%M%p\"}, \"field\": \"time\", \"title\": \"time (n = 3600)\", \"type\": \"temporal\"}}, \"width\": 600}, {\"data\": {\"url\": \"altair-data-5d5254d56b0c3f3b89b4362acfb5f99e.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"tick\", \"thickness\": 5}, \"encoding\": {\"x\": {\"field\": \"base_time\", \"title\": \"base_time (n = 8)\", \"type\": \"temporal\"}}, \"width\": 600}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.VConcatChart(...)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'time': np.unique(ds['time'])})\n",
    "df2 = pd.DataFrame({'base_time': np.unique(ds['base_time'])})\n",
    "df3 = pd.DataFrame({'sample': np.unique(ds['sample'])})\n",
    "(\n",
    "    alt.Chart(df3).mark_tick(thickness=5).encode(\n",
    "        alt.X(\"sample:Q\").title(\n",
    "            f'sample (n = {len(df3)})'\n",
    "        )\n",
    "    ).properties(width=600) & \n",
    "\n",
    "    alt.Chart(df1).mark_tick(thickness=1).encode(\n",
    "        alt.X(\"time:T\").axis(\n",
    "            format='%H%M%p'\n",
    "        ).title(\n",
    "            f'time (n = {len(df1)})'\n",
    "        )\n",
    "    ).properties(width=600) & \n",
    "\n",
    "    alt.Chart(df2).mark_tick(thickness=5).encode(\n",
    "        alt.X(\"base_time:T\").title(\n",
    "            f'base_time (n = {len(df2)})'\n",
    "        )\n",
    "    ).properties(width=600)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = df.apply(lambda row: dt.datetime(\n",
    "        year = row['time'].year,\n",
    "        month = row['time'].month,\n",
    "        day = row['time'].day,\n",
    "        hour = row['base_time'].hour,\n",
    "        minute = row['time'].minute,\n",
    "        second = row['time'].second,\n",
    "        microsecond = int(row['sample'] * (1e6/20))\n",
    "    ),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.set_index('time').to_xarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = utils.modify_xarray_timezone(ds, 'UTC', \"US/Mountain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function to do Reynolds Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_re_avg_ds(\n",
    "        ds, \n",
    "        re_avg_period_size, \n",
    "        var1,\n",
    "        var2,\n",
    "        covariance_name\n",
    "):\n",
    "    coarse_ds = ds.coarsen(time=re_avg_period_size).mean()\n",
    "    coarse_ds = coarse_ds.assign_coords(time = coarse_ds.time.dt.round('1s'))\n",
    "    coarse_ds = coarse_ds.reindex_like(ds, method='nearest')\n",
    "    ds[f\"{var1}_mean\"] = coarse_ds[f\"{var1}\"]\n",
    "    ds[f\"{var1}_fluc\"] = ds[f\"{var1}\"] - ds[f\"{var1}_mean\"]\n",
    "    ds[f\"{var2}_mean\"] = coarse_ds[f\"{var2}\"]\n",
    "    ds[f\"{var2}_fluc\"] = ds[f\"{var2}\"] - ds[f\"{var2}_mean\"]\n",
    "    ds[covariance_name] = ds[f\"{var2}_fluc\"] * ds[f\"{var1}_fluc\"]\n",
    "    ds = ds.coarsen(time = re_avg_period_size).mean()\n",
    "    ds = ds.assign_coords(time = ds.time.dt.round('1s'))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over variables, apply planar fit to fast data, and calculate covariance fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH = ds.time.dt.month.values[0]\n",
    "\n",
    "df_list = []\n",
    "for tower in ['c', 'uw', 'ue', 'd']:\n",
    "    if tower == 'c':\n",
    "        heights = [3,5,10,15,20]\n",
    "    else:\n",
    "        heights = [3,10]\n",
    "    \n",
    "    for height in heights:\n",
    "        fitting_params = fits_df.set_index(['month', 'height', 'tower']).loc[\n",
    "            MONTH,\n",
    "            height,\n",
    "            tower\n",
    "        ]\n",
    "        u, v, w = extrautils.apply_planar_fit(\n",
    "            ds[f'u_{height}m_{tower}'].values.flatten(),\n",
    "            ds[f'v_{height}m_{tower}'].values.flatten(),\n",
    "            ds[f'w_{height}m_{tower}'].values.flatten(),\n",
    "            fitting_params['a'], \n",
    "            fitting_params['W_f'],\n",
    "        )\n",
    "        ds[f'u_{height}m_{tower}_fit'] = ('time', u)\n",
    "        ds[f'v_{height}m_{tower}_fit'] = ('time', v)\n",
    "        ds[f'w_{height}m_{tower}_fit'] = ('time', w)\n",
    "        \n",
    "        ds_plain =  create_re_avg_ds(\n",
    "            ds, \n",
    "            300*20, \n",
    "            var1 = f'w_{height}m_{tower}', \n",
    "            var2= f'h2o_{height}m_{tower}', \n",
    "            covariance_name = f'w_h2o__{height}m_{tower}'\n",
    "        )\n",
    "        ds_fit =    create_re_avg_ds(\n",
    "            ds, \n",
    "            300*20, \n",
    "            var1 = f'w_{height}m_{tower}_fit', \n",
    "            var2= f'h2o_{height}m_{tower}', \n",
    "            covariance_name = f'w_h2o__{height}m_{tower}_fit'\n",
    "        )\n",
    "\n",
    "        merged_df = ds_plain[f'w_h2o__{height}m_{tower}'].to_dataframe()[[f'w_h2o__{height}m_{tower}']].join(\n",
    "                ds_fit[f'w_h2o__{height}m_{tower}_fit'].to_dataframe()[[f'w_h2o__{height}m_{tower}_fit']]\n",
    "        )\n",
    "        df_list.append(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/elischwat/Development/data/sublimationofsnow/planar_fit/20221101.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2b11a00ad1b97cabcd9cc9209b8824a0fcaf6ffe37b5243943912873b5dcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
