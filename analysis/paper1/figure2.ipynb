{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open precipitation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_file = \"/data2/elilouis/sublimationofsnow/tilden_precip_data/kettle_ponds_precip.csv\"\n",
    "\n",
    "precip_df = pd.read_csv(precip_file)\n",
    "\n",
    "precip_df['date'] = pd.to_datetime(precip_df['date'])\n",
    "\n",
    "acc_precip_on_first_day = precip_df.set_index('date').loc['20221130'].acc_prec\n",
    "\n",
    "precip_df = precip_df.set_index('date').loc['20221130': '20230510'].reset_index()\n",
    "precip_df['acc_prec']  = precip_df['acc_prec'] - acc_precip_on_first_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open SOS Measurement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '20221130'\n",
    "end_date = '20230509'\n",
    "# open files\n",
    "tidy_df_5Min = pd.read_parquet('../sos/tidy_df_20221130_20230517_noplanar_fit.parquet')\n",
    "tidy_df_30Min = pd.read_parquet('../sos/tidy_df_30Min_20221130_20230517_noplanar_fit.parquet')\n",
    "# convert time column to datetime\n",
    "tidy_df_5Min['time'] = pd.to_datetime(tidy_df_5Min['time'])\n",
    "tidy_df_30Min['time'] = pd.to_datetime(tidy_df_30Min['time'])\n",
    "# limit data to our dates of interest, based on continuous snow cover at Kettle Ponds\n",
    "tidy_df_5Min = tidy_df_5Min.set_index('time').loc[start_date:end_date].reset_index()\n",
    "tidy_df_30Min = tidy_df_30Min.set_index('time').loc[start_date:end_date].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick way to get variable info if we want it \n",
    "# import xarray as xr\n",
    "# ds = xr.open_dataset(\"/data2/elilouis/sublimationofsnow/sosnoqc/isfs_20221228.nc\")\n",
    "# ds['SWE_p2_c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: remove all LH flux data points with less than 90% of 20hz data being good\n",
    "### Step 2: remove all LH flux data points with magnitude greater than 1 g/m^2/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_lhflux_and_counts_variables = [\n",
    "    ('w_h2o__2m_c', 'counts_2m_c_1'), \n",
    "    ('w_h2o__3m_c', 'counts_3m_c_1'), \n",
    "    ('w_h2o__5m_c', 'counts_5m_c_1'), \n",
    "    ('w_h2o__10m_c', 'counts_10m_c_1'), \n",
    "    ('w_h2o__15m_c', 'counts_15m_c_1'), \n",
    "    ('w_h2o__20m_c', 'counts_20m_c_1'), \n",
    "\n",
    "\n",
    "    ('w_h2o__1m_d', 'counts_1m_d_1'), \n",
    "    ('w_h2o__3m_d', 'counts_3m_d_1'), \n",
    "    ('w_h2o__10m_d', 'counts_10m_d_1'), \n",
    "      \n",
    "    ('w_h2o__1m_ue', 'counts_1m_ue_1'), \n",
    "    ('w_h2o__3m_ue', 'counts_3m_ue_1'), \n",
    "    ('w_h2o__10m_ue', 'counts_10m_ue_1'), \n",
    "\n",
    "\n",
    "    ('w_h2o__1m_uw',  'counts_1m_uw_1'), \n",
    "    ('w_h2o__3m_uw', 'counts_3m_uw_1'), \n",
    "    ('w_h2o__10m_uw', 'counts_10m_uw_1'), \n",
    "]\n",
    "ec_lhflux_variables = list(zip(*ec_lhflux_and_counts_variables))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "all_lhflux_measurements.mean(), all_lhflux_measurements.std(), all_lhflux_measurements.min(), all_lhflux_measurements.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Remove all data points at once - perform both steps 1 and 2 simultaneously\n",
    "####################################################################################\n",
    "# for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "#     print(flux_var, counts_var)\n",
    "#     counts_src = tidy_df_5Min[tidy_df_5Min.variable == counts_var]\n",
    "#     times_with_good_data_50percent = counts_src[counts_src.value >= 5400].time\n",
    "#     n_before_dropping = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "#     tidy_df_5Min.loc[\n",
    "#         (~tidy_df_5Min['time'].isin(times_with_good_data_50percent)) &\n",
    "#         (tidy_df_5Min['variable'] == flux_var),\n",
    "#         'value'\n",
    "#     ] = np.nan\n",
    "#     n_after_step_1 = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "\n",
    "#     variable_src = tidy_df_5Min[tidy_df_5Min.variable == flux_var]\n",
    "#     times_with_outofbounds_values = variable_src[np.abs(variable_src.value) > 1].time\n",
    "#     tidy_df_5Min.loc[\n",
    "#         (tidy_df_5Min['time'].isin(times_with_outofbounds_values)) & \n",
    "#         (tidy_df_5Min['variable'] == flux_var),\n",
    "#         'value'\n",
    "#     ] = np.nan\n",
    "#     n_after_step_2 = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "#     print(n_before_dropping, n_after_step_1, n_after_step_2)\n",
    "#     print(round((n_before_dropping-n_after_step_2)/n_before_dropping, 3))\n",
    "\n",
    "####################################################################################\n",
    "# Perform steps 1 and 2 separately \n",
    "####################################################################################\n",
    "for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "    counts_src = tidy_df_5Min[tidy_df_5Min.variable == counts_var]\n",
    "    times_with_good_data_50percent = counts_src[counts_src.value >= 5400].time\n",
    "    tidy_df_5Min.loc[\n",
    "        (~tidy_df_5Min['time'].isin(times_with_good_data_50percent)) &\n",
    "        (tidy_df_5Min['variable'] == flux_var),\n",
    "        'value'\n",
    "    ] = np.nan\n",
    "\n",
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "mean = all_lhflux_measurements.mean() \n",
    "stddev = all_lhflux_measurements.std()\n",
    "print(mean, stddev, all_lhflux_measurements.min(), all_lhflux_measurements.max())\n",
    "\n",
    "for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "    variable_src = tidy_df_5Min[tidy_df_5Min.variable == flux_var]\n",
    "    times_with_outofbounds_values = variable_src[\n",
    "        ((variable_src.value) > (mean + 5*stddev)) |\n",
    "        ((variable_src.value) < (mean - 5*stddev))\n",
    "    ].time\n",
    "    tidy_df_5Min.loc[\n",
    "        (tidy_df_5Min['time'].isin(times_with_outofbounds_values)) & \n",
    "        (tidy_df_5Min['variable'] == flux_var),\n",
    "        'value'\n",
    "    ] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "print(all_lhflux_measurements.mean(), all_lhflux_measurements.std(), all_lhflux_measurements.min(), all_lhflux_measurements.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Model Ensemble Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_parquet(\"model_results.parquet\")\n",
    "# add a bunch of columns that are descriptive, from the config column which has multiple bits of info\n",
    "model_df['z0'] = model_df['config'].apply(\n",
    "    lambda v: float(v.split(' ')[-1])\n",
    ")\n",
    "model_df['e_sat_curve'] = model_df['config'].apply(\n",
    "    lambda v: 'metpy' if 'metpy' in v else 'alduchov'\n",
    ")\n",
    "model_df['surface_measurement'] = model_df['config'].apply(\n",
    "    lambda v: v.split(' ')[-3]\n",
    ")\n",
    "model_df['scheme'] = model_df['config'].apply(\n",
    "    lambda v: 'andreas' if 'andreas lengths' in v else 'yang'\n",
    ")\n",
    "model_df['most_config'] = model_df['config'].apply(lambda s: ' '.join(s.split(' ')[:-3]))\n",
    "# remove the scalar roughness length parameterization info \n",
    "model_df['most_config'] = model_df['most_config'].str.replace(' andreas lengths', '')\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle a pesky outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.loc[(model_df.time == \"2023-01-22 1400\") & (model_df.surface_measurement == 'Tsurf_d'), 'latent heat flux'] = 0\n",
    "model_df.loc[(model_df.time == \"2023-01-22 1400\") & (model_df.surface_measurement == 'Tsurf_d'), 'sensible heat flux'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cumulative sublimation (mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EC Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sublimpy import tidy\n",
    "import metpy.constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_lhflux_variables = list(zip(*ec_lhflux_and_counts_variables))[0]\n",
    "seconds_per_5min = 60*5\n",
    "for variable in ec_lhflux_variables:\n",
    "    height = int(variable.split('_')[-2].split('m')[0])\n",
    "    tower = variable.split('_')[-1]\n",
    "    # print(len(tidy_df_5Min.query(f\"variable == '{variable}'\")))\n",
    "    # print(len(np.nancumsum(tidy_df_5Min.query(f\"variable == '{variable}'\")['value']*seconds_per_5min)/metpy.constants.density_water.magnitude,))\n",
    "    tidy_df_5Min = tidy.tidy_df_add_variable(\n",
    "        tidy_df_5Min,\n",
    "        np.nancumsum(tidy_df_5Min.query(f\"variable == '{variable}'\")['value']*seconds_per_5min)/metpy.constants.density_water.magnitude,\n",
    "        f\"cumulative_sub_measured_{height}m_{tower}\",\n",
    "        \"Cumulative sublimation measured\",  \n",
    "        height,\n",
    "        tower\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_cumsum = pd.DataFrame(model_df.sort_values(\"time\").set_index(\n",
    "    [\"time\", \"config\", \"scheme\", \"z0\", \"e_sat_curve\", \"surface_measurement\", \"most_config\"]\n",
    ").groupby([\"config\", \"scheme\", \"z0\", \"e_sat_curve\", \"surface_measurement\", \"most_config\"])['latent heat flux'].cumsum()).reset_index()\n",
    "model_df_cumsum_daily = pd.DataFrame(model_df_cumsum.set_index(\"time\").groupby(\n",
    "    ['config', \"scheme\", \"z0\", \"e_sat_curve\", \"surface_measurement\", \"most_config\", pd.Grouper(freq='1440Min')]\n",
    ")['latent heat flux'].max()).reset_index()\n",
    "\n",
    "from metpy.constants import density_water\n",
    "seconds_per_30min = 60*30\n",
    "model_df_cumsum_daily['latent heat flux (mm)'] = model_df_cumsum_daily['latent heat flux'].values * seconds_per_30min/density_water.magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_chart = alt.Chart(\n",
    "    tidy_df_5Min.query(\"measurement == 'Cumulative sublimation measured'\").query(\"height > 1\")\n",
    ").transform_window(\n",
    "    frame = [-24, 24],\n",
    "    groupby=['variable'],\n",
    "    rolling_avg = 'mean(value)'\n",
    ").mark_line(opacity=0.5, strokeWidth=1).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"rolling_avg:Q\").title([\"Cumulative sublimation (mm)\", \"(4 hour rolling average)\"]),\n",
    "    detail = 'variable:N',\n",
    "    # alt.Color(\"variable:N\"),\n",
    "    tooltip = 'variable'\n",
    ").properties(width = 250, height = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_chart = alt.Chart(\n",
    "    model_df_cumsum_daily[model_df_cumsum_daily.time < '2023-05-10'].query(\"z0 < 1.e-03\").dropna()\n",
    ").mark_line(opacity = 0.5, color='grey', strokeWidth=0.2).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"latent heat flux (mm)\"),\n",
    "    detail = 'config'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpillow_and_precip_chart = alt.Chart(\n",
    "    tidy_df_30Min.query(\"variable == 'SWE_p2_c'\").dropna()\n",
    ").transform_window(\n",
    "    frame = [-48, 48],\n",
    "    rolling_median = 'median(value)'\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\").axis(labels=False).title(None),\n",
    "    alt.Y(\"rolling_median:Q\").title([\"Snow water\", \"equivalent (mm)\"])\n",
    ").properties(width = 250, height = 83) + alt.Chart(\n",
    "    precip_df\n",
    ").mark_line(strokeDash=[2,4]).encode(\n",
    "    alt.X('date:T'),\n",
    "    alt.Y(\"acc_prec\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    snowpillow_and_precip_chart &\n",
    "    (measurements_chart + models_chart)\n",
    ").interactive().display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2023-03-01\"\n",
    "end_date = \"2023-03-05\"\n",
    "meas_chart = alt.Chart(\n",
    "    tidy_df_30Min.set_index('time').loc[start_date:end_date].reset_index().query(\"variable == 'w_h2o__3m_c'\")\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\")\n",
    "\n",
    ")\n",
    "model_chart = alt.Chart(\n",
    "    model_df[model_df.config == 'MO Holtslag de Bruin andreas lengths Tsurf_c e_sat_alduchov 1e-05'].set_index('time').loc[start_date:end_date].reset_index()\n",
    ").mark_line(color='red').encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"latent heat flux:Q\")\n",
    ")\n",
    "\n",
    "(meas_chart + model_chart).properties(width = 600).display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
