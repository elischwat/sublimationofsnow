{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open SOS Measurement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '20221130'\n",
    "end_date = '20230509'\n",
    "# open files\n",
    "tidy_df_5Min = pd.read_parquet('../sos/tidy_df_20221130_20230517_noplanar_fit.parquet')\n",
    "tidy_df_30Min = pd.read_parquet('../sos/tidy_df_30Min_20221130_20230517_noplanar_fit.parquet')\n",
    "# convert time column to datetime\n",
    "tidy_df_5Min['time'] = pd.to_datetime(tidy_df_5Min['time'])\n",
    "tidy_df_30Min['time'] = pd.to_datetime(tidy_df_30Min['time'])\n",
    "# limit data to our dates of interest, based on continuous snow cover at Kettle Ponds\n",
    "tidy_df_5Min = tidy_df_5Min.set_index('time').sort_index().loc[start_date:end_date].reset_index()\n",
    "tidy_df_30Min = tidy_df_30Min.set_index('time').sort_index().loc[start_date:end_date].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick way to get variable info if we want it \n",
    "# import xarray as xr\n",
    "# ds = xr.open_dataset(\"/storage/elilouis/sublimationofsnow/sosnoqc/isfs_20221228.nc\")\n",
    "# ds['SWE_p2_c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: remove all LH flux data points with less than 90% of 20hz data being good\n",
    "### Step 2: remove all LH flux data points with magnitude greater than 1 g/m^2/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_lhflux_and_counts_variables = [\n",
    "    ('w_h2o__2m_c', 'counts_2m_c_1'), \n",
    "    ('w_h2o__3m_c', 'counts_3m_c_1'), \n",
    "    ('w_h2o__5m_c', 'counts_5m_c_1'), \n",
    "    ('w_h2o__10m_c', 'counts_10m_c_1'), \n",
    "    ('w_h2o__15m_c', 'counts_15m_c_1'), \n",
    "    ('w_h2o__20m_c', 'counts_20m_c_1'), \n",
    "\n",
    "\n",
    "    ('w_h2o__1m_d', 'counts_1m_d_1'), \n",
    "    ('w_h2o__3m_d', 'counts_3m_d_1'), \n",
    "    ('w_h2o__10m_d', 'counts_10m_d_1'), \n",
    "      \n",
    "    ('w_h2o__1m_ue', 'counts_1m_ue_1'), \n",
    "    ('w_h2o__3m_ue', 'counts_3m_ue_1'), \n",
    "    ('w_h2o__10m_ue', 'counts_10m_ue_1'), \n",
    "\n",
    "\n",
    "    ('w_h2o__1m_uw',  'counts_1m_uw_1'), \n",
    "    ('w_h2o__3m_uw', 'counts_3m_uw_1'), \n",
    "    ('w_h2o__10m_uw', 'counts_10m_uw_1'), \n",
    "]\n",
    "ec_lhflux_variables = list(zip(*ec_lhflux_and_counts_variables))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005835441437612257, 2.7197135781121715, -123.26387023925781, 2131.2578125)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "all_lhflux_measurements.mean(), all_lhflux_measurements.std(), all_lhflux_measurements.min(), all_lhflux_measurements.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Remove all data points at once - perform both steps 1 and 2 simultaneously\n",
    "####################################################################################\n",
    "# for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "#     print(flux_var, counts_var)\n",
    "#     counts_src = tidy_df_5Min[tidy_df_5Min.variable == counts_var]\n",
    "#     times_with_good_data_50percent = counts_src[counts_src.value >= 5400].time\n",
    "#     n_before_dropping = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "#     tidy_df_5Min.loc[\n",
    "#         (~tidy_df_5Min['time'].isin(times_with_good_data_50percent)) &\n",
    "#         (tidy_df_5Min['variable'] == flux_var),\n",
    "#         'value'\n",
    "#     ] = np.nan\n",
    "#     n_after_step_1 = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "\n",
    "#     variable_src = tidy_df_5Min[tidy_df_5Min.variable == flux_var]\n",
    "#     times_with_outofbounds_values = variable_src[np.abs(variable_src.value) > 1].time\n",
    "#     tidy_df_5Min.loc[\n",
    "#         (tidy_df_5Min['time'].isin(times_with_outofbounds_values)) & \n",
    "#         (tidy_df_5Min['variable'] == flux_var),\n",
    "#         'value'\n",
    "#     ] = np.nan\n",
    "#     n_after_step_2 = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "#     print(n_before_dropping, n_after_step_1, n_after_step_2)\n",
    "#     print(round((n_before_dropping-n_after_step_2)/n_before_dropping, 3))\n",
    "\n",
    "####################################################################################\n",
    "# Perform steps 1 and 2 separately \n",
    "####################################################################################\n",
    "for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "    counts_src = tidy_df_5Min[tidy_df_5Min.variable == counts_var]\n",
    "    times_with_good_data_50percent = counts_src[counts_src.value >= 5400].time\n",
    "    tidy_df_5Min.loc[\n",
    "        (~tidy_df_5Min['time'].isin(times_with_good_data_50percent)) &\n",
    "        (tidy_df_5Min['variable'] == flux_var),\n",
    "        'value'\n",
    "    ] = np.nan\n",
    "\n",
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "mean = all_lhflux_measurements.mean() \n",
    "stddev = all_lhflux_measurements.std()\n",
    "print(mean, stddev, all_lhflux_measurements.min(), all_lhflux_measurements.max())\n",
    "\n",
    "for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "    variable_src = tidy_df_5Min[tidy_df_5Min.variable == flux_var]\n",
    "    times_with_outofbounds_values = variable_src[\n",
    "        ((variable_src.value) > (mean + 5*stddev)) |\n",
    "        ((variable_src.value) < (mean - 5*stddev))\n",
    "    ].time\n",
    "    tidy_df_5Min.loc[\n",
    "        (tidy_df_5Min['time'].isin(times_with_outofbounds_values)) & \n",
    "        (tidy_df_5Min['variable'] == flux_var),\n",
    "        'value'\n",
    "    ] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002559840776554578 0.018658400299491427 -8.453908920288086 4.933438777923584\n"
     ]
    }
   ],
   "source": [
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "print(all_lhflux_measurements.mean(), all_lhflux_measurements.std(), all_lhflux_measurements.min(), all_lhflux_measurements.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset labeled by blowing snow/not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blowing_snow_data = tidy_df_5Min[\n",
    "    tidy_df_5Min.time.isin(\n",
    "        tidy_df_5Min[tidy_df_5Min.variable.isin(['SF_avg_1m_ue', 'SF_avg_2m_ue'])].query(\n",
    "            f\"value > 0\"\n",
    "        ).time\n",
    "    )\n",
    "]\n",
    "calm_data = tidy_df_5Min[\n",
    "    ~ tidy_df_5Min.time.isin(\n",
    "        tidy_df_5Min[tidy_df_5Min.variable.isin(['SF_avg_1m_ue', 'SF_avg_2m_ue'])].query(f\"value > 0\").time\n",
    "    )\n",
    "]\n",
    "\n",
    "tidy_5min_by_blowing_df = pd.concat([\n",
    "    blowing_snow_data.assign(type = 'blowing snow'),\n",
    "    calm_data.assign(type = 'clear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_5min_by_blowing_lh_flux_df = tidy_5min_by_blowing_df[\n",
    "    tidy_5min_by_blowing_df[\"variable\"].isin(['w_h2o__3m_c', 'spd_3m_c', 'Rsw_in_9m_d', 'Rnet_9m_d', 'T_3m_c', 'tke_3m_c'])\n",
    "]\n",
    "tidy_5min_by_blowing_lh_flux_df = tidy_5min_by_blowing_lh_flux_df.pivot_table(\n",
    "    index=['time','type'],\n",
    "    values='value',\n",
    "    columns='variable'\n",
    ").reset_index()\n",
    "\n",
    "# add convenience time columns\n",
    "tidy_5min_by_blowing_lh_flux_df['time_no_date'] = tidy_5min_by_blowing_lh_flux_df['time'].apply(\n",
    "    lambda x: x.replace(year=2023, month=1, day=1)\n",
    ")\n",
    "tidy_5min_by_blowing_lh_flux_df['month'] = tidy_5min_by_blowing_lh_flux_df['time'].dt.month\n",
    "tidy_5min_by_blowing_lh_flux_df['date'] = tidy_5min_by_blowing_lh_flux_df['time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31155/1869653647.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  src = tidy_5min_by_blowing_lh_flux_df.groupby([\"time_no_date\", \"month\", \"type\"]).mean().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4ee0a6189c004bb9b196faec65acb8b4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4ee0a6189c004bb9b196faec65acb8b4.vega-embed details,\n",
       "  #altair-viz-4ee0a6189c004bb9b196faec65acb8b4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4ee0a6189c004bb9b196faec65acb8b4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4ee0a6189c004bb9b196faec65acb8b4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4ee0a6189c004bb9b196faec65acb8b4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"url\": \"altair-data-99c41fe703ecf7fee6e27bad0416cbf3.json\", \"format\": {\"type\": \"json\"}}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"month\", \"scale\": {\"scheme\": \"turbo\"}, \"sort\": [12, 1, 2, 3, 4, 5], \"type\": \"ordinal\"}, \"row\": {\"field\": \"type\", \"title\": null, \"type\": \"nominal\"}, \"x\": {\"field\": \"time_no_date\", \"title\": \"Time of day\", \"type\": \"temporal\"}, \"y\": {\"field\": \"rolling_mean\", \"title\": [\"LH Flux (g/m^2/s)\", \"(1 hour rolling avg)\"], \"type\": \"quantitative\"}}, \"height\": 150, \"title\": [\"Daily average LH fluxes during each month,\", \"separated by blowing snow and calm conditions\"], \"transform\": [{\"filter\": \"((datum.month !== 11) && (datum.month !== 5))\"}, {\"window\": [{\"op\": \"mean\", \"field\": \"w_h2o__3m_c\", \"as\": \"rolling_mean\"}], \"frame\": [-6, 6], \"groupby\": [\"month\", \"type\"]}], \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\"}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = tidy_5min_by_blowing_lh_flux_df.groupby([\"time_no_date\", \"month\", \"type\"]).mean().reset_index()\n",
    "\n",
    "alt.Chart(src).transform_filter(\n",
    "    (alt.datum.month != 11) & (alt.datum.month != 5)\n",
    ").transform_window(\n",
    "    frame = [-6, 6],\n",
    "    rolling_mean = \"mean(w_h2o__3m_c)\",\n",
    "    groupby = ['month', 'type']\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time_no_date:T\", title='Time of day'),\n",
    "    alt.Y(\"rolling_mean:Q\", title=['LH Flux (g/m^2/s)','(1 hour rolling avg)']),\n",
    "    alt.Color(\"month:O\", sort=[12,1,2,3,4,5]).scale(scheme='turbo'),\n",
    "    alt.Row(\"type:N\", title=None)\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=150,\n",
    "    title=['Daily average LH fluxes during each month,','separated by blowing snow and calm conditions']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
