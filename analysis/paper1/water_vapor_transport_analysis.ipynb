{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sublimpy import utils, tidy\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "from scipy import interpolate\n",
    "\n",
    "import swifter\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from metpy.units import units\n",
    "\n",
    "import datetime as dt\n",
    "from sklearn.metrics import r2_score\n",
    "from metpy.units import units\n",
    "import math \n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tidy_df_20221101_20230619_planar_fit_multiplane_STRAIGHTUP_q7_flags9000_ARCHIVE.parquet\n"
     ]
    }
   ],
   "source": [
    "ls process_slow_data | grep parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHTS = [1,3,10]\n",
    "HORIZ_GRID_SPACING = 50\n",
    "VERT_GRID_SPACING = 20\n",
    "# start_date = '20221130'\n",
    "# end_date = '20230509'\n",
    "start_date = '20221101'\n",
    "end_date = '20230619'\n",
    "\n",
    "# data_start_date = '20221130'\n",
    "# data_cutoff_date = '20230508'\n",
    "\n",
    "data_start_date = '20221107'\n",
    "data_cutoff_date = '20230619'\n",
    "\n",
    "## PARAMETERS FOR SOS DATA\n",
    "# streamwise coordinates\n",
    "sos_tidy_fn = f\"process_slow_data/tidy_df_20221101_20230619_planar_fit_multiplane_STRAIGHTUP_q7_flags9000_10sectors.parquet\"\n",
    "\n",
    "## PARAMETERS FOR SPLASH DATA\n",
    "# download dir\n",
    "avp_download_dir = \"/Users/elischwat/Development/data/sublimationofsnow/asfs/ASFS-50_Level2_SPLASH2021-2023/\"\n",
    "kps_download_dir = \"/Users/elischwat/Development/data/sublimationofsnow/asfs/ASFS-30_Level2_SPLASH2021-2023/\"\n",
    "\n",
    "ftp_url = 'ftp1.esrl.noaa.gov'\n",
    "# Avery Picnic product\n",
    "avp_url = f'Observations/Campaigns/SPLASH/asfs50/2_level_ingest/'\n",
    "# Kettle Ponds product\n",
    "kps_url = f'Observations/Campaigns/SPLASH/asfs30/2_level_ingest/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = pd.read_parquet(sos_tidy_fn)\n",
    "\n",
    "# Convert data timezone to local and clean up data on the ends\n",
    "# convert time column to datetime\n",
    "tidy_df['time'] = pd.to_datetime(tidy_df['time'])\n",
    "tidy_df = utils.modify_df_timezone(tidy_df, 'UTC', 'US/Mountain')\n",
    "# limit data to our dates of interest, based on continuous snow cover at Kettle Ponds\n",
    "tidy_df = tidy_df[tidy_df.time > data_start_date][tidy_df.time < data_cutoff_date]\n",
    "tidy_df = tidy_df.set_index('time').sort_index().loc[data_start_date:data_cutoff_date].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tidy_df.query(\"variable == 'T_3m_c'\").set_index('time').loc['20230301':'20230401']))\n",
    "print(len(tidy_df.query(\"variable == 'T_3m_c'\").set_index('time').loc['20230301':'20230401'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tidy_df.query(\"variable == 'T_3m_c'\").set_index('time').loc['20230401':'20230501']))\n",
    "print(len(tidy_df.query(\"variable == 'T_3m_c'\").set_index('time').loc['20230401':'20230501'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df.query(f\"variable == 'dir_3m_c'\")['value'].dropna()\n",
    "pd.cut(\n",
    "    src,\n",
    "    [0,80, 140, 292,332, 360]\n",
    ").value_counts() / len(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the list of files in the directory\n",
    "file_list = os.listdir(kps_download_dir)\n",
    "\n",
    "# file_list = [f for f in file_list if 'sledmet.asfs30.level2.0.1min.' in f]\n",
    "file_list = [f for f in file_list if 'sledmet.asfs30.level2.0.1min.' in f]\n",
    "\n",
    "# Sort the file list\n",
    "file_list.sort()\n",
    "\n",
    "# Create an empty list to store the dataarrays\n",
    "mixingratio_dataarray_list = []\n",
    "abshum_dataarray_list = []\n",
    "snowdepth_list = []\n",
    "temp_dataarray_list = []\n",
    "rh_dataarray_list = []\n",
    "w_dataarray_list = []\n",
    "\n",
    "# Iterate over each file with tqdm\n",
    "for file_name in tqdm.tqdm(file_list):\n",
    "    # Open the file using xarray\n",
    "    dataset = xr.open_dataset(os.path.join(kps_download_dir, file_name))\n",
    "    \n",
    "    # Extract the dataarray for the variable 'mixing_ratio', Add the dataarray to the list\n",
    "    mixingratio_dataarray_list.append(dataset['mixing_ratio'])\n",
    "    abshum_dataarray_list.append(dataset['h2o_licor'])\n",
    "    snowdepth_list.append(dataset['snow_depth'])\n",
    "    temp_dataarray_list.append(dataset['temp'])  # Add this line\n",
    "    rh_dataarray_list.append(dataset['rh'])  # Add this line\n",
    "    w_dataarray_list.append(dataset['wspd_w_mean'])  # Add this line\n",
    "\n",
    "mixingratio_ds = xr.concat(mixingratio_dataarray_list, dim='time')\n",
    "mixingratio_ds = utils.modify_xarray_timezone(mixingratio_ds, 'UTC', 'US/Mountain')\n",
    "abshum_ds = xr.concat(abshum_dataarray_list, dim='time')\n",
    "abshum_ds = utils.modify_xarray_timezone(abshum_ds, 'UTC', 'US/Mountain')\n",
    "annex_snowdepth_ds = xr.concat(snowdepth_list, dim='time')\n",
    "annex_snowdepth_ds = utils.modify_xarray_timezone(annex_snowdepth_ds, 'UTC', 'US/Mountain')\n",
    "temp_ds = xr.concat(temp_dataarray_list, dim='time')\n",
    "temp_ds = utils.modify_xarray_timezone(temp_ds, 'UTC', 'US/Mountain')\n",
    "rh_ds = xr.concat(rh_dataarray_list, dim='time')\n",
    "rh_ds = utils.modify_xarray_timezone(rh_ds, 'UTC', 'US/Mountain')\n",
    "w_ds = xr.concat(w_dataarray_list, dim='time')\n",
    "w_ds = utils.modify_xarray_timezone(w_ds, 'UTC', 'US/Mountain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify lists of timestamps for different categories\n",
    "bs_times = set(\n",
    "    tidy_df.query(\"variable == 'SF_avg_1m_ue'\").query(\"value > 0\").time\n",
    ").union(\n",
    "    set(tidy_df.query(\"variable == 'SF_avg_2m_ue'\").query(\"value > 0\").time)\n",
    ")\n",
    "nobs_times = set(tidy_df.time).difference(bs_times)\n",
    "\n",
    "decoupled_times = tidy_df.query(\"variable == 'omega_3m_c'\").query(\"value < 0.43\").time\n",
    "weaklycoupled_times = tidy_df.query(\"variable == 'omega_3m_c'\").query(\"value >= 0.43\").query(\"value <= 0.61\").time\n",
    "coupled_times = tidy_df.query(\"variable == 'omega_3m_c'\").query(\"value > 0.61\").time\n",
    "\n",
    "ri_stable_times = tidy_df.query(\"variable == 'Ri_3m_c'\").query(\"value > 0.25\").time\n",
    "ri_unstable_times = tidy_df.query(\"variable == 'Ri_3m_c'\").query(\"value < -0.01\").time\n",
    "ri_neutral_times = tidy_df.query(\"variable == 'Ri_3m_c'\").query(\"value >= -0.01\").query(\"value <= 0.25\").time\n",
    "\n",
    "tgrad_stable_times = tidy_df.query(\"variable == 'temp_gradient_3m_c'\").query(\"value > 0.01\").time\n",
    "tgrad_unstable_times = tidy_df.query(\"variable == 'temp_gradient_3m_c'\").query(\"value < -0.01\").time\n",
    "tgrad_neutral_times = tidy_df.query(\"variable == 'temp_gradient_3m_c'\").query(\"value >= -0.01\").query(\"value <= 0.01\").time\n",
    "\n",
    "upvalley_wind_times = tidy_df[tidy_df.variable == 'dir_3m_c'].query(\"value < 152\").query(\"value > 92\").time.values\n",
    "downvalley_wind_times = tidy_df[tidy_df.variable == 'dir_3m_c'].query(\"value < 342\").query(\"value > 292\").time.values\n",
    "\n",
    "len(upvalley_wind_times),len(downvalley_wind_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ri_stable_times))\n",
    "print(len(ri_unstable_times))\n",
    "print(len(ri_neutral_times))\n",
    "print(len(tgrad_stable_times))\n",
    "print(len(tgrad_unstable_times))\n",
    "print(len(tgrad_neutral_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_annex_df = mixingratio_ds.to_dataframe()[['mixing_ratio']].rename(columns={'mixing_ratio': 'mixing_ratio_annex'}) / 1000\n",
    "s_kps_df_4m = tidy_df.query(\"variable == 'mixingratio_4m_c'\")[['time', 'value']].set_index('time').rename(columns={'value': 'mixing_ratio_kps_4m'})\n",
    "s_kps_df_3m = tidy_df.query(\"variable == 'mixingratio_3m_c'\")[['time', 'value']].set_index('time').rename(columns={'value': 'mixing_ratio_kps_3m'})\n",
    "s_kps_df_2m = tidy_df.query(\"variable == 'mixingratio_2m_c'\")[['time', 'value']].set_index('time').rename(columns={'value': 'mixing_ratio_kps_2m'})\n",
    "s_df = s_kps_df_2m.join(s_kps_df_3m).join(s_kps_df_4m).join(s_annex_df)\n",
    "alt.Chart(\n",
    "    s_df[s_df.index.isin(nobs_times)].reset_index()\n",
    ").transform_fold([\n",
    "    'mixing_ratio_kps_2m', 'mixing_ratio_kps_3m', 'mixing_ratio_kps_4m', 'mixing_ratio_annex'\n",
    "]).mark_line().encode(\n",
    "    alt.X('hours(time):T'),\n",
    "    alt.Y('mean(value):Q').scale(zero=False),\n",
    "    alt.Facet('month(time):T').sort(['Nov', 'Dec']),\n",
    "    alt.Color('key:N')\n",
    ").resolve_scale(y='independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate SOS gas analyzer measurements\n",
    "\n",
    "We calibrate by assuming that all gas analyzers have the same seasonal mean as the corresponding hygrometer measurement on the central tower (at a given height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With seasonal mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hygrometer_absolute_humidity_mean = (\n",
    "    1000 * tidy_df[tidy_df.measurement=='specific humidity'].groupby(['tower', 'height'])[['value']].mean() *\\\n",
    "    tidy_df[tidy_df.measurement=='air density'].groupby(['tower', 'height'])[['value']].mean()\n",
    ").reset_index().query(\"tower == 'c'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_absolute_humidity_mean = tidy_df[tidy_df.measurement=='Water vapor density'].groupby(['variable', 'tower', 'height'])[['value']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_df = ec_absolute_humidity_mean.merge(\n",
    "    hygrometer_absolute_humidity_mean[['height', 'value']].rename(columns={'value': 'truth'}),\n",
    "    on='height'\n",
    ")\n",
    "corrections_df['offset'] = corrections_df['value'] - corrections_df['truth']\n",
    "corrections_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update dataset with corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[tidy_df.measurement=='Water vapor density']\n",
    "src = src[src.height.isin([1,3,10])]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    (\n",
    "    1000 * tidy_df[tidy_df.measurement=='specific humidity'].groupby(['tower', 'height'])[['value']].mean() *\\\n",
    "    tidy_df[tidy_df.measurement=='air density'].groupby(['tower', 'height'])[['value']].mean()\n",
    "    ).reset_index()\n",
    ").mark_point(shape='square', filled=True, color='black', size=20).encode(\n",
    "    alt.X(\"value:Q\"),\n",
    "    alt.Y(\"height:Q\")\n",
    ").properties(width=150, height = 150)\\\n",
    "+ alt.Chart(\n",
    "    tidy_df[tidy_df.measurement=='Water vapor density'].groupby(['variable', 'tower', 'height'])[['value']].mean().reset_index()\n",
    ").mark_circle(size=40).encode(\n",
    "    alt.X(\"value:Q\"),\n",
    "    alt.Y(\"height:Q\"),\n",
    "    alt.Color('tower:N')\n",
    ").properties(width=150, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "alt.Chart(\n",
    "    src[ src.time > '20221212' ][ src.time < '20221214' ]\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\"),\n",
    "    alt.Color(\"height:N\"),\n",
    "    detail='variable'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in corrections_df.iterrows():\n",
    "    src = tidy_df.query(f\"variable == '{row['variable']}'\")\n",
    "    src = src.assign(value = src.value - row['offset'])\n",
    "    tidy_df = tidy_df[tidy_df.variable != row['variable']]\n",
    "    tidy_df = pd.concat([tidy_df, src])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    (\n",
    "    1000 * tidy_df[tidy_df.measurement=='specific humidity'].groupby(['tower', 'height'])[['value']].mean() *\\\n",
    "    tidy_df[tidy_df.measurement=='air density'].groupby(['tower', 'height'])[['value']].mean()\n",
    "    ).reset_index()\n",
    ").mark_point(shape='square', filled=True, color='black', size=20).encode(\n",
    "    alt.X(\"value:Q\"),\n",
    "    alt.Y(\"height:Q\")\n",
    ").properties(width=150, height = 150)\\\n",
    "+ alt.Chart(\n",
    "    tidy_df[tidy_df.measurement=='Water vapor density'].groupby(['variable', 'tower', 'height'])[['value']].mean().reset_index()\n",
    ").mark_circle(size=40).encode(\n",
    "    alt.X(\"value:Q\"),\n",
    "    alt.Y(\"height:Q\"),\n",
    "    alt.Color('tower:N')\n",
    ").properties(width=150, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[tidy_df.measurement=='Water vapor density']\n",
    "src = src[src.height.isin([1,3,10])]\n",
    "abs_hum = alt.Chart(\n",
    "    src[ src.time > '20221212' ][ src.time < '20221214' ]\n",
    ").mark_line(strokeWidth=0.5).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").title(\"Absolute humidity (g/m^3)\").scale(zero=False),\n",
    "    alt.Color(\"height:N\"),\n",
    "    alt.Shape('tower:N'),\n",
    "    detail='variable'\n",
    ").properties(width=600)\n",
    "\n",
    "src = tidy_df[tidy_df.measurement=='snow depth']\n",
    "snowdepth = alt.Chart(\n",
    "    src[ src.time > '20221212' ][ src.time < '20221214' ]\n",
    ").mark_line(strokeWidth=0.5).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").title(\"Snow depth (m)\"),\n",
    "    alt.Shape('tower:N'),\n",
    "    detail='variable'\n",
    ").properties(width=600, height=150)\n",
    "\n",
    "(snowdepth & abs_hum).resolve_scale(color='independent', shape='independent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With monthly means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_spechumidity = tidy_df[tidy_df.measurement=='specific humidity']\n",
    "# hygrometer_absolute_humidity_mean = (\n",
    "#     1000 * filtered_spechumidity.groupby(['tower', 'height', filtered_spechumidity.time.dt.month])[['value']].mean() *\\\n",
    "#     tidy_df[tidy_df.measurement=='air density'].groupby(['tower', 'height'])[['value']].mean()\n",
    "# ).reset_index().query(\"tower == 'c'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_abshumidity = tidy_df[tidy_df.measurement=='Water vapor density']\n",
    "# ec_absolute_humidity_mean = filtered_abshumidity.groupby([\n",
    "#     'variable', 'tower', 'height', filtered_abshumidity.time.dt.month\n",
    "# ])[['value']].mean().reset_index()\n",
    "# ec_absolute_humidity_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrections_df = ec_absolute_humidity_mean.merge(\n",
    "#     hygrometer_absolute_humidity_mean[['height', 'value', 'time', 'tower']].rename(columns={'value': 'truth'}),\n",
    "#     on=['height', 'tower', 'time']\n",
    "# )\n",
    "# corrections_df['offset'] = corrections_df['value'] - corrections_df['truth']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update dataset with corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected_measurements = []\n",
    "# for variable in corrections_df.variable.unique():\n",
    "#     for month in corrections_df[corrections_df.variable == variable].time.unique():\n",
    "#         src = tidy_df.query(f\"variable == '{variable}'\")\n",
    "#         src = src[src.time.dt.month == month]\n",
    "#         row = corrections_df.set_index(['variable', 'time']).loc[variable, month]\n",
    "#         src = src.assign(value = src.value - row['offset'])\n",
    "#         corrected_measurements.append(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for variable in corrections_df.variable.unique():\n",
    "#     tidy_df = tidy_df[tidy_df.variable != variable]\n",
    "# tidy_df = pd.concat([tidy_df] + corrected_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hygr_vals = (\n",
    "#     1000 * tidy_df[tidy_df.measurement=='specific humidity'].groupby(['tower', 'height'])[['value']].mean() *\\\n",
    "#     tidy_df[tidy_df.measurement=='air density'].groupby(['tower', 'height'])[['value']].mean()\n",
    "#     ).reset_index()\n",
    "# irga_vals = tidy_df[tidy_df.measurement=='Water vapor density'].groupby(['variable', 'tower', 'height'])[['value']].mean().reset_index()\n",
    "# # hygr_vals = hygr_vals[hygr_vals.time.dt.month==12]\n",
    "# # irga_vals = irga_vals[irga_vals.time.dt.month==12]\n",
    "# alt.Chart(hygr_vals).mark_point(shape='square', filled=True, color='black', size=20).encode(\n",
    "#     alt.X(\"value:Q\"),\n",
    "#     alt.Y(\"height:Q\")\n",
    "# ).properties(width=150, height = 150)\\\n",
    "# + alt.Chart(irga_vals).mark_circle(size=40).encode(\n",
    "#     alt.X(\"value:Q\"),\n",
    "#     alt.Y(\"height:Q\"),\n",
    "#     alt.Color('tower:N')\n",
    "# ).properties(width=150, height = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument location info (georeferenced)\n",
    "We use a file with theodolite/GPS readings provided by NCAR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_loc_df = pd.read_csv(\"~/Development/data/sublimationofsnow/SOSm.txt\", names = ['ec', 'x', 'y', 'z'])\n",
    "instrument_loc_df = instrument_loc_df[ \n",
    "    instrument_loc_df['ec'].str.startswith('CS')\n",
    "    |\n",
    "    instrument_loc_df['ec'].str.startswith('DS') \n",
    "    |\n",
    "    instrument_loc_df['ec'].str.startswith('UWS') \n",
    "    |\n",
    "    instrument_loc_df['ec'].str.startswith('UES') \n",
    "]\n",
    "instrument_loc_df = instrument_loc_df[ \n",
    "    instrument_loc_df['ec'].str.endswith('T') \n",
    "    |\n",
    "    instrument_loc_df['ec'].str.endswith('B') \n",
    "]\n",
    "instrument_loc_df['top or bottom'] = instrument_loc_df['ec'].str[-1]\n",
    "instrument_loc_df['tower'] = instrument_loc_df['ec'].apply(lambda str: str.split('S')[0].lower())\n",
    "instrument_loc_df['height'] = instrument_loc_df['ec'].apply(lambda str: int(str.split('S')[1][:-1]))\n",
    "instrument_loc_df = instrument_loc_df.drop(columns='ec')\n",
    "instrument_loc_df = instrument_loc_df.pivot(index=['height', 'tower'], columns='top or bottom').reset_index()\n",
    "instrument_loc_df = instrument_loc_df.set_index(['height', 'tower']).groupby(level=0, axis=1).mean()\n",
    "instrument_loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we want to, we can convert instrument locations to streamwise coordinates too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for height in [1,2,3,5,10,15,20]:\n",
    "#     instrument_loc_df.loc[(height,'c'), 'z'] = height\n",
    "#     instrument_loc_df.loc[(height,'d'), 'z'] = height\n",
    "#     instrument_loc_df.loc[(height,'ue'), 'z'] = height\n",
    "#     instrument_loc_df.loc[(height,'uw'), 'z'] = height\n",
    "# instrument_loc_df = instrument_loc_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind field measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_field_df = tidy_df[tidy_df.measurement.isin(['u','v','w']) & tidy_df.height.isin(HEIGHTS)]\n",
    "wind_field_df = wind_field_df.pivot_table(index='time', columns=['height', 'tower', 'measurement'], values='value')\n",
    "wind_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbulent water vapor flux measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_flux_field_df = tidy_df[tidy_df.measurement.isin(['u_h2o_','v_h2o_','w_h2o_']) & tidy_df.height.isin(HEIGHTS)]\n",
    "turb_flux_field_df = turb_flux_field_df.pivot_table(index='time', columns=['height', 'tower', 'measurement'], values='value')\n",
    "turb_flux_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbulent temperature flux measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_turb_flux_field_df = tidy_df[tidy_df.measurement.isin(['u_tc_','v_tc_','w_tc_']) & tidy_df.height.isin(HEIGHTS)]\n",
    "temp_turb_flux_field_df = temp_turb_flux_field_df.pivot_table(index='time', columns=['height', 'tower', 'measurement'], values='value'), \n",
    "temp_turb_flux_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Humidity measurements (from Irgas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_hum_field_df = tidy_df[tidy_df.measurement.isin(['Water vapor density']) & tidy_df.height.isin(HEIGHTS)]\n",
    "abs_hum_field_df.measurement = 'q'\n",
    "abs_hum_field_df = abs_hum_field_df.pivot_table(\n",
    "        index='time', columns=['height', 'tower', 'measurement'], values='value'\n",
    "    )\n",
    "abs_hum_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advective flux measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for h in wind_field_df.columns.get_level_values('height').unique():\n",
    "    for t in wind_field_df.columns.get_level_values('tower').unique():\n",
    "        this_wind_df = wind_field_df[(h,t)].copy()\n",
    "        this_abs_hum_df = abs_hum_field_df[(h,t)].copy()  \n",
    "        this_wind_df['uq'] = this_wind_df['u']*this_abs_hum_df['q']\n",
    "        this_wind_df['vq'] = this_wind_df['v']*this_abs_hum_df['q']\n",
    "        this_wind_df['wq'] = this_wind_df['w']*this_abs_hum_df['q']\n",
    "        new = pd.concat([this_wind_df], axis=1, keys=[(h,t)])\n",
    "        ls.append(new.drop(columns=[(h,t,'u'),(h,t,'v'),(h,t,'w')]))\n",
    "\n",
    "adv_flux_field_df = ls[0]\n",
    "for l in ls[1:]:\n",
    "    adv_flux_field_df = adv_flux_field_df.join(l)\n",
    "adv_flux_field_df.columns = adv_flux_field_df.columns.set_names('height', level=0)\n",
    "adv_flux_field_df.columns = adv_flux_field_df.columns.set_names('tower', level=1)\n",
    "adv_flux_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dry air density measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather dry air density measurements\n",
    "dryair_density_field_df = tidy_df[tidy_df.measurement.isin(['dry air density']) & tidy_df.height.isin(HEIGHTS)]\n",
    "dryair_density_field_df.measurement = 'rho'\n",
    "dryair_density_field_df = dryair_density_field_df.pivot_table(\n",
    "        index='time', columns=['height', 'tower', 'measurement'], values='value'\n",
    "    )\n",
    "\n",
    "# duplicate the dry air density measurements across the towers (THIS IS NAIVE)\n",
    "dryair_density_for_tower_d = dryair_density_field_df.copy()\n",
    "dryair_density_for_tower_d.columns = pd.MultiIndex.from_tuples([(cs[0], 'd', cs[2]) for cs in dryair_density_for_tower_d.columns])\n",
    "\n",
    "dryair_density_for_tower_uw = dryair_density_field_df.copy()\n",
    "dryair_density_for_tower_uw.columns = pd.MultiIndex.from_tuples([(cs[0], 'uw', cs[2]) for cs in dryair_density_for_tower_d.columns])\n",
    "\n",
    "dryair_density_for_tower_ue = dryair_density_field_df.copy()\n",
    "dryair_density_for_tower_ue.columns = pd.MultiIndex.from_tuples([(cs[0], 'ue', cs[2]) for cs in dryair_density_for_tower_d.columns])\n",
    "\n",
    "dryair_density_field_df = dryair_density_field_df.join(\n",
    "    dryair_density_for_tower_d\n",
    ").join(\n",
    "    dryair_density_for_tower_ue\n",
    ").join(\n",
    "    dryair_density_for_tower_uw\n",
    ")\n",
    "\n",
    "dryair_density_field_df.columns = dryair_density_field_df.columns.set_names(['height', 'tower', 'measurement'])\n",
    "\n",
    "# convert from kg/m^3 to g/m^3\n",
    "dryair_density_field_df = dryair_density_field_df*1000\n",
    "\n",
    "dryair_density_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather dry air density measurements\n",
    "temp_field_df = tidy_df[tidy_df.measurement.isin(['temperature']) & tidy_df.height.isin(HEIGHTS)]\n",
    "temp_field_df.measurement = 'T'\n",
    "temp_field_df = temp_field_df.pivot_table(\n",
    "        index='time', columns=['height', 'tower', 'measurement'], values='value'\n",
    "    )\n",
    "\n",
    "# duplicate the dry air density measurements across the towers (THIS IS NAIVE)\n",
    "temp_for_tower_d = temp_field_df.copy()\n",
    "temp_for_tower_d.columns = pd.MultiIndex.from_tuples([(cs[0], 'd', cs[2]) for cs in temp_for_tower_d.columns])\n",
    "\n",
    "temp_for_tower_uw = temp_field_df.copy()\n",
    "temp_for_tower_uw.columns = pd.MultiIndex.from_tuples([(cs[0], 'uw', cs[2]) for cs in temp_for_tower_d.columns])\n",
    "\n",
    "temp_for_tower_ue = temp_field_df.copy()\n",
    "temp_for_tower_ue.columns = pd.MultiIndex.from_tuples([(cs[0], 'ue', cs[2]) for cs in temp_for_tower_d.columns])\n",
    "\n",
    "temp_field_df = temp_field_df.join(\n",
    "    temp_for_tower_d\n",
    ").join(\n",
    "    temp_for_tower_ue\n",
    ").join(\n",
    "    temp_for_tower_uw\n",
    ")\n",
    "\n",
    "temp_field_df.columns = temp_field_df.columns.set_names(['height', 'tower', 'measurement'])\n",
    "\n",
    "temp_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing ratio measurements (from Irgas and other sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing_ratio_field_df = abs_hum_field_df.droplevel(2, 1) / dryair_density_field_df.droplevel(2, 1)\n",
    "\n",
    "mixing_ratio_field_df.columns = pd.MultiIndex.from_product(mixing_ratio_field_df.columns.levels + [['r']])\n",
    "mixing_ratio_field_df.columns = mixing_ratio_field_df.columns.set_names('measurement', level=2)\n",
    "\n",
    "mixing_ratio_field_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Differential Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate interpolated fields (3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHTS = [3,10]\n",
    "\n",
    "# gather all measurements into a dataframe, isolate to the heights we care about\n",
    "df = wind_field_df.join(\n",
    "    turb_flux_field_df\n",
    ").join(\n",
    "    temp_turb_flux_field_df\n",
    ").join(\n",
    "    abs_hum_field_df\n",
    ").join(\n",
    "    adv_flux_field_df\n",
    ").join(\n",
    "    dryair_density_field_df\n",
    ").join(\n",
    "    temp_field_df\n",
    ").join(\n",
    "    mixing_ratio_field_df\n",
    ")\n",
    "data_df = df[HEIGHTS]\n",
    "\n",
    "# Gather the instrument locations into a dataframe, isolate to heights we care about\n",
    "instrument_loc_limited_heights = instrument_loc_df[instrument_loc_df.index.get_level_values(0).isin(HEIGHTS)]\n",
    "\n",
    "# Transform the dataframe of instrument locations into a form that can be merged with the dataframe of measurements\n",
    "#   transform\n",
    "xxx = pd.DataFrame(instrument_loc_limited_heights.unstack().unstack()).T\n",
    "xxx.columns = xxx.columns.swaplevel(0,2)\n",
    "xxx.columns = xxx.columns.set_names('measurement', level=2)\n",
    "#   duplicate the sensor locations so we can join (duplicate) x,y,z info into the dataframe of measurements\n",
    "instrument_loc_limited_heights_repeated = xxx.loc[xxx.index.repeat(len(data_df))]\n",
    "instrument_loc_limited_heights_repeated.index = data_df.index\n",
    "instrument_loc_limited_heights_repeated\n",
    "data_df = data_df.join(instrument_loc_limited_heights_repeated)\n",
    "\n",
    "# Create a meshgrid for the interpolation and isolate the x,y,z locations of measurements\n",
    "xx, yy, zz = np.meshgrid(\n",
    "    np.linspace(instrument_loc_limited_heights.x.min(), instrument_loc_limited_heights.x.max(), HORIZ_GRID_SPACING),\n",
    "    np.linspace(instrument_loc_limited_heights.y.min(), instrument_loc_limited_heights.y.max(), HORIZ_GRID_SPACING),\n",
    "    np.linspace(instrument_loc_limited_heights.z.min(), instrument_loc_limited_heights.z.max(), VERT_GRID_SPACING)\n",
    ")\n",
    "spacing_x = np.diff(xx[0,:,0]).mean()\n",
    "spacing_y = np.diff(yy[:,0,0]).mean()\n",
    "spacing_z = np.diff(zz[0,0,:]).mean()\n",
    "points = np.transpose(np.vstack((instrument_loc_limited_heights.x, instrument_loc_limited_heights.y, instrument_loc_limited_heights.z)))\n",
    "\n",
    "# Calculate interpolated fields\n",
    "    # VECTOR FIELDS\n",
    "    # wind velocity fields\n",
    "u_interp = data_df.loc[:, (slice(None),slice(None),['u'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "v_interp = data_df.loc[:, (slice(None),slice(None),['v'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "w_interp = data_df.loc[:, (slice(None),slice(None),['w'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "    # turb. flux fields\n",
    "u_q__interp = data_df.loc[:, (slice(None),slice(None),['u_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "v_q__interp = data_df.loc[:, (slice(None),slice(None),['v_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "w_q__interp = data_df.loc[:, (slice(None),slice(None),['w_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "    # SCALAR FIELDS\n",
    "rho_interp = data_df.loc[:, (slice(None),slice(None),['rho'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "r_interp = data_df.loc[:, (slice(None),slice(None),['r'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "q_interp = data_df.loc[:, (slice(None),slice(None),['q'])].apply(\n",
    "    lambda row:  interpolate.griddata(points, row.values, (xx, yy, zz), method='linear'),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT: Example of a 3d interpolated wind field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
    "ax.quiver(\n",
    "    xx[::5,::5,::2], \n",
    "    yy[::5,::5,::2],\n",
    "    zz[::5,::5,::2],\n",
    "    u_interp[100][::5,::5,::2],\n",
    "    v_interp[100][::5,::5,::2], \n",
    "    w_interp[100][::5,::5,::2],\n",
    "    label='interpolated'\n",
    ")\n",
    "# plt.quiver(\n",
    "#     data_df.iloc[100][(slice(None),slice(None),'x')].values.astype('float'),\n",
    "#     data_df.iloc[100][(slice(None),slice(None),'y')].values.astype('float'),\n",
    "#     data_df.iloc[100][(slice(None),slice(None),'z')].values.astype('float'),\n",
    "#     data_df.iloc[100][(slice(None),slice(None),'u')].values.astype('float'),\n",
    "#     data_df.iloc[100][(slice(None),slice(None),'v')].values.astype('float'),\n",
    "#     data_df.iloc[100][(slice(None),slice(None),'w')].values.astype('float'),\n",
    "#     label='measured',\n",
    "#     color='red'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_mean_u_field = np.nanmean(np.stack(u_interp[u_interp.index.isin(ri_stable_times)].values), axis = 0)\n",
    "stable_mean_v_field = np.nanmean(np.stack(v_interp[v_interp.index.isin(ri_stable_times)].values), axis = 0)\n",
    "stable_mean_w_field = np.nanmean(np.stack(w_interp[w_interp.index.isin(ri_stable_times)].values), axis = 0)\n",
    "# 3d plot\n",
    "ax = plt.figure(figsize=(10,10)).add_subplot(projection='3d')\n",
    "ax.quiver(xx[::5,::5,::2],     yy[::5,::5,::2],    zz[::5,::5,::2], stable_mean_u_field[::5,::5,::2], stable_mean_v_field[::5,::5,::2],  stable_mean_w_field[::5,::5,::2],label='interpolated',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2, figsize=(5,7.5), sharex=True, sharey=True)\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "stable_mean_u_field = np.nanmean(np.stack(u_interp[u_interp.index.isin(ri_stable_times)].values), axis = 0)\n",
    "stable_mean_v_field = np.nanmean(np.stack(v_interp[v_interp.index.isin(ri_stable_times)].values), axis = 0)\n",
    "stable_mean_w_field = np.nanmean(np.stack(w_interp[w_interp.index.isin(ri_stable_times)].values), axis = 0)\n",
    "axes[0,0].quiver(\n",
    "    xx[::5,::5,4],  yy[::5,::5,4],\n",
    "    stable_mean_u_field[::5,::5,4], stable_mean_v_field[::5,::5,4], \n",
    ")\n",
    "axes[0,0].set_title('stable, 4.5m')\n",
    "axes[0,1].quiver(\n",
    "    xx[::5,::5,15],  yy[::5,::5,15],\n",
    "    stable_mean_u_field[::5,::5,15], stable_mean_v_field[::5,::5,15], \n",
    ")\n",
    "axes[0,1].set_title('stable, 8m')\n",
    "\n",
    "unstable_mean_u_field = np.nanmean(np.stack(u_interp[u_interp.index.isin(ri_unstable_times)].values), axis = 0)\n",
    "unstable_mean_v_field = np.nanmean(np.stack(v_interp[v_interp.index.isin(ri_unstable_times)].values), axis = 0)\n",
    "unstable_mean_w_field = np.nanmean(np.stack(w_interp[w_interp.index.isin(ri_unstable_times)].values), axis = 0)\n",
    "axes[1,0].quiver(\n",
    "    xx[::5,::5,4],  yy[::5,::5,4],\n",
    "    unstable_mean_u_field[::5,::5,4], unstable_mean_v_field[::5,::5,4], \n",
    ")\n",
    "axes[1,0].set_title('unstable, 4.5m')\n",
    "axes[1,1].quiver(\n",
    "    xx[::5,::5,15],  yy[::5,::5,15],\n",
    "    unstable_mean_u_field[::5,::5,15], unstable_mean_v_field[::5,::5,15], \n",
    ")\n",
    "axes[1,1].set_title('unstable, 8m')\n",
    "\n",
    "neutral_mean_u_field = np.nanmean(np.stack(u_interp[u_interp.index.isin(ri_neutral_times)].values), axis = 0)\n",
    "neutral_mean_v_field = np.nanmean(np.stack(v_interp[v_interp.index.isin(ri_neutral_times)].values), axis = 0)\n",
    "neutral_mean_w_field = np.nanmean(np.stack(w_interp[w_interp.index.isin(ri_neutral_times)].values), axis = 0)\n",
    "axes[2,0].quiver(\n",
    "    xx[::5,::5,4],  yy[::5,::5,4],\n",
    "    neutral_mean_u_field[::5,::5,4], neutral_mean_v_field[::5,::5,4], \n",
    ")\n",
    "axes[2,0].set_title('neutral, 4.5m')\n",
    "axes[2,1].quiver(\n",
    "    xx[::5,::5,15],  yy[::5,::5,15],\n",
    "    neutral_mean_u_field[::5,::5,15], neutral_mean_v_field[::5,::5,15], \n",
    ")\n",
    "axes[2,1].set_title('neutral, 8m')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_unstable = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_unstable = src_unstable[(src_unstable.time >= '20221130') & (src_unstable.time < '20230509')]\n",
    "src_unstable = src_unstable[src_unstable.time.isin(set(ri_unstable_times).intersection(set(nobs_times)))]\n",
    "src_unstable = src_unstable.pivot_table(index='time', values='value', columns='variable')\n",
    "src_unstable['diff_unstable'] = src_unstable['w_h2o__20m_c'] - src_unstable['w_h2o__3m_c']\n",
    "\n",
    "src_stable = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_stable = src_stable[(src_stable.time >= '20221130') & (src_stable.time < '20230509')]\n",
    "src_stable = src_stable[src_stable.time.isin(set(ri_stable_times).intersection(set(nobs_times)))]\n",
    "src_stable = src_stable.pivot_table(index='time', values='value', columns='variable')\n",
    "src_stable['diff_stable'] = src_stable['w_h2o__20m_c'] - src_stable['w_h2o__3m_c']\n",
    "\n",
    "src_neutral = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_neutral = src_neutral[(src_neutral.time >= '20221130') & (src_neutral.time < '20230509')]\n",
    "src_neutral = src_neutral[src_neutral.time.isin(set(ri_neutral_times).intersection(set(nobs_times)))]\n",
    "src_neutral = src_neutral.pivot_table(index='time', values='value', columns='variable')\n",
    "src_neutral['diff_neutral'] = src_neutral['w_h2o__20m_c'] - src_neutral['w_h2o__3m_c']\n",
    "\n",
    "src = pd.concat([\n",
    "    src_neutral[['diff_neutral']].reset_index(),\n",
    "    src_stable[['diff_stable']].reset_index(),\n",
    "    src_unstable[['diff_unstable']].reset_index(),\n",
    "])\n",
    "alt.Chart(\n",
    "    src.reset_index()\n",
    "    # src.reset_index()\n",
    ").transform_fold([\n",
    "    'diff_neutral', 'diff_stable', 'diff_unstable'\n",
    "]).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=150, height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_unstable = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_unstable = src_unstable[(src_unstable.time >= '20221130') & (src_unstable.time < '20230509')]\n",
    "src_unstable = src_unstable[src_unstable.time.isin(set(ri_unstable_times).intersection(set(nobs_times)))]\n",
    "src_unstable = src_unstable.pivot_table(index='time', values='value', columns='variable')\n",
    "src_unstable = src_unstable.reset_index()\n",
    "\n",
    "src_stable = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_stable = src_stable[(src_stable.time >= '20221130') & (src_stable.time < '20230509')]\n",
    "src_stable = src_stable[src_stable.time.isin(set(ri_stable_times).intersection(set(nobs_times)))]\n",
    "src_stable = src_stable.pivot_table(index='time', values='value', columns='variable')\n",
    "src_stable = src_stable.reset_index()\n",
    "\n",
    "src_neutral = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_neutral = src_neutral[(src_neutral.time >= '20221130') & (src_neutral.time < '20230509')]\n",
    "src_neutral = src_neutral[src_neutral.time.isin(set(ri_neutral_times).intersection(set(nobs_times)))]\n",
    "src_neutral = src_neutral.pivot_table(index='time', values='value', columns='variable')\n",
    "src_neutral = src_neutral.reset_index()\n",
    "\n",
    "chart = alt.Chart(\n",
    ").transform_fold([\n",
    "    'w_h2o__3m_c', 'w_h2o__20m_c'\n",
    "]).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ")\n",
    "\n",
    "alt.layer(\n",
    "    chart,\n",
    "    data =  src_stable[(src_stable.time >= '20221130') & (src_stable.time < '20230509')].reset_index()\n",
    ") | alt.layer(\n",
    "    chart,\n",
    "    data =  src_neutral[(src_neutral.time >= '20221130') & (src_neutral.time < '20230509')].reset_index()\n",
    ") | alt.layer(\n",
    "    chart,\n",
    "    data =  src_unstable[(src_unstable.time >= '20221130') & (src_unstable.time < '20230509')].reset_index()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_unstable = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_unstable = src_unstable[src_unstable.time.isin(set(ri_unstable_times).intersection(set(nobs_times)))]\n",
    "src_unstable = src_unstable.pivot_table(index='time', values='value', columns='variable')\n",
    "src_unstable['diff_unstable'] = src_unstable['w_h2o__20m_c'] - src_unstable['w_h2o__3m_c']\n",
    "\n",
    "src_stable = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_stable = src_stable[src_stable.time.isin(set(ri_stable_times).intersection(set(nobs_times)))]\n",
    "src_stable = src_stable.pivot_table(index='time', values='value', columns='variable')\n",
    "src_stable['diff_stable'] = src_stable['w_h2o__20m_c'] - src_stable['w_h2o__3m_c']\n",
    "\n",
    "src_neutral = tidy_df[tidy_df.variable.isin(['w_h2o__3m_c', 'w_h2o__20m_c'])]\n",
    "src_neutral = src_neutral[src_neutral.time.isin(set(ri_neutral_times).intersection(set(nobs_times)))]\n",
    "src_neutral = src_neutral.pivot_table(index='time', values='value', columns='variable')\n",
    "src_neutral['diff_neutral'] = src_neutral['w_h2o__20m_c'] - src_neutral['w_h2o__3m_c']\n",
    "\n",
    "src = pd.concat([\n",
    "    src_neutral[['diff_neutral']].reset_index(),\n",
    "    src_stable[['diff_stable']].reset_index(),\n",
    "    src_unstable[['diff_unstable']].reset_index(),\n",
    "])\n",
    "alt.Chart(\n",
    "    src[(src.time >= '20221130') & (src.time < '20230509')].reset_index()\n",
    "    # src.reset_index()\n",
    ").transform_fold([\n",
    "    'diff_neutral', 'diff_stable', 'diff_unstable'\n",
    "]).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df.query(\"measurement == 'wind direction'\")\n",
    "src = src[src.time.isin(ri_unstable_times)]\n",
    "src\n",
    "alt.Chart(src).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.Facet('tower:N')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate terms (3D)\n",
    "\n",
    "Calculate advective terms in both the Paw U form\n",
    "\n",
    "$u \\rho \\dfrac{\\partial s}{\\partial x} + v \\rho \\dfrac{\\partial s}{\\partial y} + w \\rho \\dfrac{\\partial s}{\\partial z}$\n",
    "\n",
    "and in the Sun form\n",
    "\n",
    "$u \\dfrac{\\partial q}{\\partial x} + v \\dfrac{\\partial q}{\\partial y} + w \\dfrac{\\partial q}{\\partial z}$\n",
    "\n",
    "and also calculate the turbulent flux divergence terms (same for Paw U and Sun)\n",
    "\n",
    "$\\dfrac{\\partial \\overline{u'q'}}{\\partial x} + \\dfrac{\\partial \\overline{v'q'}}{\\partial y} + \\dfrac{\\partial \\overline{w'q'}}{\\partial z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with grids of interpolated data\n",
    "u_interp.name = 'u'\n",
    "v_interp.name = 'v'\n",
    "w_interp.name = 'w'\n",
    "u_q__interp.name = 'u_q_'\n",
    "v_q__interp.name = 'v_q_'\n",
    "w_q__interp.name = 'w_q_'\n",
    "rho_interp.name = 'rho'\n",
    "r_interp.name = 'r'\n",
    "q_interp.name = 'q'\n",
    "\n",
    "fields_df = pd.DataFrame(u_interp).join(\n",
    "    v_interp\n",
    ").join(\n",
    "    w_interp\n",
    ").join(\n",
    "    u_q__interp\n",
    ").join(\n",
    "    v_q__interp\n",
    ").join(\n",
    "    w_q__interp\n",
    ").join(\n",
    "    rho_interp\n",
    ").join(\n",
    "    r_interp\n",
    ").join(\n",
    "    q_interp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the time series of fields and calculate the terms \n",
    "# We take the median of the gridded values.\n",
    "# The apply function returns a tuple of 4 values, with each tuple contains values \n",
    "# for the following in order:\n",
    "# means of:  lateral_advection_pawu , vertical_advection_pawu ,  lateral_advection_sun , vertical_advection_sun, lateral_turb_flux_div, vertical_turb_flux_div \n",
    "# medians of:  lateral_advection_pawu , vertical_advection_pawu ,  lateral_advection_sun , vertical_advection_sun, lateral_turb_flux_div, vertical_turb_flux_div \n",
    "advective_terms_3d = fields_df.apply(\n",
    "    lambda row: \n",
    "    (\n",
    "        # Lateral advection Paw U style\n",
    "        np.nanmean(\n",
    "            row['u']*row['rho']*np.gradient(row['r'], spacing_x, axis=0)\n",
    "            +\n",
    "            row['v']*row['rho']*np.gradient(row['r'], spacing_y, axis=1)\n",
    "        ),\n",
    "        # Vertical advection Paw U style\n",
    "        np.nanmean(row['w']*row['rho']*np.gradient(row['r'], spacing_z, axis=2)),\n",
    "        # Lateral advection Sun style\n",
    "        np.nanmean(\n",
    "            row['u']*np.gradient(row['q'], spacing_x, axis=0)\n",
    "            +\n",
    "            row['v']*np.gradient(row['q'], spacing_y, axis=1)\n",
    "        ),\n",
    "        # Vertical advection Sun style\n",
    "        np.nanmean(row['w']*np.gradient(row['q'], spacing_z, axis=2)),\n",
    "        # Lateral turb. flux divergence\n",
    "        np.nanmean(\n",
    "            np.gradient(row['u_q_'], spacing_x, axis=0)\n",
    "            +\n",
    "            np.gradient(row['v_q_'], spacing_y, axis=1)\n",
    "        ),\n",
    "        # Vertical turb. flux divergence\n",
    "        np.nanmean(np.gradient(row['w_q_'], spacing_z, axis=2)),\n",
    "        # Vertical air density flux term (Paw U only)\n",
    "        ###???\n",
    "        # Lateral advection Paw U style\n",
    "        np.nanmedian(\n",
    "            row['u']*row['rho']*np.gradient(row['r'], spacing_x, axis=0)\n",
    "            +\n",
    "            row['v']*row['rho']*np.gradient(row['r'], spacing_y, axis=1)\n",
    "        ),\n",
    "        # Vertical advection Paw U style\n",
    "        np.nanmedian(row['w']*row['rho']*np.gradient(row['r'], spacing_z, axis=2)),\n",
    "        # Lateral advection Sun style\n",
    "        np.nanmedian(\n",
    "            row['u']*np.gradient(row['q'], spacing_x, axis=0)\n",
    "            +\n",
    "            row['v']*np.gradient(row['q'], spacing_y, axis=1)\n",
    "        ),\n",
    "        # Vertical advection Sun style\n",
    "        np.nanmedian(row['w']*np.gradient(row['q'], spacing_z, axis=2)),\n",
    "        # Lateral turb. flux divergence\n",
    "        np.nanmedian(\n",
    "            np.gradient(row['u_q_'], spacing_x, axis=0)\n",
    "            +\n",
    "            np.gradient(row['v_q_'], spacing_y, axis=1)\n",
    "        ),\n",
    "        # Vertical turb. flux divergence\n",
    "        np.nanmedian(np.gradient(row['w_q_'], spacing_z, axis=2)),\n",
    "        # Vertical air density flux term (Paw U only)\n",
    "        ###???\n",
    "    )\n",
    "    ,\n",
    "    axis = 1\n",
    ")\n",
    "advective_terms_3d = pd.DataFrame(\n",
    "    [[a, b, c, d, e, f, g, h, i, j, k, l] for a,b,c,d,e,f,g,h,i,j,k,l in advective_terms_3d.values], \n",
    "    columns=[\n",
    "        'lateral_advection_pawu (mean)',\n",
    "        'vertical_advection_pawu (mean)',\n",
    "        'lateral_advection_sun (mean)',\n",
    "        'vertical_advection_sun (mean)',\n",
    "        'lateral_turb_flux_div (mean)',\n",
    "        'vertical_turb_flux_div (mean)',\n",
    "        \n",
    "        'lateral_advection_pawu (median)',\n",
    "        'vertical_advection_pawu (median)',\n",
    "        'lateral_advection_sun (median)',\n",
    "        'vertical_advection_sun (median)',\n",
    "        'lateral_turb_flux_div (median)',\n",
    "        'vertical_turb_flux_div (median)',\n",
    "    ]\n",
    ")\n",
    "advective_terms_3d.index = fields_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advective_terms_3d = advective_terms_3d*7\n",
    "advective_terms_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate vertical velocity from horizontal divergence.\n",
    "\n",
    "Following Vickers and Mahrt (2006), for incompressible mass continuity, time averaged vertical velocity based on divergence in \n",
    "\n",
    "$$ w(h) = - \\int_{z=0}^{z=h} (\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y}) dz$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w_for_row(row):\n",
    "    data = - np.nansum(\n",
    "        (\n",
    "            np.gradient(row['u'], spacing_x, axis=0)\n",
    "            + np.gradient(row['v'], spacing_y, axis=1)\n",
    "        ),\n",
    "        axis = 2\n",
    "    ) * (\n",
    "        instrument_loc_limited_heights.z.max() \n",
    "        - instrument_loc_limited_heights.z.min()\n",
    "    )\n",
    "\n",
    "    data[data == 0] = np.nan\n",
    "    data\n",
    "    return np.nanmedian(data)\n",
    "\n",
    "w_from_div = fields_df.apply(get_w_for_row, axis = 1)\n",
    "\n",
    "alt.Chart(pd.DataFrame(w_from_div.rename('w')).reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(w):Q')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_chart = (alt.Chart(\n",
    "    (advective_terms_3d/7).reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_3d.columns) if 'turb' not in c and 'mean' in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150) | alt.Chart(\n",
    "    advective_terms_3d.reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_3d.columns) if 'turb' in c and 'mean' in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150)).resolve_scale(color='independent')\n",
    "\n",
    "median_chart = (alt.Chart(\n",
    "    (advective_terms_3d/7).reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_3d.columns) if 'turb' not in c and 'median' in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150) | alt.Chart(\n",
    "    advective_terms_3d.reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_3d.columns) if 'turb' in c and 'median' in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150)).resolve_scale(color='independent')\n",
    "\n",
    "(mean_chart & median_chart).resolve_scale(y='shared', x='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    advective_terms_3d.loc['20230201': '20230205'].reset_index()\n",
    ").transform_fold(\n",
    "    list(advective_terms_3d.columns)\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    # .scale(domain=[0,0.02], clamp=True),\n",
    "    alt.Color('key:N')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Differential Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3m height\n",
    "\n",
    "Repeat all the steps we did above, but just for a single plane at 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHTS_2D = [3]\n",
    "\n",
    "# gather all measurements into a dataframe, isolate to the heights we care about\n",
    "df = wind_field_df.join(\n",
    "    turb_flux_field_df\n",
    ").join(\n",
    "    temp_turb_flux_field_df\n",
    ").join(\n",
    "    abs_hum_field_df\n",
    ").join(\n",
    "    adv_flux_field_df\n",
    ").join(\n",
    "    dryair_density_field_df\n",
    ").join(\n",
    "    temp_field_df\n",
    ").join(\n",
    "    mixing_ratio_field_df\n",
    ")\n",
    "data_df_2d = df[HEIGHTS_2D]\n",
    "\n",
    "# Gather the instrument locations into a dataframe, isolate to heights we care about\n",
    "instrument_loc_limited_heights_2d = instrument_loc_df[instrument_loc_df.index.get_level_values(0).isin(HEIGHTS_2D)]\n",
    "\n",
    "# Transform the dataframe of instrument locations into a form that can be merged with the dataframe of measurements\n",
    "#   transform\n",
    "xxx = pd.DataFrame(instrument_loc_limited_heights_2d.unstack().unstack()).T\n",
    "xxx.columns = xxx.columns.swaplevel(0,2)\n",
    "xxx.columns = xxx.columns.set_names('measurement', level=2)\n",
    "#   duplicate the sensor locations so we can join (duplicate) x,y,z info into the dataframe of measurements\n",
    "instrument_loc_limited_heights_2d_repeated = xxx.loc[xxx.index.repeat(len(data_df_2d))]\n",
    "instrument_loc_limited_heights_2d_repeated.index = data_df_2d.index\n",
    "instrument_loc_limited_heights_2d_repeated\n",
    "data_df_2d = data_df_2d.join(instrument_loc_limited_heights_2d_repeated)\n",
    "data_df_2d\n",
    "\n",
    "# Create a meshgrid for the interpolation and isolate the x,y,z locations of measurements\n",
    "xx_2d, yy_2d = np.meshgrid(\n",
    "    np.linspace(instrument_loc_limited_heights_2d.x.min(), instrument_loc_limited_heights_2d.x.max(), HORIZ_GRID_SPACING),\n",
    "    np.linspace(instrument_loc_limited_heights_2d.y.min(), instrument_loc_limited_heights_2d.y.max(), HORIZ_GRID_SPACING)\n",
    ")\n",
    "spacing_x_2d = np.diff(xx_2d[0,:]).mean()\n",
    "spacing_y_2d = np.diff(yy_2d[:,0]).mean()\n",
    "points_2d = np.transpose(np.vstack((instrument_loc_limited_heights_2d.x, instrument_loc_limited_heights_2d.y)))\n",
    "\n",
    "# Calculate interpolated fields\n",
    "    # VECTOR FIELDS\n",
    "    # wind velocity fields\n",
    "u_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['u'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "v_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['v'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "w_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['w'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "    # turb. flux fields\n",
    "u_q__interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['u_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "v_q__interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['v_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "w_q__interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['w_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "    # SCALAR FIELDS\n",
    "rho_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['rho'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "r_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['r'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "q_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['q'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create dataframe with grids of interpolated data\n",
    "u_interp_2d.name = 'u'\n",
    "v_interp_2d.name = 'v'\n",
    "w_interp_2d.name = 'w'\n",
    "u_q__interp_2d.name = 'u_q_'\n",
    "v_q__interp_2d.name = 'v_q_'\n",
    "w_q__interp_2d.name = 'w_q_'\n",
    "rho_interp_2d.name = 'rho'\n",
    "r_interp_2d.name = 'r'\n",
    "q_interp_2d.name = 'q'\n",
    "\n",
    "fields_df_2d = pd.DataFrame(u_interp_2d).join(\n",
    "    v_interp_2d\n",
    ").join(\n",
    "    w_interp_2d\n",
    ").join(\n",
    "    u_q__interp_2d\n",
    ").join(\n",
    "    v_q__interp_2d\n",
    ").join(\n",
    "    w_q__interp_2d\n",
    ").join(\n",
    "    rho_interp_2d\n",
    ").join(\n",
    "    r_interp_2d\n",
    ").join(\n",
    "    q_interp_2d\n",
    ")\n",
    "\n",
    "# Iterate over the time series of fields and calculate the terms \n",
    "# We take the median of the gridded values.\n",
    "# The apply function returns a tuple of 4 values, with each tuple contains values \n",
    "# for the following in order:\n",
    "#  means of: lateral_advection_pawu , vertical_advection_pawu ,  lateral_advection_sun , vertical_advection_sun, lateral_turb_flux_div, vertical_turb_flux_div \n",
    "#  medians of: lateral_advection_pawu , vertical_advection_pawu ,  lateral_advection_sun , vertical_advection_sun, lateral_turb_flux_div, vertical_turb_flux_div \n",
    "advective_terms_2d_3m = fields_df_2d.apply(\n",
    "    lambda row: \n",
    "    (\n",
    "        # Lateral advection Paw U style\n",
    "        np.nanmean(\n",
    "            row['u']*row['rho']*np.gradient(row['r'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*row['rho']*np.gradient(row['r'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral advection Sun style\n",
    "        np.nanmean(\n",
    "            row['u']*np.gradient(row['q'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*np.gradient(row['q'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral turb. flux divergence\n",
    "        np.nanmean(\n",
    "            np.gradient(row['u_q_'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            np.gradient(row['v_q_'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral advection Paw U style\n",
    "        np.nanmedian(\n",
    "            row['u']*row['rho']*np.gradient(row['r'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*row['rho']*np.gradient(row['r'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral advection Sun style\n",
    "        np.nanmedian(\n",
    "            row['u']*np.gradient(row['q'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*np.gradient(row['q'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral turb. flux divergence\n",
    "        np.nanmedian(\n",
    "            np.gradient(row['u_q_'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            np.gradient(row['v_q_'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "    ),\n",
    "    axis = 1\n",
    ")\n",
    "advective_terms_2d_3m = pd.DataFrame(\n",
    "    [[a, b, c, d, e, f] for a, b, c, d, e, f in advective_terms_2d_3m.values], \n",
    "    columns=[\n",
    "        'lateral_advection_pawu (mean)', \n",
    "        'lateral_advection_sun (mean)',\n",
    "        'lateral_turb_flux_div (mean)', \n",
    "        'lateral_advection_pawu (median)', \n",
    "        'lateral_advection_sun (median)',\n",
    "        'lateral_turb_flux_div (median)', \n",
    "    ]\n",
    ")\n",
    "advective_terms_2d_3m.index = fields_df_2d.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT: Example of a 2d interpolated wind field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.quiver(\n",
    "    xx_2d[::4], \n",
    "    yy_2d[::4],\n",
    "    u_interp_2d[100][::4],\n",
    "    v_interp_2d[100][::4], \n",
    "    label='interpolated'\n",
    ")\n",
    "plt.quiver(\n",
    "    data_df_2d.iloc[100][(slice(None),slice(None),'x')].values.astype('float'),\n",
    "    data_df_2d.iloc[100][(slice(None),slice(None),'y')].values.astype('float'),\n",
    "    data_df_2d.iloc[100][(slice(None),slice(None),'u')].values.astype('float'),\n",
    "    data_df_2d.iloc[100][(slice(None),slice(None),'v')].values.astype('float'),\n",
    "    label='measured',\n",
    "    color='red'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10m height\n",
    "\n",
    "Repeat all the steps we did above, but just for a single plane at 3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHTS_2D = [10]\n",
    "\n",
    "# gather all measurements into a dataframe, isolate to the heights we care about\n",
    "df = wind_field_df.join(\n",
    "    turb_flux_field_df\n",
    ").join(\n",
    "    temp_turb_flux_field_df\n",
    ").join(\n",
    "    abs_hum_field_df\n",
    ").join(\n",
    "    adv_flux_field_df\n",
    ").join(\n",
    "    dryair_density_field_df\n",
    ").join(\n",
    "    temp_field_df\n",
    ").join(\n",
    "    mixing_ratio_field_df\n",
    ")\n",
    "data_df_2d = df[HEIGHTS_2D]\n",
    "\n",
    "# Gather the instrument locations into a dataframe, isolate to heights we care about\n",
    "instrument_loc_limited_heights_2d = instrument_loc_df[instrument_loc_df.index.get_level_values(0).isin(HEIGHTS_2D)]\n",
    "\n",
    "# Transform the dataframe of instrument locations into a form that can be merged with the dataframe of measurements\n",
    "#   transform\n",
    "xxx = pd.DataFrame(instrument_loc_limited_heights_2d.unstack().unstack()).T\n",
    "xxx.columns = xxx.columns.swaplevel(0,2)\n",
    "xxx.columns = xxx.columns.set_names('measurement', level=2)\n",
    "#   duplicate the sensor locations so we can join (duplicate) x,y,z info into the dataframe of measurements\n",
    "instrument_loc_limited_heights_2d_repeated = xxx.loc[xxx.index.repeat(len(data_df_2d))]\n",
    "instrument_loc_limited_heights_2d_repeated.index = data_df_2d.index\n",
    "instrument_loc_limited_heights_2d_repeated\n",
    "data_df_2d = data_df_2d.join(instrument_loc_limited_heights_2d_repeated)\n",
    "data_df_2d\n",
    "\n",
    "# Create a meshgrid for the interpolation and isolate the x,y,z locations of measurements\n",
    "xx_2d, yy_2d = np.meshgrid(\n",
    "    np.linspace(instrument_loc_limited_heights_2d.x.min(), instrument_loc_limited_heights_2d.x.max(), HORIZ_GRID_SPACING),\n",
    "    np.linspace(instrument_loc_limited_heights_2d.y.min(), instrument_loc_limited_heights_2d.y.max(), HORIZ_GRID_SPACING)\n",
    ")\n",
    "spacing_x_2d = np.diff(xx_2d[0,:]).mean()\n",
    "spacing_y_2d = np.diff(yy_2d[:,0]).mean()\n",
    "points_2d = np.transpose(np.vstack((instrument_loc_limited_heights_2d.x, instrument_loc_limited_heights_2d.y)))\n",
    "\n",
    "# Calculate interpolated fields\n",
    "    # VECTOR FIELDS\n",
    "    # wind velocity fields\n",
    "u_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['u'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "v_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['v'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "w_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['w'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "    # turb. flux fields\n",
    "u_q__interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['u_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "v_q__interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['v_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "w_q__interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['w_h2o_'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "    # SCALAR FIELDS\n",
    "rho_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['rho'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "r_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['r'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "q_interp_2d = data_df_2d.loc[:, (slice(None),slice(None),['q'])].apply(\n",
    "    lambda row:  interpolate.griddata(points_2d, row.values, (xx_2d, yy_2d), method='linear'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create dataframe with grids of interpolated data\n",
    "u_interp_2d.name = 'u'\n",
    "v_interp_2d.name = 'v'\n",
    "w_interp_2d.name = 'w'\n",
    "u_q__interp_2d.name = 'u_q_'\n",
    "v_q__interp_2d.name = 'v_q_'\n",
    "w_q__interp_2d.name = 'w_q_'\n",
    "rho_interp_2d.name = 'rho'\n",
    "r_interp_2d.name = 'r'\n",
    "q_interp_2d.name = 'q'\n",
    "\n",
    "fields_df_2d = pd.DataFrame(u_interp_2d).join(\n",
    "    v_interp_2d\n",
    ").join(\n",
    "    w_interp_2d\n",
    ").join(\n",
    "    u_q__interp_2d\n",
    ").join(\n",
    "    v_q__interp_2d\n",
    ").join(\n",
    "    w_q__interp_2d\n",
    ").join(\n",
    "    rho_interp_2d\n",
    ").join(\n",
    "    r_interp_2d\n",
    ").join(\n",
    "    q_interp_2d\n",
    ")\n",
    "\n",
    "# Iterate over the time series of fields and calculate the terms \n",
    "# We take the median of the gridded values.\n",
    "# The apply function returns a tuple of 4 values, with each tuple contains values \n",
    "# for the following in order:\n",
    "#  lateral_advection_pawu , vertical_advection_pawu ,  lateral_advection_sun , vertical_advection_sun, lateral_turb_flux_div, vertical_turb_flux_div \n",
    "advective_terms_2d_10m = fields_df_2d.apply(\n",
    "    lambda row: \n",
    "    (\n",
    "        # Lateral advection Paw U style\n",
    "        np.nanmean(\n",
    "            row['u']*row['rho']*np.gradient(row['r'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*row['rho']*np.gradient(row['r'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral advection Sun style\n",
    "        np.nanmean(\n",
    "            row['u']*np.gradient(row['q'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*np.gradient(row['q'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral turb. flux divergence\n",
    "        np.nanmean(\n",
    "            np.gradient(row['u_q_'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            np.gradient(row['v_q_'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral advection Paw U style\n",
    "        np.nanmedian(\n",
    "            row['u']*row['rho']*np.gradient(row['r'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*row['rho']*np.gradient(row['r'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral advection Sun style\n",
    "        np.nanmedian(\n",
    "            row['u']*np.gradient(row['q'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            row['v']*np.gradient(row['q'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "        # Lateral turb. flux divergence\n",
    "        np.nanmedian(\n",
    "            np.gradient(row['u_q_'], spacing_x_2d, axis=0)\n",
    "            +\n",
    "            np.gradient(row['v_q_'], spacing_y_2d, axis=1)\n",
    "        ),\n",
    "    ),\n",
    "    axis = 1\n",
    ")\n",
    "advective_terms_2d_10m = pd.DataFrame(\n",
    "    [[a, b, c, d, e, f] for a, b, c, d, e, f in advective_terms_2d_10m.values], \n",
    "    columns=[\n",
    "        'lateral_advection_pawu (mean)', \n",
    "        'lateral_advection_sun (mean)',\n",
    "        'lateral_turb_flux_div (mean)', \n",
    "        'lateral_advection_pawu (median)', \n",
    "        'lateral_advection_sun (median)',\n",
    "        'lateral_turb_flux_div (median)', \n",
    "    ]\n",
    ")\n",
    "advective_terms_2d_10m.index = fields_df_2d.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average the two planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advective_terms_2d_3m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advective_terms_2d_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advective_terms_2d = (advective_terms_2d_3m + advective_terms_2d_10m)/2\n",
    "advective_terms_2d = advective_terms_2d*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    advective_terms_2d.reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_2d.columns) if 'turb' not in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150) | alt.Chart(\n",
    "    advective_terms_2d.reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_2d.columns) if 'turb' in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    advective_terms_3d.reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_3d.columns) if 'turb' not in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150) | alt.Chart(\n",
    "    advective_terms_3d.reset_index()\n",
    ").transform_fold(\n",
    "    [c for c in list(advective_terms_3d.columns) if 'turb' in c]\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('key:N')\n",
    ").properties(width=200, height = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Integral Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define area of triangular prism faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define face areas\n",
    "A1 = A2 = A3 = 37 * 7 * units('m^2')\n",
    "A4 = A5 = 580.2 * units('m^2')\n",
    "CV_HEIGHT = 7*units('m')\n",
    "VOLUME = A4*CV_HEIGHT\n",
    "A1, A2, A3, A4, A5, VOLUME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define normal vectors to the triangular prism faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELI'S angles\n",
    "n1 = np.array([ np.cos(np.deg2rad(258.7)),   np.sin(np.deg2rad(258.7))])*units(None)\n",
    "n2 = np.array([ np.cos(np.deg2rad(20.1)),   np.sin(np.deg2rad(20.1))])*units(None)\n",
    "n3 = np.array([ np.cos(np.deg2rad(139.26)),   np.sin(np.deg2rad(139.26))])*units(None)\n",
    "\n",
    "# DANNY'S angles\n",
    "# n1 = np.array([ np.cos(np.deg2rad(269.5)),   np.sin(np.deg2rad(269.5))])*units(None)\n",
    "# n2 = np.array([ np.cos(np.deg2rad(19.5)),   np.sin(np.deg2rad(19.5))])*units(None)\n",
    "# n3 = np.array([ np.cos(np.deg2rad(143.5)),   np.sin(np.deg2rad(143.5))])*units(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instrument_loc_df = gpd.GeoDataFrame(\n",
    "    instrument_loc_df,\n",
    "    geometry = gpd.points_from_xy(\n",
    "        instrument_loc_df.x, \n",
    "        instrument_loc_df.y, \n",
    "        instrument_loc_df.z\n",
    "    ),\n",
    "    crs = 'EPSG:32613'\n",
    ")\n",
    "instrument_loc_df = instrument_loc_df.to_crs('EPSG:4326')\n",
    "instrument_loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate storage term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_change_term = tidy_df[\n",
    "    tidy_df.measurement.isin(['specific humidity', 'air density'])\n",
    "].query(\"tower == 'c'\").query(\"height <= 10\").query(\"height >= 3\").groupby(\n",
    "    ['time', 'tower', 'measurement']\n",
    ")[['value']].mean().reset_index() \n",
    "storage_change_term = storage_change_term.pivot_table(index='time', values='value', columns='measurement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = storage_change_term.index.diff()[1].seconds * units('seconds')\n",
    "print(timestep)\n",
    "absolute_humidity = storage_change_term['specific humidity'].values * units(\"g/g\")  * (\n",
    "    storage_change_term['air density'].values * units(\"kg/m^3\")\n",
    ")\n",
    "delta_humidity = np.diff(absolute_humidity * VOLUME, prepend=np.nan)\n",
    "dq_dt = delta_humidity / timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_change_term['absolute humidity (g/m^3)'] = absolute_humidity.to('g/m^3')\n",
    "storage_change_term['delta water storage (g/s)'] = dq_dt.to('grams/second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate advective flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advective_flux_3m_ue = wind_field_df[3]['ue'].multiply(\n",
    "    abs_hum_field_df[3]['ue']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_10m_ue = wind_field_df[10]['ue'].multiply(\n",
    "    abs_hum_field_df[10]['ue']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_3m_uw = wind_field_df[3]['uw'].multiply(\n",
    "    abs_hum_field_df[3]['uw']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_10m_uw = wind_field_df[10]['uw'].multiply(\n",
    "    abs_hum_field_df[10]['uw']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_3m_d = wind_field_df[3]['d'].multiply(\n",
    "    abs_hum_field_df[3]['d']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_10m_d = wind_field_df[10]['d'].multiply(\n",
    "    abs_hum_field_df[10]['d']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_3m_c = wind_field_df[3]['c'].multiply(\n",
    "    abs_hum_field_df[3]['c']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})\n",
    "\n",
    "advective_flux_10m_c = wind_field_df[10]['c'].multiply(\n",
    "    abs_hum_field_df[10]['c']['q'],\n",
    "    axis=0\n",
    ").rename(columns={'u': 'uq', 'v': 'vq','w': 'wq',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average u, v, and w components needed to calculate flux through each face\n",
    "face1_avg_u_flux = 0.25*(\n",
    "    advective_flux_3m_uw['uq'] + advective_flux_10m_uw['uq'] + \n",
    "    advective_flux_3m_d['uq'] + advective_flux_10m_d['uq']\n",
    ")\n",
    "\n",
    "face1_avg_v_flux = 0.25*(\n",
    "    advective_flux_3m_uw['vq'] + advective_flux_10m_uw['vq'] + \n",
    "    advective_flux_3m_d['vq'] + advective_flux_10m_d['vq']\n",
    ")\n",
    "\n",
    "face2_avg_u_flux = 0.25*(\n",
    "    advective_flux_3m_ue['uq'] + advective_flux_10m_ue['uq'] + \n",
    "    advective_flux_3m_d['uq'] + advective_flux_10m_d['uq']\n",
    ")\n",
    "\n",
    "face2_avg_v_flux = 0.25*(\n",
    "    advective_flux_3m_ue['vq'] + advective_flux_10m_ue['vq'] + \n",
    "    advective_flux_3m_d['vq'] + advective_flux_10m_d['vq']\n",
    ")\n",
    "\n",
    "face3_avg_u_flux = 0.25*(\n",
    "    advective_flux_3m_ue['uq'] + advective_flux_10m_ue['uq'] + \n",
    "    advective_flux_3m_uw['uq'] + advective_flux_10m_uw['uq']\n",
    ")\n",
    "\n",
    "face3_avg_v_flux = 0.25*(\n",
    "    advective_flux_3m_ue['vq'] + advective_flux_10m_ue['vq'] + \n",
    "    advective_flux_3m_uw['vq'] + advective_flux_10m_uw['vq']\n",
    ")\n",
    "\n",
    "face4_avg_w_flux = 0.25*(\n",
    "    advective_flux_10m_ue['wq'] + advective_flux_10m_uw['wq'] + \n",
    "    advective_flux_10m_c['wq'] + advective_flux_10m_d['wq']\n",
    ")\n",
    "\n",
    "face5_avg_w_flux = - 0.25*(\n",
    "    advective_flux_3m_ue['wq'] + advective_flux_3m_uw['wq'] + \n",
    "    advective_flux_3m_c['wq'] + advective_flux_3m_d['wq']\n",
    ")\n",
    "\n",
    "# Combine the (separate) u and v components into a list of vectors for the lateral faces\n",
    "face1_avg_adv_flux = np.array([\n",
    "    face1_avg_u_flux,\n",
    "    face1_avg_v_flux\n",
    "]).T\n",
    "\n",
    "face2_avg_adv_flux = np.array([\n",
    "    face2_avg_u_flux,\n",
    "    face2_avg_v_flux\n",
    "]).T\n",
    "\n",
    "face3_avg_adv_flux = np.array([\n",
    "    face3_avg_u_flux,\n",
    "    face3_avg_v_flux\n",
    "]).T\n",
    "\n",
    "# Project the lateral flux vectors onto the face-normal vectors\n",
    "face1_projected_adv_flux = np.dot(face1_avg_adv_flux, n1.m)\n",
    "face2_projected_adv_flux = np.dot(face2_avg_adv_flux, n2.m)\n",
    "face3_projected_adv_flux = np.dot(face3_avg_adv_flux, n3.m)\n",
    "\n",
    "# Calculate total lateral and vertical flux\n",
    "total_lateral_adv_divergence = (\n",
    "    face1_projected_adv_flux*A1.m + \n",
    "    face2_projected_adv_flux*A2.m + \n",
    "    face3_projected_adv_flux*A3.m\n",
    ") / VOLUME.m\n",
    "\n",
    "total_vertical_adv_divergence = (face4_avg_w_flux*A4 + face5_avg_w_flux*A5)  / VOLUME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate turbulent flux divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average u, v, and w components needed to calculate flux through each face\n",
    "face1_avg_u_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[3]['uw']['u_h2o_'] + turb_flux_field_df[10]['uw']['u_h2o_'] + \n",
    "    turb_flux_field_df[3]['d']['u_h2o_'] + turb_flux_field_df[10]['d']['u_h2o_']\n",
    ")\n",
    "\n",
    "face1_avg_v_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[3]['uw']['v_h2o_'] + turb_flux_field_df[10]['uw']['v_h2o_'] + \n",
    "    turb_flux_field_df[3]['d']['v_h2o_'] + turb_flux_field_df[10]['d']['v_h2o_']\n",
    ")\n",
    "\n",
    "face2_avg_u_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[3]['ue']['u_h2o_'] + turb_flux_field_df[10]['ue']['u_h2o_'] + \n",
    "    turb_flux_field_df[3]['d']['u_h2o_'] + turb_flux_field_df[10]['d']['u_h2o_']\n",
    ")\n",
    "\n",
    "face2_avg_v_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[3]['ue']['v_h2o_'] + turb_flux_field_df[10]['ue']['v_h2o_'] + \n",
    "    turb_flux_field_df[3]['d']['v_h2o_'] + turb_flux_field_df[10]['d']['v_h2o_']\n",
    ")\n",
    "\n",
    "face3_avg_u_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[3]['ue']['u_h2o_'] + turb_flux_field_df[10]['ue']['u_h2o_'] + \n",
    "    turb_flux_field_df[3]['uw']['u_h2o_'] + turb_flux_field_df[10]['uw']['u_h2o_']\n",
    ")\n",
    "\n",
    "face3_avg_v_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[3]['ue']['v_h2o_'] + turb_flux_field_df[10]['ue']['v_h2o_'] + \n",
    "    turb_flux_field_df[3]['uw']['v_h2o_'] + turb_flux_field_df[10]['uw']['v_h2o_']\n",
    ")\n",
    "\n",
    "face4_avg_w_turb_flux = 0.25*(\n",
    "    turb_flux_field_df[10]['ue']['w_h2o_'] + turb_flux_field_df[10]['uw']['w_h2o_'] + \n",
    "    turb_flux_field_df[10]['c']['w_h2o_'] + turb_flux_field_df[10]['d']['w_h2o_']\n",
    ")\n",
    "\n",
    "face5_avg_w_turb_flux = - 0.25*(\n",
    "    turb_flux_field_df[3]['ue']['w_h2o_'] + turb_flux_field_df[3]['uw']['w_h2o_'] + \n",
    "    turb_flux_field_df[3]['c']['w_h2o_'] + turb_flux_field_df[3]['d']['w_h2o_']\n",
    ")\n",
    "\n",
    "# Combine the (separate) u and v components into a list of vectors for the lateral faces\n",
    "face1_avg_adv_flux = np.array([\n",
    "    face1_avg_u_turb_flux,\n",
    "    face1_avg_v_turb_flux\n",
    "]).T\n",
    "\n",
    "face2_avg_adv_flux = np.array([\n",
    "    face2_avg_u_turb_flux,\n",
    "    face2_avg_v_turb_flux\n",
    "]).T\n",
    "\n",
    "face3_avg_adv_flux = np.array([\n",
    "    face3_avg_u_turb_flux,\n",
    "    face3_avg_v_turb_flux\n",
    "]).T\n",
    "\n",
    "# Project the lateral flux vectors onto the face-normal vectors\n",
    "face1_projected_turb_flux = np.dot(face1_avg_adv_flux, n1.m)\n",
    "face2_projected_turb_flux = np.dot(face2_avg_adv_flux, n2.m)\n",
    "face3_projected_turb_flux = np.dot(face3_avg_adv_flux, n3.m)\n",
    "\n",
    "# Calculate total lateral and vertical flux\n",
    "total_lateral_turb_divergence = (\n",
    "    face1_projected_turb_flux*A1.m + \n",
    "    face2_projected_turb_flux*A2.m + \n",
    "    face3_projected_turb_flux*A3.m\n",
    ") / VOLUME.m\n",
    "\n",
    "total_vertical_turb_divergence = (face4_avg_w_turb_flux*A4 + face5_avg_w_turb_flux*A5)  / VOLUME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((\n",
    "    alt.Chart(\n",
    "        pd.DataFrame(total_vertical_turb_divergence).reset_index()\n",
    "    ).mark_line().encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('median(w_h2o_):Q')\n",
    "    )\n",
    ").properties(title='Vertical Turb. Flux Divergence') | (\n",
    "    alt.Chart(\n",
    "        pd.DataFrame(total_lateral_turb_divergence).reset_index().assign(time=total_vertical_turb_divergence.index).rename(columns={0:'u_q_'})\n",
    "    ).mark_line().encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('median(u_q_):Q')\n",
    "    )\n",
    ").properties(title='Lateral Turb. Flux Divergence')).resolve_scale(y='shared', x='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((\n",
    "    alt.Chart(\n",
    "        pd.DataFrame(total_vertical_adv_divergence).reset_index()\n",
    "    ).mark_line().encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('mean(wq):Q')\n",
    "    )\n",
    "    +\n",
    "    alt.Chart(\n",
    "        pd.DataFrame(total_vertical_adv_divergence).reset_index()\n",
    "    ).mark_line(color='red').encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('median(wq):Q')\n",
    "    )\n",
    ").properties(title='Vertical Advection') | (\n",
    "    alt.Chart(\n",
    "        pd.DataFrame(total_lateral_adv_divergence).reset_index().assign(time=total_vertical_adv_divergence.index).rename(columns={0:'uq'})\n",
    "    ).mark_line().encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('mean(uq):Q')\n",
    "    )\n",
    "    +\n",
    "    alt.Chart(\n",
    "        pd.DataFrame(total_lateral_adv_divergence).reset_index().assign(time=total_vertical_adv_divergence.index).rename(columns={0:'uq'})\n",
    "    ).mark_line(color='red').encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('median(uq):Q')\n",
    "    )\n",
    ").properties(title='Lateral Advection')).resolve_scale(y='shared', x='shared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform planar fitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply multiple algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sublimpy import extrautils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot original w (planar fitted in preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\").set_index('time')\n",
    "vertical_velocities_normal_planar_fit_chart = alt.Chart(src[src.index.isin(upvalley_wind_times)].reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150) | alt.Chart(src[src.index.isin(downvalley_wind_times)].reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150)\n",
    "vertical_velocities_normal_planar_fit_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planar fit per month, split between downvalley, upvalley, and otherwise winds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planar_fitted_valleydir_dfs = []\n",
    "variable_sets = [\n",
    "    # ('u_1m_c', 'v_1m_c', 'w_1m_c'),\n",
    "    ('u_2m_c', 'v_2m_c', 'w_2m_c'),\n",
    "    ('u_3m_c',   'v_3m_c',   'w_3m_c'),\n",
    "    ('u_5m_c',   'v_5m_c',   'w_5m_c'),\n",
    "    ('u_10m_c',   'v_10m_c',   'w_10m_c'),\n",
    "    ('u_15m_c',   'v_15m_c',   'w_15m_c'),\n",
    "    ('u_20m_c',   'v_20m_c',   'w_20m_c'),\n",
    "    \n",
    "    # ('u_1m_uw', 'v_1m_uw', 'w_1m_uw'),\n",
    "    # ('u_2m_uw', 'v_2m_uw', 'w_2m_uw'),\n",
    "    # ('u_2_5m_uw', 'v_2_5m_uw', 'w_2_5m_uw'),\n",
    "    ('u_3m_uw',   'v_3m_uw',   'w_3m_uw'),\n",
    "    ('u_10m_uw',   'v_10m_uw',   'w_10m_uw'),\n",
    "    \n",
    "    # ('u_1m_ue', 'v_1m_ue', 'w_1m_ue'),\n",
    "    # ('u_2m_ue', 'v_2m_ue', 'w_2m_ue'),\n",
    "    ('u_3m_ue',   'v_3m_ue',   'w_3m_ue'),\n",
    "    ('u_10m_ue',   'v_10m_ue',   'w_10m_ue'),\n",
    "\n",
    "    # ('u_1m_d', 'v_1m_d', 'w_1m_d'),\n",
    "    # ('u_2m_d', 'v_2m_d', 'w_2m_d'),\n",
    "    ('u_3m_d',   'v_3m_d',   'w_3m_d'),\n",
    "    ('u_10m_d',   'v_10m_d',   'w_10m_d'),\n",
    "]\n",
    "VARIABLE_NAMES = list(np.array(variable_sets).flatten())\n",
    "for month,year in [\n",
    "    (11,2022),\n",
    "    (12,2022),\n",
    "    (1,2023),\n",
    "    (2,2023),\n",
    "    (3,2023),\n",
    "    (4,2023),\n",
    "    (5,2023),\n",
    "    (6,2023),\n",
    "]:\n",
    "    for u_VAR, v_VAR, w_VAR in variable_sets:\n",
    "        src = tidy_df[tidy_df.variable.isin([u_VAR, v_VAR, w_VAR])].pivot(\n",
    "            index='time',\n",
    "            columns='variable',\n",
    "            values='value'\n",
    "        )\n",
    "        src_upvalley = src[src.index.isin(upvalley_wind_times)]\n",
    "        src_downvalley = src[src.index.isin(downvalley_wind_times)]\n",
    "        src_otherwise = src[\n",
    "            (~src.index.isin(upvalley_wind_times))\n",
    "            & (~src.index.isin(downvalley_wind_times))\n",
    "        ]\n",
    "        \n",
    "        # we are repeating all this thrice...\n",
    "        if len(src_upvalley.dropna()) > 0:\n",
    "            src_upvalley = src_upvalley[src_upvalley.index.month == month]\n",
    "            src_upvalley = src_upvalley[src_upvalley.index.year == year]\n",
    "            u,v,w = extrautils.calculate_and_apply_planar_fit(\n",
    "            src_upvalley[u_VAR], src_upvalley[v_VAR], src_upvalley[w_VAR]\n",
    "            )\n",
    "            src_upvalley[u_VAR] = u\n",
    "            src_upvalley[v_VAR] = v\n",
    "            src_upvalley[w_VAR] = w\n",
    "            src_upvalley = src_upvalley.melt(ignore_index=False)\n",
    "            src_upvalley['height'] = src_upvalley.variable.apply(tidy._height_from_variable_name)\n",
    "            src_upvalley['measurement'] = src_upvalley.variable.apply(tidy._measurement_from_variable_name)\n",
    "            src_upvalley['tower'] = src_upvalley.variable.apply(tidy._tower_from_variable_name)\n",
    "            planar_fitted_valleydir_dfs.append(src_upvalley)\n",
    "\n",
    "        # we are repeating all this thrice...\n",
    "        if len(src_downvalley.dropna()) > 0:\n",
    "            src_downvalley = src_downvalley[src_downvalley.index.month == month]\n",
    "            src_downvalley = src_downvalley[src_downvalley.index.year == year]\n",
    "            u,v,w = extrautils.calculate_and_apply_planar_fit(\n",
    "            src_downvalley[u_VAR], src_downvalley[v_VAR], src_downvalley[w_VAR]\n",
    "            )\n",
    "            src_downvalley[u_VAR] = u\n",
    "            src_downvalley[v_VAR] = v\n",
    "            src_downvalley[w_VAR] = w\n",
    "            src_downvalley = src_downvalley.melt(ignore_index=False)\n",
    "            src_downvalley['height'] = src_downvalley.variable.apply(tidy._height_from_variable_name)\n",
    "            src_downvalley['measurement'] = src_downvalley.variable.apply(tidy._measurement_from_variable_name)\n",
    "            src_downvalley['tower'] = src_downvalley.variable.apply(tidy._tower_from_variable_name)\n",
    "            planar_fitted_valleydir_dfs.append(src_downvalley)\n",
    "\n",
    "        # we are repeating all this thrice...\n",
    "        if len(src_otherwise.dropna()) > 0:\n",
    "            src_otherwise = src_otherwise[src_otherwise.index.month == month]\n",
    "            src_otherwise = src_otherwise[src_otherwise.index.year == year]\n",
    "            u,v,w = extrautils.calculate_and_apply_planar_fit(\n",
    "            src_otherwise[u_VAR], src_otherwise[v_VAR], src_otherwise[w_VAR]\n",
    "            )\n",
    "            src_otherwise[u_VAR] = u\n",
    "            src_otherwise[v_VAR] = v\n",
    "            src_otherwise[w_VAR] = w\n",
    "            src_otherwise = src_otherwise.melt(ignore_index=False)\n",
    "            src_otherwise['height'] = src_otherwise.variable.apply(tidy._height_from_variable_name)\n",
    "            src_otherwise['measurement'] = src_otherwise.variable.apply(tidy._measurement_from_variable_name)\n",
    "            src_otherwise['tower'] = src_otherwise.variable.apply(tidy._tower_from_variable_name)\n",
    "            planar_fitted_valleydir_dfs.append(src_otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planar fit per month, split into 30˚ sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_wind_dir = 270 -np.rad2deg(np.arctan2(\n",
    "    tidy_df.query(\"variable == 'v_3m_c'\").set_index('time').value,\n",
    "    tidy_df.query(\"variable == 'u_3m_c'\").set_index('time').value,\n",
    "))\n",
    "calculated_wind_dir = calculated_wind_dir.apply(lambda v: v - 360 if v > 360 else v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_wind_dir.loc[:'20221115'].plot()\n",
    "tidy_df.query(\"variable == 'dir_3m_c'\").set_index('time').loc[:'20221115'].value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_bins = pd.cut(\n",
    "    tidy_df.query(\"variable == 'dir_3m_c'\").set_index('time')['value'],\n",
    "    bins = np.arange(0, 390, 30)\n",
    ")\n",
    "grouped_indices = wind_dir_bins.groupby(wind_dir_bins).apply(lambda x: x.index.tolist())\n",
    "for interval, timestamps in grouped_indices.items():\n",
    "    print(interval, '\\t', len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Planar fit per month, split between downvalley, upvalley, and otherwise winds\n",
    "planar_fitted_sector30_dfs = []\n",
    "variable_sets = [\n",
    "    # ('u_1m_c', 'v_1m_c', 'w_1m_c'),\n",
    "    ('u_2m_c', 'v_2m_c', 'w_2m_c'),\n",
    "    ('u_3m_c',   'v_3m_c',   'w_3m_c'),\n",
    "    ('u_5m_c',   'v_5m_c',   'w_5m_c'),\n",
    "    ('u_10m_c',   'v_10m_c',   'w_10m_c'),\n",
    "    ('u_15m_c',   'v_15m_c',   'w_15m_c'),\n",
    "    ('u_20m_c',   'v_20m_c',   'w_20m_c'),\n",
    "    \n",
    "    # ('u_1m_uw', 'v_1m_uw', 'w_1m_uw'),\n",
    "    # ('u_2m_uw', 'v_2m_uw', 'w_2m_uw'),\n",
    "    # ('u_2_5m_uw', 'v_2_5m_uw', 'w_2_5m_uw'),\n",
    "    ('u_3m_uw',   'v_3m_uw',   'w_3m_uw'),\n",
    "    ('u_10m_uw',   'v_10m_uw',   'w_10m_uw'),\n",
    "    \n",
    "    # ('u_1m_ue', 'v_1m_ue', 'w_1m_ue'),\n",
    "    # ('u_2m_ue', 'v_2m_ue', 'w_2m_ue'),\n",
    "    ('u_3m_ue',   'v_3m_ue',   'w_3m_ue'),\n",
    "    ('u_10m_ue',   'v_10m_ue',   'w_10m_ue'),\n",
    "\n",
    "    # ('u_1m_d', 'v_1m_d', 'w_1m_d'),\n",
    "    # ('u_2m_d', 'v_2m_d', 'w_2m_d'),\n",
    "    ('u_3m_d',   'v_3m_d',   'w_3m_d'),\n",
    "    ('u_10m_d',   'v_10m_d',   'w_10m_d'),\n",
    "]\n",
    "VARIABLE_NAMES = list(np.array(variable_sets).flatten())\n",
    "for month,year in [\n",
    "    (11,2022),\n",
    "    (12,2022),\n",
    "    (1,2023),\n",
    "    (2,2023),\n",
    "    (3,2023),\n",
    "    (4,2023),\n",
    "    (5,2023),\n",
    "    (6,2023),\n",
    "]:\n",
    "    for u_VAR, v_VAR, w_VAR in variable_sets:\n",
    "        for interval, timestamps in grouped_indices.items():\n",
    "            src = tidy_df[tidy_df.variable.isin([u_VAR, v_VAR, w_VAR])].pivot(\n",
    "                index='time',\n",
    "                columns='variable',\n",
    "                values='value'\n",
    "            )\n",
    "            src = src[src.index.isin(timestamps)]\n",
    "            src = src[src.index.month == month]\n",
    "            src = src[src.index.year == year]\n",
    "            if len(src.dropna()) > 0:\n",
    "                u,v,w = extrautils.calculate_and_apply_planar_fit(\n",
    "                    src[u_VAR], src[v_VAR], src[w_VAR]\n",
    "                )\n",
    "                src[u_VAR] = u\n",
    "                src[v_VAR] = v\n",
    "                src[w_VAR] = w\n",
    "                src = src.melt(ignore_index=False)\n",
    "                src['height'] = src.variable.apply(tidy._height_from_variable_name)\n",
    "                src['measurement'] = src.variable.apply(tidy._measurement_from_variable_name)\n",
    "                src['tower'] = src.variable.apply(tidy._tower_from_variable_name)\n",
    "                planar_fitted_sector30_dfs.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planar fit per month, split into 60˚ sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 420, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_bins = pd.cut(\n",
    "    tidy_df.query(\"variable == 'dir_3m_c'\").set_index('time')['value'],\n",
    "    bins = np.arange(0, 420, 60)\n",
    ")\n",
    "grouped_indices = wind_dir_bins.groupby(wind_dir_bins).apply(lambda x: x.index.tolist())\n",
    "for interval, timestamps in grouped_indices.items():\n",
    "    print(interval, '\\t', len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Planar fit per month, split between downvalley, upvalley, and otherwise winds\n",
    "planar_fitted_sector60_dfs = []\n",
    "variable_sets = [\n",
    "    # ('u_1m_c', 'v_1m_c', 'w_1m_c'),\n",
    "    ('u_2m_c', 'v_2m_c', 'w_2m_c'),\n",
    "    ('u_3m_c',   'v_3m_c',   'w_3m_c'),\n",
    "    ('u_5m_c',   'v_5m_c',   'w_5m_c'),\n",
    "    ('u_10m_c',   'v_10m_c',   'w_10m_c'),\n",
    "    ('u_15m_c',   'v_15m_c',   'w_15m_c'),\n",
    "    ('u_20m_c',   'v_20m_c',   'w_20m_c'),\n",
    "    \n",
    "    # ('u_1m_uw', 'v_1m_uw', 'w_1m_uw'),\n",
    "    # ('u_2m_uw', 'v_2m_uw', 'w_2m_uw'),\n",
    "    # ('u_2_5m_uw', 'v_2_5m_uw', 'w_2_5m_uw'),\n",
    "    ('u_3m_uw',   'v_3m_uw',   'w_3m_uw'),\n",
    "    ('u_10m_uw',   'v_10m_uw',   'w_10m_uw'),\n",
    "    \n",
    "    # ('u_1m_ue', 'v_1m_ue', 'w_1m_ue'),\n",
    "    # ('u_2m_ue', 'v_2m_ue', 'w_2m_ue'),\n",
    "    ('u_3m_ue',   'v_3m_ue',   'w_3m_ue'),\n",
    "    ('u_10m_ue',   'v_10m_ue',   'w_10m_ue'),\n",
    "\n",
    "    # ('u_1m_d', 'v_1m_d', 'w_1m_d'),\n",
    "    # ('u_2m_d', 'v_2m_d', 'w_2m_d'),\n",
    "    ('u_3m_d',   'v_3m_d',   'w_3m_d'),\n",
    "    ('u_10m_d',   'v_10m_d',   'w_10m_d'),\n",
    "]\n",
    "VARIABLE_NAMES = list(np.array(variable_sets).flatten())\n",
    "for month,year in [\n",
    "    (11,2022),\n",
    "    (12,2022),\n",
    "    (1,2023),\n",
    "    (2,2023),\n",
    "    (3,2023),\n",
    "    (4,2023),\n",
    "    (5,2023),\n",
    "    (6,2023),\n",
    "]:\n",
    "    for u_VAR, v_VAR, w_VAR in variable_sets:\n",
    "        for interval, timestamps in grouped_indices.items():\n",
    "            src = tidy_df[tidy_df.variable.isin([u_VAR, v_VAR, w_VAR])].pivot(\n",
    "                index='time',\n",
    "                columns='variable',\n",
    "                values='value'\n",
    "            )\n",
    "            src = src[src.index.isin(timestamps)]\n",
    "            src = src[src.index.month == month]\n",
    "            src = src[src.index.year == year]\n",
    "            if len(src.dropna()) > 0:\n",
    "                u,v,w = extrautils.calculate_and_apply_planar_fit(\n",
    "                    src[u_VAR], src[v_VAR], src[w_VAR]\n",
    "                )\n",
    "                src[u_VAR] = u\n",
    "                src[v_VAR] = v\n",
    "                src[w_VAR] = w\n",
    "                src = src.melt(ignore_index=False)\n",
    "                src['height'] = src.variable.apply(tidy._height_from_variable_name)\n",
    "                src['measurement'] = src.variable.apply(tidy._measurement_from_variable_name)\n",
    "                src['tower'] = src.variable.apply(tidy._tower_from_variable_name)\n",
    "                planar_fitted_sector60_dfs.append(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Planar fit per month, split into 10˚ sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_bins = pd.cut(\n",
    "    tidy_df.query(\"variable == 'dir_3m_c'\").set_index('time')['value'],\n",
    "    bins = np.arange(0, 370, 10)\n",
    ")\n",
    "grouped_indices = wind_dir_bins.groupby(wind_dir_bins).apply(lambda x: x.index.tolist())\n",
    "for interval, timestamps in grouped_indices.items():\n",
    "    print(interval, '\\t', len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Planar fit per month, split between downvalley, upvalley, and otherwise winds\n",
    "planar_fitted_sector10_dfs = []\n",
    "variable_sets = [\n",
    "    # ('u_1m_c', 'v_1m_c', 'w_1m_c'),\n",
    "    ('u_2m_c', 'v_2m_c', 'w_2m_c'),\n",
    "    ('u_3m_c',   'v_3m_c',   'w_3m_c'),\n",
    "    ('u_5m_c',   'v_5m_c',   'w_5m_c'),\n",
    "    ('u_10m_c',   'v_10m_c',   'w_10m_c'),\n",
    "    ('u_15m_c',   'v_15m_c',   'w_15m_c'),\n",
    "    ('u_20m_c',   'v_20m_c',   'w_20m_c'),\n",
    "    \n",
    "    # ('u_1m_uw', 'v_1m_uw', 'w_1m_uw'),\n",
    "    # ('u_2m_uw', 'v_2m_uw', 'w_2m_uw'),\n",
    "    # ('u_2_5m_uw', 'v_2_5m_uw', 'w_2_5m_uw'),\n",
    "    ('u_3m_uw',   'v_3m_uw',   'w_3m_uw'),\n",
    "    ('u_10m_uw',   'v_10m_uw',   'w_10m_uw'),\n",
    "    \n",
    "    # ('u_1m_ue', 'v_1m_ue', 'w_1m_ue'),\n",
    "    # ('u_2m_ue', 'v_2m_ue', 'w_2m_ue'),\n",
    "    ('u_3m_ue',   'v_3m_ue',   'w_3m_ue'),\n",
    "    ('u_10m_ue',   'v_10m_ue',   'w_10m_ue'),\n",
    "\n",
    "    # ('u_1m_d', 'v_1m_d', 'w_1m_d'),\n",
    "    # ('u_2m_d', 'v_2m_d', 'w_2m_d'),\n",
    "    ('u_3m_d',   'v_3m_d',   'w_3m_d'),\n",
    "    ('u_10m_d',   'v_10m_d',   'w_10m_d'),\n",
    "]\n",
    "VARIABLE_NAMES = list(np.array(variable_sets).flatten())\n",
    "for month,year in [\n",
    "    (11,2022),\n",
    "    (12,2022),\n",
    "    (1,2023),\n",
    "    (2,2023),\n",
    "    (3,2023),\n",
    "    (4,2023),\n",
    "    (5,2023),\n",
    "    (6,2023),\n",
    "]:\n",
    "    for u_VAR, v_VAR, w_VAR in variable_sets:\n",
    "        for interval, timestamps in grouped_indices.items():\n",
    "            src = tidy_df[tidy_df.variable.isin([u_VAR, v_VAR, w_VAR])].pivot(\n",
    "                index='time',\n",
    "                columns='variable',\n",
    "                values='value'\n",
    "            )\n",
    "            #############################################\n",
    "            ## EXPERIMENTAL\n",
    "            #############################################\n",
    "            src = src[src.index.isin(winds_times_1to2)]\n",
    "            #############################################\n",
    "            #############################################\n",
    "            src = src[src.index.isin(timestamps)]\n",
    "            src = src[src.index.month == month]\n",
    "            src = src[src.index.year == year]\n",
    "            if len(src.dropna()) > 0:\n",
    "                u,v,w = extrautils.calculate_and_apply_planar_fit(\n",
    "                    src[u_VAR], src[v_VAR], src[w_VAR]\n",
    "                )\n",
    "                src[u_VAR] = u\n",
    "                src[v_VAR] = v\n",
    "                src[w_VAR] = w\n",
    "                src = src.melt(ignore_index=False)\n",
    "                src['height'] = src.variable.apply(tidy._height_from_variable_name)\n",
    "                src['measurement'] = src.variable.apply(tidy._measurement_from_variable_name)\n",
    "                src['tower'] = src.variable.apply(tidy._tower_from_variable_name)\n",
    "                planar_fitted_sector10_dfs.append(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planar_fitted_valleydir_df = pd.concat(planar_fitted_valleydir_dfs).reset_index()\n",
    "planar_fitted_sector30_df = pd.concat(planar_fitted_sector30_dfs).reset_index()\n",
    "planar_fitted_sector60_df = pd.concat(planar_fitted_sector60_dfs).reset_index()\n",
    "planar_fitted_sector10_df = pd.concat(planar_fitted_sector10_dfs).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = planar_fitted_valleydir_df[planar_fitted_valleydir_df.measurement == 'w'].query(\"tower == 'c'\").set_index('time')\n",
    "\n",
    "vertical_velocities_valleydir_planar_fit_chart = alt.Chart(\n",
    "    src[src.index.isin(upvalley_wind_times)].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150) | alt.Chart(src[src.index.isin(downvalley_wind_times)].reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = planar_fitted_sector30_df[planar_fitted_sector30_df.measurement == 'w'].query(\"tower == 'c'\").set_index('time')\n",
    "\n",
    "vertical_velocities_sector30_planar_fit_chart = alt.Chart(\n",
    "    src[src.index.isin(upvalley_wind_times)].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150) | alt.Chart(src[src.index.isin(downvalley_wind_times)].reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = planar_fitted_sector60_df[planar_fitted_sector60_df.measurement == 'w'].query(\"tower == 'c'\").set_index('time')\n",
    "\n",
    "vertical_velocities_sector60_planar_fit_chart = alt.Chart(\n",
    "    src[src.index.isin(upvalley_wind_times)].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150) | alt.Chart(src[src.index.isin(downvalley_wind_times)].reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = planar_fitted_sector10_df[planar_fitted_sector10_df.measurement == 'w'].query(\"tower == 'c'\").set_index('time')\n",
    "\n",
    "vertical_velocities_sector10_planar_fit_chart = alt.Chart(\n",
    "    src[src.index.isin(upvalley_wind_times)].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150) | alt.Chart(src[src.index.isin(downvalley_wind_times)].reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('median(value):Q'),\n",
    "    alt.Color('height:O').scale(scheme='rainbow')\n",
    ").properties(width=300, height = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    vertical_velocities_normal_planar_fit_chart.properties(title='Planar fit: Monthly').resolve_scale(\n",
    "        x='shared',\n",
    "        y='shared',\n",
    "        color='shared'\n",
    "    )\n",
    "    & \n",
    "    vertical_velocities_valleydir_planar_fit_chart.properties(title='Planar fit: Monthly + 3 sectors').resolve_scale(\n",
    "        x='shared',\n",
    "        y='shared',\n",
    "        color='shared'\n",
    "    )\n",
    "    & \n",
    "    vertical_velocities_sector30_planar_fit_chart.properties(title='Planar fit: Monthly + 12 sectors').resolve_scale(\n",
    "        x='shared',\n",
    "        y='shared',\n",
    "        color='shared'\n",
    "    )\n",
    "    & \n",
    "    vertical_velocities_sector60_planar_fit_chart.properties(title='Planar fit: Monthly + 6 sectors').resolve_scale(\n",
    "        x='shared',\n",
    "        y='shared',\n",
    "        color='shared'\n",
    "    )\n",
    "    & \n",
    "    vertical_velocities_sector10_planar_fit_chart.properties(title='Planar fit: Monthly + 36 sectors').resolve_scale(\n",
    "        x='shared',\n",
    "        y='shared',\n",
    "        color='shared'\n",
    "    )\n",
    ").resolve_scale(\n",
    "    x='shared',\n",
    "    y='shared',\n",
    "    color='shared'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets with different planar fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original w variables that we'll add back in later \n",
    "planar_fitted_original_df = tidy_df[tidy_df.variable.isin(\n",
    "    planar_fitted_valleydir_df.variable.unique()\n",
    ")]\n",
    "\n",
    "# drop variables that we have sectorial-planar-fitted\n",
    "# THIS COMMAND NEEDS TO BE RUN SECOND\n",
    "tidy_df = tidy_df[~tidy_df.variable.isin(\n",
    "    planar_fitted_valleydir_df.variable.unique()\n",
    ")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df_pf_valleydir = pd.concat([\n",
    "    tidy_df,\n",
    "    planar_fitted_valleydir_df\n",
    "])\n",
    "\n",
    "tidy_df_pf_sector30 = pd.concat([\n",
    "    tidy_df,\n",
    "    planar_fitted_sector30_df\n",
    "])\n",
    "\n",
    "tidy_df_pf_sector60 = pd.concat([\n",
    "    tidy_df,\n",
    "    planar_fitted_sector60_df\n",
    "])\n",
    "\n",
    "tidy_df_pf_sector10 = pd.concat([\n",
    "    tidy_df,\n",
    "    planar_fitted_sector10_df\n",
    "])\n",
    "\n",
    "# THIS COMMAND NEEDS TO RUN LAST\n",
    "# so we dont add multiple versions of w variables to dataframes created above\n",
    "tidy_df = pd.concat([\n",
    "    tidy_df,\n",
    "    planar_fitted_original_df\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D continuous solution for vertical advection (new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect mixing ratio data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolate humidity measurements (from hygrometers)\n",
    "mixing_ratio_profile_df = tidy_df[tidy_df.measurement.isin(['mixing ratio'])]\n",
    "mixing_ratio_profile_df.measurement = 'q_hygr'\n",
    "mixing_ratio_profile_df = mixing_ratio_profile_df.pivot_table(\n",
    "        index='time', columns=['height', 'tower', 'measurement'], values='value'\n",
    "    )\n",
    "\n",
    "# Combine with snow depth data\n",
    "mixing_ratio_profile_df = mixing_ratio_profile_df.melt(ignore_index=False).join(\n",
    "    tidy_df[tidy_df.variable == 'SnowDepth_c'].set_index('time')['value'].rename('snow depth')\n",
    ")\n",
    "\n",
    "# Calculate instrument height above snow surface\n",
    "mixing_ratio_profile_df['instrument_height'] = mixing_ratio_profile_df['height'] - mixing_ratio_profile_df['snow depth']\n",
    "\n",
    "# Filter out measurements that are buried in the snow\n",
    "mixing_ratio_profile_df = mixing_ratio_profile_df[\n",
    "    (mixing_ratio_profile_df['instrument_height'] > 0)\n",
    "    | (mixing_ratio_profile_df['height'] == 0)\n",
    "]\n",
    "\n",
    "mixing_ratio_profile_df['instrument_height'] = mixing_ratio_profile_df['instrument_height'].where(\n",
    "    mixing_ratio_profile_df['instrument_height'] > 0,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to calculate gradient for a given set of heights and mixingratio measurements (for single timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sublimpy.gradients import LogPolynomialWithRoughness\n",
    "\n",
    "def calculate_mixingratio_gradient(\n",
    "        one_ts_groupby,\n",
    "        height4estimate,\n",
    "        Z0Q = 0.005\n",
    "    ):\n",
    "    \"\"\" \n",
    "    Calculates mixing ratio gradient from a dataframe with datetimeindex,\n",
    "    and columns `instrument_height`  and `value`, which holds mixing ratio\n",
    "    values. These calculations are done by fitting log-polynomial curve to \n",
    "    measurements of z and X where X is some measured variable.\n",
    "    We include a boundary wall condition, applying measured X at\n",
    "    roughness height (T=T_s at z=z0). We also adjust for snow depth \n",
    "    in our calculations.\n",
    "    \"\"\"    \n",
    "    heights = one_ts_groupby.sort_values('instrument_height')['instrument_height']\n",
    "    values = one_ts_groupby.sort_values('instrument_height')['value']\n",
    "\n",
    "    heights = heights.replace(0,Z0Q)\n",
    "\n",
    "    # calculate fitted loglinear parameters\n",
    "    params = LogPolynomialWithRoughness.fit_function(\n",
    "        values,\n",
    "        heights\n",
    "    )\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    gradient = LogPolynomialWithRoughness.gradient_single_component(height4estimate, a, b)\n",
    "    return gradient, a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the function out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient, a, b =  calculate_mixingratio_gradient(\n",
    "    mixing_ratio_profile_df.groupby('time').get_group('2023-05-05 12:30:00'),\n",
    "    3   \n",
    ")\n",
    "heights = mixing_ratio_profile_df.groupby('time').get_group('2023-05-05 12:30:00').instrument_height\n",
    "values = mixing_ratio_profile_df.groupby('time').get_group('2023-05-05 12:30:00').value\n",
    "c = values[0]\n",
    "heights_fit = pd.Series(np.linspace(0,20,100))\n",
    "values_fit = heights_fit.apply( lambda z:\n",
    "    LogPolynomialWithRoughness.function(z, a, b, c)\n",
    ")\n",
    "plt.plot(values_fit, heights_fit)\n",
    "plt.scatter(values, heights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $d\\sigma/dz$ for all timestamps, tower measurements at all heights >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dsigma_dz_values_for_height(H):\n",
    "    dsigma_dz = mixing_ratio_profile_df.reset_index().swifter.groupby('time').apply(\n",
    "        lambda df: calculate_mixingratio_gradient(df, H)\n",
    "    )\n",
    "    dsigma_dz = pd.DataFrame(dsigma_dz.tolist()).rename(columns={\n",
    "        0: 'dsigma_dz',\n",
    "        1: 'fit_param_a',\n",
    "        2: 'fit_param_b',\n",
    "    }).assign(time = dsigma_dz.index).set_index('time')\n",
    "\n",
    "    return dsigma_dz.drop_duplicates()\n",
    "\n",
    "def add_variables_to_dsigma_dz_values(H, dsigma_dz_values, tidy_df_specific_pf):\n",
    "    return dsigma_dz_values.join(\n",
    "        tidy_df_specific_pf.query(f\"variable == 'w_{H}m_c'\").set_index('time')['value'].rename('w')\n",
    "    ).join(\n",
    "        tidy_df_specific_pf.query(f\"variable == 'airdensity_{H}m_c'\").set_index('time')['value'].rename('rho_d')\n",
    "    ).join(\n",
    "        tidy_df_specific_pf.query(f\"variable == 'w_h2o__{H}m_c_gapfill'\").set_index('time')['value'].rename('w_h2o__')\n",
    "    )\n",
    "\n",
    "def calculate_transport_terms_with_dsigma_dz(H, dsigma_dz_values):\n",
    "    dsigma_dz_values['vertical_advection'] = dsigma_dz_values['w']*dsigma_dz_values['rho_d']*dsigma_dz_values['dsigma_dz']*1000\n",
    "    dsigma_dz_values['w_h2o__corrected'] = (dsigma_dz_values['w_h2o__'] + dsigma_dz_values['vertical_advection']*H)\n",
    "    return dsigma_dz_values\n",
    "\n",
    "def get_advection_and_cumsum_df(H, tidy_df_specific_pf):\n",
    "    df = get_dsigma_dz_values_for_height(H)\n",
    "    df = add_variables_to_dsigma_dz_values(H, df, tidy_df_specific_pf) \n",
    "    df = calculate_transport_terms_with_dsigma_dz(H, df)\n",
    "\n",
    "    cumsum_df = df.loc['20221130': '20230509']\n",
    "    cumsum_df['w_h2o___cumsum'] = cumsum_df['w_h2o__'].cumsum()\n",
    "    cumsum_df['w_h2o__corrected_cumsum'] = cumsum_df['w_h2o__corrected'].cumsum()\n",
    "    return df, cumsum_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3 sector\n",
    "dsigma_dz_values_for_height_pf_og = {\n",
    "    2:      get_advection_and_cumsum_df(2,     tidy_df),\n",
    "    3:      get_advection_and_cumsum_df(3,     tidy_df),\n",
    "    5:      get_advection_and_cumsum_df(5,     tidy_df),\n",
    "    10:     get_advection_and_cumsum_df(10,    tidy_df),\n",
    "    15:     get_advection_and_cumsum_df(15,    tidy_df),\n",
    "    20:     get_advection_and_cumsum_df(20,    tidy_df),\n",
    "}\n",
    "vertical_advection_estimates_pf_og = pd.concat([\n",
    "    df[0].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_og.items()\n",
    "])\n",
    "cumsub_vertical_advection_correction_estimates_pf_og = pd.concat([\n",
    "    df[1].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_og.items()\n",
    "])\n",
    "\n",
    "# ### 3 sector\n",
    "# dsigma_dz_values_for_height_pf_valleydir = {\n",
    "#     2:      get_advection_and_cumsum_df(2,     tidy_df_pf_valleydir),\n",
    "#     3:      get_advection_and_cumsum_df(3,     tidy_df_pf_valleydir),\n",
    "#     5:      get_advection_and_cumsum_df(5,     tidy_df_pf_valleydir),\n",
    "#     10:     get_advection_and_cumsum_df(10,    tidy_df_pf_valleydir),\n",
    "#     15:     get_advection_and_cumsum_df(15,    tidy_df_pf_valleydir),\n",
    "#     20:     get_advection_and_cumsum_df(20,    tidy_df_pf_valleydir),\n",
    "# }\n",
    "# vertical_advection_estimates_pf_valleydir = pd.concat([\n",
    "#     df[0].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_valleydir.items()\n",
    "# ])\n",
    "# cumsub_vertical_advection_correction_estimates_pf_valleydir = pd.concat([\n",
    "#     df[1].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_valleydir.items()\n",
    "# ])\n",
    "\n",
    "# ### 12 sector\n",
    "# dsigma_dz_values_for_height_pf_sector30 = {\n",
    "#     2:      get_advection_and_cumsum_df(2,     tidy_df_pf_sector30),\n",
    "#     3:      get_advection_and_cumsum_df(3,     tidy_df_pf_sector30),\n",
    "#     5:      get_advection_and_cumsum_df(5,     tidy_df_pf_sector30),\n",
    "#     10:     get_advection_and_cumsum_df(10,    tidy_df_pf_sector30),\n",
    "#     15:     get_advection_and_cumsum_df(15,    tidy_df_pf_sector30),\n",
    "#     20:     get_advection_and_cumsum_df(20,    tidy_df_pf_sector30),\n",
    "# }\n",
    "# vertical_advection_estimates_pf_sector30 = pd.concat([\n",
    "#     df[0].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_sector30.items()\n",
    "# ])\n",
    "# cumsub_vertical_advection_correction_estimates_pf_sector30 = pd.concat([\n",
    "#     df[1].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_sector30.items()\n",
    "# ])\n",
    "\n",
    "# ### 6 sector\n",
    "# dsigma_dz_values_for_height_pf_sector60 = {\n",
    "#     2:      get_advection_and_cumsum_df(2,     tidy_df_pf_sector60),\n",
    "#     3:      get_advection_and_cumsum_df(3,     tidy_df_pf_sector60),\n",
    "#     5:      get_advection_and_cumsum_df(5,     tidy_df_pf_sector60),\n",
    "#     10:     get_advection_and_cumsum_df(10,    tidy_df_pf_sector60),\n",
    "#     15:     get_advection_and_cumsum_df(15,    tidy_df_pf_sector60),\n",
    "#     20:     get_advection_and_cumsum_df(20,    tidy_df_pf_sector60),\n",
    "# }\n",
    "# vertical_advection_estimates_pf_sector60 = pd.concat([\n",
    "#     df[0].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_sector60.items()\n",
    "# ])\n",
    "# cumsub_vertical_advection_correction_estimates_pf_sector60 = pd.concat([\n",
    "#     df[1].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_sector60.items()\n",
    "# ])\n",
    "\n",
    "# ### 36 sector\n",
    "# dsigma_dz_values_for_height_pf_sector10 = {\n",
    "#     2:      get_advection_and_cumsum_df(2,     tidy_df_pf_sector10),\n",
    "#     3:      get_advection_and_cumsum_df(3,     tidy_df_pf_sector10),\n",
    "#     5:      get_advection_and_cumsum_df(5,     tidy_df_pf_sector10),\n",
    "#     10:     get_advection_and_cumsum_df(10,    tidy_df_pf_sector10),\n",
    "#     15:     get_advection_and_cumsum_df(15,    tidy_df_pf_sector10),\n",
    "#     20:     get_advection_and_cumsum_df(20,    tidy_df_pf_sector10),\n",
    "# }\n",
    "# vertical_advection_estimates_pf_sector10 = pd.concat([\n",
    "#     df[0].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_sector10.items()\n",
    "# ])\n",
    "# cumsub_vertical_advection_correction_estimates_pf_sector10 = pd.concat([\n",
    "#     df[1].assign(height = H) for (H, df) in dsigma_dz_values_for_height_pf_sector10.items()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_casestudy_and_seasonal_charts(\n",
    "        vert_adv_estimates_df,\n",
    "        cumsub_estimates_df,\n",
    "        casestudy_date = '20230505'\n",
    "):\n",
    "    flux_div = pd.DataFrame(\n",
    "        (\n",
    "            tidy_df.query(f\"variable == 'w_h2o__10m_c_raw'\").set_index('time').loc[casestudy_date]['value'] - \\\n",
    "            tidy_df.query(f\"variable == 'w_h2o__3m_c_raw'\").set_index('time').loc[casestudy_date]['value']\n",
    "        ).rename('flux div') / 7\n",
    "    ).reset_index()\n",
    "\n",
    "    casestudy_chart = alt.Chart(\n",
    "        flux_div\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'mean(flux div)',\n",
    "        frame = [-3, 3]\n",
    "    ).mark_line(color='black').encode(\n",
    "        alt.X('time:T'),\n",
    "        alt.Y('rolling_avg:Q'),\n",
    "    ) +\\\n",
    "    alt.Chart(\n",
    "        vert_adv_estimates_df.loc[casestudy_date].reset_index()\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'mean(vertical_advection)',\n",
    "        frame = [-3, 3]\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'),\n",
    "        alt.Y('rolling_avg:Q').scale(domain=[-0.003, 0.003]),\n",
    "        alt.Color('height:O').scale(scheme='rainbow')\n",
    "    ).properties(\n",
    "        width=200,\n",
    "        height=200\n",
    "    )\n",
    "\n",
    "    seasonal_sub_chart = alt.Chart(\n",
    "        (cumsub_estimates_df.groupby([\n",
    "        pd.Grouper(freq='24H'), 'height'\n",
    "        ]).max() * 1.8).reset_index()\n",
    "    ).transform_fold([\n",
    "        'w_h2o___cumsum', 'w_h2o__corrected_cumsum'\n",
    "    ]).mark_point(size=50).encode(\n",
    "        alt.Y('height:N').sort('-y'),\n",
    "        alt.X('max(value):Q').scale(domain=[20,42]),\n",
    "        alt.Shape('key:N'),\n",
    "        alt.Color('key:N')\n",
    "    ).properties(\n",
    "        width=200, height=200\n",
    "    )\n",
    "\n",
    "    seasonal_w_chart_upvalley = alt.Chart(\n",
    "        cumsub_estimates_df[\n",
    "            cumsub_estimates_df.index.isin(upvalley_wind_times)\n",
    "        ].reset_index()\n",
    "    ).mark_line().encode(\n",
    "        alt.X('hours(time):T'),\n",
    "        alt.Y('median(w):Q').scale(domain=[-0.05,0.05]),\n",
    "        alt.Color('height:O').scale(scheme='rainbow')\n",
    "    ).properties(width=200, height=200)\n",
    "    seasonal_w_chart_downvalley = alt.Chart(\n",
    "        cumsub_estimates_df[\n",
    "            cumsub_estimates_df.index.isin(downvalley_wind_times)\n",
    "        ].reset_index()\n",
    "    ).mark_line().encode(\n",
    "        alt.X('hours(time):T'),\n",
    "        alt.Y('median(w):Q').scale(domain=[-0.05,0.05]),\n",
    "        alt.Color('height:O').scale(scheme='rainbow')\n",
    "    ).properties(width=200, height=200)\n",
    "\n",
    "    return (\n",
    "        seasonal_sub_chart & \n",
    "        # casestudy_chart & \n",
    "        seasonal_w_chart_upvalley & seasonal_w_chart_downvalley\n",
    "    ).resolve_scale(shape='independent', color='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_casestudy_and_seasonal_charts(\n",
    "    vertical_advection_estimates_pf_og,\n",
    "    cumsub_vertical_advection_correction_estimates_pf_og,\n",
    "    casestudy_date = '20230505'\n",
    ").properties(title='Monthly planar fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(get_casestudy_and_seasonal_charts(\n",
    "    vertical_advection_estimates_pf_og,\n",
    "    cumsub_vertical_advection_correction_estimates_pf_og,\n",
    "    casestudy_date = '20230505'\n",
    ").properties(title='Monthly planar fit') |\\\n",
    "get_casestudy_and_seasonal_charts(\n",
    "    vertical_advection_estimates_pf_valleydir,\n",
    "    cumsub_vertical_advection_correction_estimates_pf_valleydir,\n",
    "    casestudy_date = '20230505'\n",
    ").properties(title='Monthly planar fit + 3 sectors') |\\\n",
    "get_casestudy_and_seasonal_charts(\n",
    "    vertical_advection_estimates_pf_sector60,\n",
    "    cumsub_vertical_advection_correction_estimates_pf_sector60,\n",
    "    casestudy_date = '20230505'\n",
    ").properties(title='Monthly planar fit + 6 sectors') |\\\n",
    "get_casestudy_and_seasonal_charts(\n",
    "    vertical_advection_estimates_pf_sector30,\n",
    "    cumsub_vertical_advection_correction_estimates_pf_sector30,\n",
    "    casestudy_date = '20230505'\n",
    ").properties(title='Monthly planar fit + 12 sectors') |\\\n",
    "get_casestudy_and_seasonal_charts(\n",
    "    vertical_advection_estimates_pf_sector10,\n",
    "    cumsub_vertical_advection_correction_estimates_pf_sector10,\n",
    "    casestudy_date = '20230505'\n",
    ").properties(title='Monthly planar fit + 36 sectors')).configure_legend(orient='top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D gradient solutions for multiple terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at relative snow depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_snowdepth_df = tidy_df.query(\"variable == 'SnowDepth_c'\").set_index('time')\n",
    "annex_snowdepth_df = annex_snowdepth_ds.to_dataframe()#.loc[kps_snowdepth_df.index.min(), kps_snowdepth_df.index.max()]\n",
    "annex_snowdepth_df = annex_snowdepth_df.resample('30min').median().loc[kps_snowdepth_df.index.min(): kps_snowdepth_df.index.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_src = (tidy_df.query(\n",
    "        \"measurement == 'mixing ratio'\"\n",
    "    ).set_index('time').loc['20230201 1000': '20230201 1500'].query(\n",
    "        \"height > 0\"\n",
    "    )).reset_index()\n",
    "kps_src['value'] = kps_src['value'] * 1000\n",
    "alt.Chart(\n",
    "    kps_src.query(\"height <= 5\")\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q').scale(zero=False),\n",
    "    alt.Color('height:O')\n",
    ") +\\\n",
    "alt.Chart(\n",
    "mixingratio_ds.to_dataframe().sort_index().loc['20230201 1000': '20230201 1500'].resample('30min').mean().reset_index()\n",
    ").mark_line(color='red').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('mixing_ratio:Q').scale(zero=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowdepth_pair = pd.DataFrame(annex_snowdepth_df['snow_depth'].rename('annex')).join(\n",
    "    (100*kps_snowdepth_df['value'].rename('kps'))\n",
    ").reset_index()\n",
    "\n",
    "onetoone_line = alt.Chart(pd.DataFrame({'x':[0, 200], 'y':[0, 200]})).mark_line(color='grey').encode(x='x', y='y')\n",
    "(alt.Chart(snowdepth_pair).mark_line().transform_fold([\n",
    "    'annex', 'kps'\n",
    "]).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('key:N')\n",
    ") | onetoone_line+alt.Chart(snowdepth_pair.set_index('time').resample('1440min').mean().reset_index()).mark_circle().encode(\n",
    "    alt.X('annex:Q'),\n",
    "    alt.Y('kps:Q')\n",
    ")).configure_legend(orient='top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate air density flux term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airdensityflux_df = tidy_df[tidy_df.variable.isin([\n",
    "    'dryairdensity_3m_c',   'dryairdensity_20m_c',\n",
    "    'T_3m_c',   'T_20m_c',\n",
    "    'mixingratio_3m_c',   'mixingratio_20m_c',\n",
    "    'w_tc__3m_c',   'w_tc__20m_c',\n",
    "    'w_h2o__3m_c',   'w_h2o__20m_c',\n",
    "])].pivot(index='time', columns='variable', values='value')\n",
    "\n",
    "mean_mixing_ratio = tidy_df.query(\n",
    "    \"measurement == 'mixing ratio'\"\n",
    ").query(\n",
    "    \"height >= 3\"\n",
    ").query(\n",
    "    \"height <= 20\"\n",
    ").groupby('time').value.mean().rename('mixingratio_mean_3to17')\n",
    "\n",
    "airdensityflux_df = airdensityflux_df.join(mean_mixing_ratio)\n",
    "\n",
    "# ALL KELVIN\n",
    "UNITS_FOR_T_MEAS = units('kelvin')\n",
    "UNITS_FOR_SH_FLUX = units(\"kelvin*m/s\")\n",
    "airdensityflux_df['T_3m_c'] = (airdensityflux_df['T_3m_c'].values * units(\"degC\")).to(UNITS_FOR_T_MEAS)\n",
    "airdensityflux_df['T_20m_c'] = (airdensityflux_df['T_20m_c'].values * units(\"degC\")).to(UNITS_FOR_T_MEAS)\n",
    "\n",
    "# ALL CELSIUS\n",
    "# UNITS_FOR_T_MEAS = units('degC')\n",
    "# UNITS_FOR_SH_FLUX = units(\"degC*m/s\")\n",
    "# airdensityflux_df['T_3m_c'] = (airdensityflux_df['T_3m_c'].values * units(\"degC\")).to(UNITS_FOR_T_MEAS)\n",
    "# airdensityflux_df['T_20m_c'] = (airdensityflux_df['T_20m_c'].values * units(\"degC\")).to(UNITS_FOR_T_MEAS)\n",
    "\n",
    "mu = 1/0.622\n",
    "air_density_flux = (\n",
    "    (\n",
    "        airdensityflux_df['mixingratio_mean_3to17'].values * units(\"g/g\")\n",
    "    ) * (\n",
    "        (\n",
    "            ((airdensityflux_df['dryairdensity_20m_c'].values * units(\"kg/m^3\")) / (airdensityflux_df['T_20m_c'].values * UNITS_FOR_T_MEAS))\n",
    "            * (1 + mu * (airdensityflux_df['mixingratio_20m_c'].values * units(\"g/g\")))\n",
    "            * (airdensityflux_df['w_tc__20m_c'].values * UNITS_FOR_SH_FLUX) + mu*(airdensityflux_df['w_h2o__20m_c'].values * units(\"g/m^2/s\"))\n",
    "        )\n",
    "        -\n",
    "        (\n",
    "            ((airdensityflux_df['dryairdensity_3m_c'].values * units(\"kg/m^3\")) / (airdensityflux_df['T_3m_c'].values * UNITS_FOR_T_MEAS))\n",
    "            * (1 + mu * (airdensityflux_df['mixingratio_3m_c'].values * units(\"g/g\")))\n",
    "            * (airdensityflux_df['w_tc__3m_c'].values * UNITS_FOR_SH_FLUX) + mu*(airdensityflux_df['w_h2o__3m_c'].values * units(\"g/m^2/s\"))\n",
    "        )\n",
    "\n",
    "    ) / (17 * units('m'))\n",
    ").to(units('g/m^3/s'))\n",
    "\n",
    "airdensityflux_df['air_density_flux'] = air_density_flux\n",
    "air_density_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate horizontal advection and storage change term (using two-point solution to derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# combine mixing ratio measurements from the two sites into one dataframe \n",
    "kpsannex_mixingratio_measurements = mixingratio_ds.sortby('time').sel(\n",
    "    time=slice(data_start_date, data_cutoff_date)\n",
    ").resample(time='30min').mean().rename('annex').to_dataframe() / 1000\n",
    "kps_mixingratio_measurements_2m = tidy_df.query(\"variable == 'mixingratio_2m_c'\").set_index('time')['value'].rename('kps_2m')\n",
    "kps_mixingratio_measurements_3m = tidy_df.query(\"variable == 'mixingratio_3m_c'\").set_index('time')['value'].rename('kps_3m')\n",
    "kps_mixingratio_measurements_4m = tidy_df.query(\"variable == 'mixingratio_4m_c'\").set_index('time')['value'].rename('kps_4m')\n",
    "\n",
    "kps_lateral_simple_df = kpsannex_mixingratio_measurements.join(\n",
    "    kps_mixingratio_measurements_2m\n",
    ").join(\n",
    "    kps_mixingratio_measurements_3m\n",
    ").join(\n",
    "    kps_mixingratio_measurements_4m\n",
    ")\n",
    "\n",
    "# isolate measurements to when wind is up (100˚ - 140˚) or downvalley (300 - 340)\n",
    "kps_lateral_simple_df = kps_lateral_simple_df.join(\n",
    "    tidy_df.query(\"variable == 'dir_10m_c'\").set_index('time')['value'].rename('dir_10m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'spd_3m_c'\").set_index('time')['value'].rename('spd_3m_c')\n",
    ").join(\n",
    "    1000*tidy_df.query(\"variable == 'dryairdensity_3m_c'\").set_index('time')['value'].rename('rho')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__3m_c'\").set_index('time')['value'].rename('w_h2o__3m_c')\n",
    ")\n",
    "\n",
    "kps_lateral_simple_df = kps_lateral_simple_df[\n",
    "    ((kps_lateral_simple_df.dir_10m_c >= 112) & (kps_lateral_simple_df.dir_10m_c <= 152))\n",
    "    |\n",
    "    ((kps_lateral_simple_df.dir_10m_c >= 292) & (kps_lateral_simple_df.dir_10m_c <= 332))\n",
    "]\n",
    "# label each timestamp up or downvalley\n",
    "kps_lateral_simple_df['direction'] = kps_lateral_simple_df['dir_10m_c'].apply(lambda x: 'down' if 292 <= x <= 332 else 'up')\n",
    "# # Calculate deltas. During downvalley winds, ds = annex - kps. During up valley winds, ds = kps - annex\n",
    "kps_lateral_simple_df['ds_2m'] = kps_lateral_simple_df.apply(\n",
    "    lambda row: row['annex'] - row['kps_2m'] if row['direction'] == 'down' else row['kps_2m'] - row['annex'],\n",
    "    axis=1\n",
    ")\n",
    "kps_lateral_simple_df['ds_3m'] = kps_lateral_simple_df.apply(\n",
    "    lambda row: row['annex'] - row['kps_3m'] if row['direction'] == 'down' else row['kps_3m'] - row['annex'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "kps_lateral_simple_df['ds_3m_uncertainty'] = 0.2/1000\n",
    "\n",
    "kps_lateral_simple_df['ds_4m'] = kps_lateral_simple_df.apply(\n",
    "    lambda row: row['annex'] - row['kps_4m'] if row['direction'] == 'down' else row['kps_4m'] - row['annex'],\n",
    "    axis=1\n",
    ")\n",
    "kps_lateral_simple_df['dx'] = 400\n",
    "kps_lateral_simple_df['ds/dx 2m'] = kps_lateral_simple_df['ds_2m'] / kps_lateral_simple_df['dx']\n",
    "kps_lateral_simple_df['ds/dx 3m'] = kps_lateral_simple_df['ds_3m'] / kps_lateral_simple_df['dx']\n",
    "kps_lateral_simple_df['ds/dx 3m uncertainty'] = kps_lateral_simple_df['ds_3m_uncertainty'] / kps_lateral_simple_df['dx']\n",
    "kps_lateral_simple_df['ds/dx 4m'] = kps_lateral_simple_df['ds_4m'] / kps_lateral_simple_df['dx']\n",
    "\n",
    "kps_lateral_simple_df['lateral_advection_2m'] = kps_lateral_simple_df['spd_3m_c'] * kps_lateral_simple_df['rho'] * kps_lateral_simple_df['ds/dx 2m']\n",
    "kps_lateral_simple_df['lateral_advection_3m'] = kps_lateral_simple_df['spd_3m_c'] * kps_lateral_simple_df['rho'] * kps_lateral_simple_df['ds/dx 3m']\n",
    "kps_lateral_simple_df['lateral_advection_3m_uncertainty'] = kps_lateral_simple_df['spd_3m_c'] * kps_lateral_simple_df['rho'] * kps_lateral_simple_df['ds/dx 3m uncertainty']\n",
    "kps_lateral_simple_df['lateral_advection_4m'] = kps_lateral_simple_df['spd_3m_c'] * kps_lateral_simple_df['rho'] * kps_lateral_simple_df['ds/dx 4m']\n",
    "\n",
    "\n",
    "kps_lateral_simple_df['ds/dt'] = kps_lateral_simple_df['rho'] * (kps_lateral_simple_df[['kps_2m', 'kps_3m', 'kps_4m']].mean(axis=1)).diff() * units('g/g') / (30*60*units('seconds'))\n",
    "# kps_lateral_simple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = kps_lateral_simple_df[['lateral_advection_3m', 'lateral_advection_3m_uncertainty']]\n",
    "src['ub'] = src['lateral_advection_3m'] + src['lateral_advection_3m_uncertainty']\n",
    "src['lb'] = src['lateral_advection_3m'] - src['lateral_advection_3m_uncertainty']\n",
    "\n",
    "alt.Chart(src.reset_index()).mark_area(opacity=0.5).encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('mean(lb):Q'),\n",
    "    alt.Y2('mean(ub):Q')\n",
    ") + alt.Chart(src.reset_index()).mark_line().encode(\n",
    "    alt.X('hoursminutes(time):T'),\n",
    "    alt.Y('mean(lateral_advection_3m):Q'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using KPS Irga measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mixing ratio measurements from the corner towers\n",
    "upwind_s = 0.5*(mixing_ratio_field_df[3, 'ue', 'r'] + mixing_ratio_field_df[3, 'uw', 'r'])\n",
    "upwind_s.name = 'upwind_s'\n",
    "kps_lateral_simple_irga_df = pd.DataFrame(upwind_s)\n",
    "kps_lateral_simple_irga_df['downwind_s'] = mixing_ratio_field_df[3, 'd', 'r']\n",
    "\n",
    "\n",
    "# # Add wind dir variable\n",
    "kps_lateral_simple_irga_df = kps_lateral_simple_irga_df.join(\n",
    "    tidy_df.query(\"variable == 'dir_10m_c'\").set_index('time').loc['20221101': '20230620']['value'].rename('dir_10m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'spd_3m_c'\").set_index('time').loc['20221101': '20230620']['value'].rename('spd_3m_c')\n",
    ").join(\n",
    "    1000*tidy_df.query(\"variable == 'dryairdensity_3m_c'\").set_index('time').loc['20221101': '20230620']['value'].rename('rho')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__3m_c'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__3m_c')\n",
    ")\n",
    "\n",
    "\n",
    "# isolate measurements to when wind is up (100˚ - 140˚) or downvalley (300 - 340)\n",
    "kps_lateral_simple_irga_df = kps_lateral_simple_irga_df[\n",
    "    ((kps_lateral_simple_irga_df.dir_10m_c >= 100) & (kps_lateral_simple_irga_df.dir_10m_c <= 140))\n",
    "    |\n",
    "    ((kps_lateral_simple_irga_df.dir_10m_c >= 300) & (kps_lateral_simple_irga_df.dir_10m_c <= 340))\n",
    "]\n",
    "\n",
    "# label each timestamp up or downvalley\n",
    "kps_lateral_simple_irga_df['direction'] = kps_lateral_simple_irga_df['dir_10m_c'].apply(lambda x: 'down' if 300 <= x <= 340 else 'up')\n",
    "# # Calculate deltas. During downvalley winds, ds = annex - kps. During up valley winds, ds = kps - annex\n",
    "kps_lateral_simple_irga_df['ds'] = kps_lateral_simple_irga_df.apply(\n",
    "    lambda row: row['downwind_s'] - row['upwind_s'] if row['direction'] == 'down' else row['upwind_s'] - row['downwind_s'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "kps_lateral_simple_irga_df['dx'] = 32\n",
    "kps_lateral_simple_irga_df['ds/dx'] = kps_lateral_simple_irga_df['ds'] / kps_lateral_simple_irga_df['dx']\n",
    "\n",
    "kps_lateral_simple_irga_df\n",
    "\n",
    "kps_lateral_simple_irga_df['lateral_advection_irga'] = kps_lateral_simple_irga_df['spd_3m_c'] * kps_lateral_simple_irga_df['rho'] * kps_lateral_simple_irga_df['ds/dx']\n",
    "kps_lateral_simple_irga_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate vertical advection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple two-point solution to the derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 to 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kps_mixingratio_measurements_2m = tidy_df.query(\"variable == 'mixingratio_2m_c'\").set_index('time')['value'].rename('mixingratio_2m_c')\n",
    "kps_mixingratio_measurements_10m = tidy_df.query(\"variable == 'mixingratio_10m_c'\").set_index('time')['value'].rename('mixingratio_10m_c')\n",
    "kps_vert_simple_df_2to10 = pd.DataFrame(kps_mixingratio_measurements_2m).join(kps_mixingratio_measurements_10m)\n",
    "kps_vert_simple_df_2to10['ds'] = kps_vert_simple_df_2to10['mixingratio_10m_c'] - kps_vert_simple_df_2to10['mixingratio_2m_c']\n",
    "kps_vert_simple_df_2to10['ds_uncertainty'] = 0.2 / 1000\n",
    "kps_vert_simple_df_2to10['dz'] = 8\n",
    "kps_vert_simple_df_2to10['ds/dz'] = kps_vert_simple_df_2to10['ds'] / kps_vert_simple_df_2to10['dz']\n",
    "kps_vert_simple_df_2to10['ds/dz uncertainty'] = kps_vert_simple_df_2to10['ds_uncertainty'] / kps_vert_simple_df_2to10['dz']\n",
    "\n",
    "kps_vert_simple_df_2to10 = kps_vert_simple_df_2to10.join(\n",
    "    tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\").query(\"height <= 10\").query(\"height >= 2\").groupby(['time'])['value'].mean().rename('w')\n",
    ").join(\n",
    "    1000*tidy_df.query(\"variable == 'dryairdensity_5m_c'\").set_index('time').loc['20221101': '20230620']['value'].rename('rho')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__2m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__2m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__5m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__5m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__10m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__10m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__20m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__20m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__2m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__2m_c_raw')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__5m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__5m_c_raw')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__10m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__10m_c_raw')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__20m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__20m_c_raw')\n",
    ")\n",
    "kps_vert_simple_df_2to10['vertical_advection_simple_2to10'] =  kps_vert_simple_df_2to10['w'] * kps_vert_simple_df_2to10['rho'] * kps_vert_simple_df_2to10['ds/dz']\n",
    "\n",
    "kps_vert_simple_df_2to10['vertical_advection_simple_2to10_uncertainty'] =  kps_vert_simple_df_2to10['w'] * kps_vert_simple_df_2to10['rho'] * kps_vert_simple_df_2to10['ds/dz uncertainty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 to 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_mixingratio_measurements_3m = tidy_df.query(\"variable == 'mixingratio_3m_c'\").set_index('time')['value'].rename('mixingratio_3m_c')\n",
    "kps_mixingratio_measurements_10m = tidy_df.query(\"variable == 'mixingratio_10m_c'\").set_index('time')['value'].rename('mixingratio_10m_c')\n",
    "kps_vert_simple_df_3to10 = pd.DataFrame(kps_mixingratio_measurements_3m).join(kps_mixingratio_measurements_10m)\n",
    "kps_vert_simple_df_3to10['ds'] = kps_vert_simple_df_3to10['mixingratio_10m_c'] - kps_vert_simple_df_3to10['mixingratio_3m_c']\n",
    "kps_vert_simple_df_3to10['ds_uncertainty'] = 0.2 / 1000\n",
    "kps_vert_simple_df_3to10['dz'] = 7\n",
    "kps_vert_simple_df_3to10['ds/dz'] = kps_vert_simple_df_3to10['ds'] / kps_vert_simple_df_3to10['dz']\n",
    "kps_vert_simple_df_3to10['ds/dz uncertainty'] = kps_vert_simple_df_3to10['ds_uncertainty'] / kps_vert_simple_df_3to10['dz']\n",
    "\n",
    "kps_vert_simple_df_3to10 = kps_vert_simple_df_3to10.join(\n",
    "    tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\").query(\"height <= 10\").query(\"height >= 3\").groupby(['time'])['value'].mean().rename('w')\n",
    ").join(\n",
    "    1000*tidy_df.query(\"variable == 'dryairdensity_5m_c'\").set_index('time').loc['20221101': '20230620']['value'].rename('rho')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__3m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__3m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__5m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__5m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__10m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__10m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__20m_c_gapfill'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__20m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__3m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__3m_c_raw')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__5m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__5m_c_raw')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__10m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__10m_c_raw')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__20m_c_raw'\").set_index('time').loc['20221101': '20230620']['value'].rename('w_h2o__20m_c_raw')\n",
    ")\n",
    "kps_vert_simple_df_3to10['vertical_advection_simple_3to10'] =  kps_vert_simple_df_3to10['w'] * kps_vert_simple_df_3to10['rho'] * kps_vert_simple_df_3to10['ds/dz']\n",
    "\n",
    "kps_vert_simple_df_3to10['vertical_advection_simple_3to10_uncertainty'] =  kps_vert_simple_df_3to10['w'] * kps_vert_simple_df_3to10['rho'] * kps_vert_simple_df_3to10['ds/dz uncertainty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 to 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_mixingratio_measurements_2m = tidy_df.query(\"variable == 'mixingratio_2m_c'\").set_index('time')['value'].rename('mixingratio_2m_c')\n",
    "kps_mixingratio_measurements_20m = tidy_df.query(\"variable == 'mixingratio_20m_c'\").set_index('time')['value'].rename('mixingratio_20m_c')\n",
    "kps_vert_simple_df_2to20 = pd.DataFrame(kps_mixingratio_measurements_2m).join(kps_mixingratio_measurements_20m)\n",
    "kps_vert_simple_df_2to20['ds'] = kps_vert_simple_df_2to20['mixingratio_20m_c'] - kps_vert_simple_df_2to20['mixingratio_2m_c']\n",
    "kps_vert_simple_df_2to20['ds_uncertainty'] = 0.2 / 1000\n",
    "kps_vert_simple_df_2to20['dz'] = 18\n",
    "kps_vert_simple_df_2to20['ds/dz'] = kps_vert_simple_df_2to20['ds'] / kps_vert_simple_df_2to20['dz']\n",
    "kps_vert_simple_df_2to20['ds/dz uncertainty'] = kps_vert_simple_df_2to20['ds_uncertainty'] / kps_vert_simple_df_2to20['dz']\n",
    "\n",
    "kps_vert_simple_df_2to20 = kps_vert_simple_df_2to20.join(\n",
    "    tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\").query(\"height <= 20\").query(\"height >= 3\").groupby(['time'])['value'].mean().rename('w')\n",
    ").join(\n",
    "    1000*tidy_df[tidy_df.measurement == 'dry air density'].query(\"tower == 'c'\").groupby(['time'])['value'].mean().rename('rho')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__2m_c_gapfill'\").set_index('time')['value'].rename('w_h2o__2m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__20m_c_gapfill'\").set_index('time')['value'].rename('w_h2o__20m_c')\n",
    ")\n",
    "kps_vert_simple_df_2to20['vertical_advection_simple_2to20'] =  kps_vert_simple_df_2to20['w'] * kps_vert_simple_df_2to20['rho'] * kps_vert_simple_df_2to20['ds/dz']\n",
    "kps_vert_simple_df_2to20['vertical_advection_simple_2to20_uncertainty'] =  kps_vert_simple_df_2to20['w'] * kps_vert_simple_df_2to20['rho'] * kps_vert_simple_df_2to20['ds/dz uncertainty']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 to 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_mixingratio_measurements_3m = tidy_df.query(\"variable == 'mixingratio_3m_c'\").set_index('time')['value'].rename('mixingratio_3m_c')\n",
    "kps_mixingratio_measurements_20m = tidy_df.query(\"variable == 'mixingratio_20m_c'\").set_index('time')['value'].rename('mixingratio_20m_c')\n",
    "kps_vert_simple_df_3to20 = pd.DataFrame(kps_mixingratio_measurements_3m).join(kps_mixingratio_measurements_20m)\n",
    "kps_vert_simple_df_3to20['ds'] = kps_vert_simple_df_3to20['mixingratio_20m_c'] - kps_vert_simple_df_3to20['mixingratio_3m_c']\n",
    "kps_vert_simple_df_3to20['ds_uncertainty'] = 0.2 / 1000\n",
    "kps_vert_simple_df_3to20['dz'] = 17\n",
    "kps_vert_simple_df_3to20['ds/dz'] = kps_vert_simple_df_3to20['ds'] / kps_vert_simple_df_3to20['dz']\n",
    "kps_vert_simple_df_3to20['ds/dz uncertainty'] = kps_vert_simple_df_3to20['ds_uncertainty'] / kps_vert_simple_df_3to20['dz']\n",
    "\n",
    "kps_vert_simple_df_3to20 = kps_vert_simple_df_3to20.join(\n",
    "    tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\").query(\"height <= 20\").query(\"height >= 3\").groupby(['time'])['value'].mean().rename('w')\n",
    ").join(\n",
    "    1000*tidy_df[tidy_df.measurement == 'dry air density'].query(\"tower == 'c'\").groupby(['time'])['value'].mean().rename('rho')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__3m_c_gapfill'\").set_index('time')['value'].rename('w_h2o__3m_c')\n",
    ").join(\n",
    "    tidy_df.query(\"variable == 'w_h2o__20m_c_gapfill'\").set_index('time')['value'].rename('w_h2o__20m_c')\n",
    ")\n",
    "kps_vert_simple_df_3to20['vertical_advection_simple_3to20'] =  kps_vert_simple_df_3to20['w'] * kps_vert_simple_df_3to20['rho'] * kps_vert_simple_df_3to20['ds/dz']\n",
    "kps_vert_simple_df_3to20['vertical_advection_simple_3to20_uncertainty'] =  kps_vert_simple_df_3to20['w'] * kps_vert_simple_df_3to20['rho'] * kps_vert_simple_df_3to20['ds/dz uncertainty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_advection_estimates_gradient_calculations_df = pd.concat([\n",
    "    pd.DataFrame(\n",
    "        ((kps_vert_simple_df_2to20['vertical_advection_simple_2to20']*20 + kps_vert_simple_df_3to20['w_h2o__20m_c'])*1.8).loc[\n",
    "            '20221130': '20230509'\n",
    "        ].cumsum().rename('value')\n",
    "    ).assign(height = 20, type='2to20'),\n",
    "    pd.DataFrame(\n",
    "        ((kps_vert_simple_df_3to20['vertical_advection_simple_3to20']*20 + kps_vert_simple_df_3to20['w_h2o__20m_c'])*1.8).loc[\n",
    "            '20221130': '20230509'\n",
    "        ].cumsum().rename('value')\n",
    "    ).assign(height = 20, type='3to20'),\n",
    "    pd.DataFrame(\n",
    "        ((kps_vert_simple_df_2to10['vertical_advection_simple_2to10']*10 + kps_vert_simple_df_2to10['w_h2o__10m_c'])*1.8).loc[\n",
    "            '20221130': '20230509'\n",
    "        ].cumsum().rename('value')\n",
    "    ).assign(height = 10, type='2to10'),\n",
    "    pd.DataFrame(\n",
    "        ((kps_vert_simple_df_3to10['vertical_advection_simple_3to10']*10 + kps_vert_simple_df_3to10['w_h2o__10m_c'])*1.8).loc[\n",
    "            '20221130': '20230509'\n",
    "        ].cumsum().rename('value')\n",
    "    ).assign(height = 10, type='3to10'),\n",
    "])\n",
    "\n",
    "alt.Chart(\n",
    "        vertical_advection_estimates_gradient_calculations_df\n",
    ").mark_point(size=50).encode(\n",
    "    alt.Y('height:N').sort('-y'),\n",
    "    alt.X('max(value):Q').scale(domain=[20,42]),\n",
    "    alt.Shape('type:N'),\n",
    "    alt.Color('type:N')\n",
    ").properties(\n",
    "    width=200, height=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical multi-point solution to the derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 to 10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gather the measurements we want\n",
    "# kps_mixingratio_measurements = tidy_df[tidy_df.measurement == 'mixing ratio'][tidy_df.height >= 3][tidy_df.height <= 10]\n",
    "# kps_dryairdensity_measurements = tidy_df[tidy_df.measurement == 'dry air density'][tidy_df.height >= 3][tidy_df.height <= 10]\n",
    "# kps_verticalvelocity_measurements = tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\")\n",
    "\n",
    "# # iterate over each timestamp, doing calculations for each\n",
    "# timestamps = kps_mixingratio_measurements.time.unique()\n",
    "# vert_adv_ls = []\n",
    "# ts_ls = []\n",
    "# for ts in timestamps:\n",
    "#     # get the measurements we want for this timestamp \n",
    "#     ex_s = kps_mixingratio_measurements[kps_mixingratio_measurements.time == ts]\n",
    "#     ex_rho = kps_dryairdensity_measurements[kps_dryairdensity_measurements.time == ts]\n",
    "#     ex_w = kps_verticalvelocity_measurements[kps_verticalvelocity_measurements.time == ts]\n",
    "#     # calculate the scalar gradient profile\n",
    "#     ds_dz = np.gradient(\n",
    "#         ex_s.sort_values('height')['value'],\n",
    "#         ex_s.sort_values('height')['height'],\n",
    "#     )\n",
    "#     # calculate the wind profile by interpolating actual measurements to where we have mixing ratio measurements\n",
    "#     w_interp = np.interp(\n",
    "#         ex_s.sort_values('height')['height'],\n",
    "#         ex_w.sort_values('height')['height'],\n",
    "#         ex_w.sort_values('height')['value']\n",
    "#     )\n",
    "#     # Calculate the vertical advection term\n",
    "#     vert_advection = (1000 * ex_rho.sort_values('height').value.values * w_interp * ds_dz).sum()\n",
    "#     vert_adv_ls.append(vert_advection)\n",
    "#     ts_ls.append(ts)\n",
    "\n",
    "# kps_vert_complex_10m_df = pd.DataFrame({\n",
    "#     'time': ts_ls,\n",
    "#     'vertical_advection_complex': vert_adv_ls\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 to 20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gather the measurements we want\n",
    "# kps_mixingratio_measurements = tidy_df[tidy_df.measurement == 'mixing ratio'][tidy_df.height >= 3][tidy_df.height <= 20]\n",
    "# kps_dryairdensity_measurements = tidy_df[tidy_df.measurement == 'dry air density'][tidy_df.height >= 3][tidy_df.height <= 20]\n",
    "# kps_verticalvelocity_measurements = tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\")\n",
    "\n",
    "# # iterate over each timestamp, doing calculations for each\n",
    "# timestamps = kps_mixingratio_measurements.time.unique()\n",
    "# vert_adv_ls = []\n",
    "# ts_ls = []\n",
    "# for ts in timestamps:\n",
    "#     # get the measurements we want for this timestamp \n",
    "#     ex_s = kps_mixingratio_measurements[kps_mixingratio_measurements.time == ts]\n",
    "#     ex_rho = kps_dryairdensity_measurements[kps_dryairdensity_measurements.time == ts]\n",
    "#     ex_w = kps_verticalvelocity_measurements[kps_verticalvelocity_measurements.time == ts]\n",
    "#     # calculate the scalar gradient profile\n",
    "#     ds_dz = np.gradient(\n",
    "#         ex_s.sort_values('height')['value'],\n",
    "#         ex_s.sort_values('height')['height'],\n",
    "#     )\n",
    "#     # calculate the wind profile by interpolating actual measurements to where we have mixing ratio measurements\n",
    "#     w_interp = np.interp(\n",
    "#         ex_s.sort_values('height')['height'],\n",
    "#         ex_w.sort_values('height')['height'],\n",
    "#         ex_w.sort_values('height')['value']\n",
    "#     )\n",
    "#     # Calculate the vertical advection term\n",
    "#     vert_advection = (1000 * ex_rho.sort_values('height').value.values * w_interp * ds_dz).sum()\n",
    "#     vert_adv_ls.append(vert_advection)\n",
    "#     ts_ls.append(ts)\n",
    "\n",
    "# kps_vert_complex_10m_df = pd.DataFrame({\n",
    "#     'time': ts_ls,\n",
    "#     'vertical_advection_complex': vert_adv_ls\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advection_1d_fluxdensity_nonnorm_df = kps_vert_simple_df_3to10[[\n",
    "    'w_h2o__3m_c', 'w_h2o__5m_c', 'w_h2o__10m_c', 'w_h2o__20m_c',\n",
    "    'w_h2o__3m_c_raw', 'w_h2o__5m_c_raw', 'w_h2o__10m_c_raw', 'w_h2o__20m_c_raw'\n",
    "]].join(\n",
    "    kps_vert_simple_df_3to20[['vertical_advection_simple_3to20', 'vertical_advection_simple_3to20_uncertainty']]\n",
    ").join(\n",
    "    kps_vert_simple_df_3to10[['vertical_advection_simple_3to10', 'vertical_advection_simple_3to10_uncertainty']]\n",
    ").join(\n",
    "    kps_vert_simple_df_2to10[['vertical_advection_simple_2to10', 'vertical_advection_simple_2to10_uncertainty']]\n",
    ").join(\n",
    "    kps_vert_simple_df_2to20[['vertical_advection_simple_2to20', 'vertical_advection_simple_2to20_uncertainty']]\n",
    ").join(\n",
    "    kps_lateral_simple_df[['lateral_advection_2m', 'lateral_advection_3m', 'lateral_advection_4m', 'lateral_advection_3m_uncertainty']]\n",
    ").join(\n",
    "    kps_lateral_simple_irga_df['lateral_advection_irga']\n",
    ").join(\n",
    "    kps_lateral_simple_df[['ds/dt']]\n",
    ").join(\n",
    "    airdensityflux_df['air_density_flux']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate differential form of measured EC turbulent fluxes\n",
    "Calculate $$ \\frac{\\Delta \\overline{w'q'}}{\\Delta z} \\quad \\text{and} \\quad  \\frac{\\Delta \\overline{w'q'}}{\\Delta z}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advection_1d_fluxdensity_nonnorm_df['vertical_turb_flux_divergence_3to20'] = (\n",
    "    advection_1d_fluxdensity_nonnorm_df['w_h2o__20m_c_raw'] - advection_1d_fluxdensity_nonnorm_df['w_h2o__3m_c_raw']\n",
    ") / 17\n",
    "\n",
    "advection_1d_fluxdensity_nonnorm_df['vertical_turb_flux_divergence_3to10'] = (\n",
    "    advection_1d_fluxdensity_nonnorm_df['w_h2o__10m_c_raw'] - advection_1d_fluxdensity_nonnorm_df['w_h2o__3m_c_raw']\n",
    ") / 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advection_1d_fluxdensity_nonnorm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite - No BS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_WIDTH = 150\n",
    "PLOT_HEIGHT = 150\n",
    "# Function to plot diurnal cycles in conservation terms\n",
    "########################################################\n",
    "def get_chart_with_errorbands(src, title):\n",
    "    vars = [\n",
    "            'vertical_turb_flux_divergence_3to20', 'vertical_advection_simple_2to20',  \n",
    "            # 'ds/dt', 'air_density_flux'\n",
    "        ]\n",
    "    colors = ['#ff7f0e', '#1f77b4'\n",
    "            #   ,  '#2ca02c', 'black', 'grey'\n",
    "            ]\n",
    "    all_data_chart = alt.Chart(src).mark_line().transform_fold(\n",
    "        vars\n",
    "    ).encode(\n",
    "        alt.X('hoursminutes(time):T').axis(labelAlign='center'),\n",
    "        alt.Y('median(value):Q').title('Flux density (g/m^3/s)').scale(domain = [-0.0005, 0.0005], clamp=True),\n",
    "        alt.Color('key:N').scale(domain = vars,range = colors)\n",
    "    ).properties(width=PLOT_WIDTH, height=PLOT_HEIGHT, title=title)\n",
    "    all_data_chart_vert_adv_uncertainty = alt.Chart(src).mark_area(\n",
    "        color = colors[1],\n",
    "        opacity=0.35\n",
    "    ).encode(\n",
    "        alt.X('hoursminutes(time):T'),\n",
    "        alt.Y('median(vertical_advection_lb):Q').title(''),\n",
    "        alt.Y2('median(vertical_advection_ub):Q').title(''),\n",
    "    )\n",
    "    return all_data_chart_vert_adv_uncertainty + all_data_chart \n",
    "\n",
    "# Function to plot diurnal cycles in profiles\n",
    "########################################################\n",
    "def plot_profiles(src):\n",
    "    return alt.Chart(src).transform_filter(\n",
    "        alt.datum.height > 1\n",
    "    ).transform_filter(\n",
    "        alt.datum.height != 12\n",
    "    ).transform_filter(\n",
    "        alt.datum.height != 6\n",
    "    ).mark_line(\n",
    "        point={'size':20}, strokeWidth=1\n",
    "    ).encode(\n",
    "        alt.X('mean(value):Q').scale(zero=False).title('Mixing ratio (g/Kg)'),\n",
    "        alt.Y('height:Q').title('Height (m)'),\n",
    "                \n",
    "        alt.Color('conditions:N', sort=\n",
    "                  ['0-3','3-6','6-9','9-12','12-15','15-18','18-21','21-0' ]\n",
    "                ).title(\n",
    "            'time (hours)'\n",
    "        ),\n",
    "        alt.Order('height:Q')\n",
    "    ).properties(width=PLOT_WIDTH, height=PLOT_HEIGHT)\n",
    "def plot_profiles_nocolor(src):\n",
    "    return alt.Chart(src).transform_filter(\n",
    "        alt.datum.height > 1\n",
    "    ).transform_filter(\n",
    "        alt.datum.height != 12\n",
    "    ).transform_filter(\n",
    "        alt.datum.height != 6\n",
    "    ).mark_line(\n",
    "        point={'size':20, 'color': 'black'}, strokeWidth=1, color='black'\n",
    "    ).encode(\n",
    "        alt.X('mean(value):Q').scale(zero=False).title('Mixing ratio (g/Kg)'),\n",
    "        alt.Y('height:Q').title('Height (m)'),\n",
    "        alt.Order('height:Q'),\n",
    "        alt.Detail('conditions:N')\n",
    "    ).properties(width=PLOT_WIDTH, height=PLOT_HEIGHT)\n",
    "\n",
    "# Function to plot diurnal cycles in w\n",
    "########################################################\n",
    "def w_diurnal_chart(src, title):\n",
    "    line = alt.Chart().transform_calculate(y = '0').mark_rule().encode(y='y:Q')\n",
    "    return alt.layer(\n",
    "        line, \n",
    "        alt.Chart().mark_line().encode(\n",
    "            alt.X('hours(time):T').axis(labelAlign='center', values=[0,6,12,18,]),\n",
    "            alt.Y('mean(value):Q').title('Vertical velocity (m/s)'),\n",
    "            alt.Color('height:O').scale(scheme='turbo')\n",
    "        ), \n",
    "        data = src\n",
    "    ).properties(width=PLOT_WIDTH, height=PLOT_HEIGHT, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for diurnal cycles in conservation terms\n",
    "########################################################\n",
    "src_cons_terms = advection_1d_fluxdensity_nonnorm_df.copy()\n",
    "src_cons_terms['vertical_advection_lb'] = src_cons_terms['vertical_advection_simple_2to20'] - src_cons_terms['vertical_advection_simple_2to20_uncertainty']\n",
    "src_cons_terms['vertical_advection_ub'] = src_cons_terms['vertical_advection_simple_2to20'] + src_cons_terms['vertical_advection_simple_2to20_uncertainty']\n",
    "\n",
    "\n",
    "upvalley_nobs_times = set(pd.to_datetime(upvalley_wind_times)).intersection(set(nobs_times))\n",
    "downvalley_nobs_times = set(pd.to_datetime(downvalley_wind_times)).intersection(set(nobs_times))\n",
    "\n",
    "# get_chart_with_errorbands(src_cons_terms[src_cons_terms.index.isin(nobs_times)].reset_index(),\n",
    "#  title='All data') |\\\n",
    "src_cons_terms_upvalley_nobs = src_cons_terms[src_cons_terms.index.isin(upvalley_nobs_times)].reset_index()\n",
    "src_cons_terms_dovalley_nobs = src_cons_terms[src_cons_terms.index.isin(downvalley_nobs_times)].reset_index()\n",
    "\n",
    "\n",
    "# Data for diurnal cycles in mixing ratio profiles\n",
    "########################################################\n",
    "src_mixingratio = tidy_df[tidy_df.measurement == 'mixing ratio'].query(\"tower == 'c'\")\n",
    "src_mixingratio = src_mixingratio[src_mixingratio.time.isin(nobs_times)]\n",
    "src_mixingratio['conditions'] = src_mixingratio.time.dt.hour\n",
    "# src_mixingratio = src_mixingratio[src_mixingratio.conditions % 4 == 0]\n",
    "src_mixingratio['conditions'] = pd.cut(\n",
    "    src_mixingratio.time.dt.hour,\n",
    "    [-1,3,6,9,12,15,18,21,24],\n",
    "    labels=['0-3', '3-6', '6-9', '9-12', '12-15', '15-18', '18-21', '21-0'],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "src_mixingratio = src_mixingratio[\n",
    "    src_mixingratio['conditions'].isin(\n",
    "        [\n",
    "            '0-3',\n",
    "            # '3-6',\n",
    "            '6-9',\n",
    "            # '9-12',\n",
    "            '12-15',\n",
    "            # '15-18',\n",
    "            '18-21',\n",
    "            # '21-0'\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "src_mixingratio['value'] = src_mixingratio['value']*1000\n",
    "src_mixingratio_upvalley_nobs = src_mixingratio[src_mixingratio.time.isin(upvalley_nobs_times)]\n",
    "src_mixingratio_dovalley_nobs = src_mixingratio[src_mixingratio.time.isin(downvalley_nobs_times)]\n",
    "src_mixingratio_upvalley_nobs = src_mixingratio_upvalley_nobs.query(\"height > 1\")\n",
    "src_mixingratio_dovalley_nobs = src_mixingratio_dovalley_nobs.query(\"height > 1\")\n",
    "\n",
    "# Data for diurnal cycles in w\n",
    "########################################################\n",
    "src_w = tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\")\n",
    "src_w_upvalley_nobs = src_w[src_w.time.isin(upvalley_nobs_times)]\n",
    "src_w_dovalley_nobs = src_w[src_w.time.isin(downvalley_nobs_times)]\n",
    "src_w_upvalley_nobs = src_w_upvalley_nobs.query(\"height > 1\")\n",
    "src_w_dovalley_nobs = src_w_dovalley_nobs.query(\"height > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s_profile_charts = (\n",
    "    plot_profiles_nocolor(src_mixingratio_upvalley_nobs).properties(title='') &\\\n",
    "    plot_profiles_nocolor(src_mixingratio_dovalley_nobs).properties(title='')\n",
    ")\n",
    "w_charts = (\n",
    "    w_diurnal_chart(src_w_upvalley_nobs, title='') &\\\n",
    "    w_diurnal_chart(src_w_dovalley_nobs, title='')\n",
    ").resolve_scale(y='shared')\n",
    "conservation_charts = (\n",
    "    get_chart_with_errorbands(src_cons_terms_upvalley_nobs, title='') &\\\n",
    "    get_chart_with_errorbands(src_cons_terms_dovalley_nobs, title='')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (\n",
    "        s_profile_charts | conservation_charts | w_charts\n",
    "    ).resolve_scale(color='independent')\n",
    ").configure_legend(orient='top', columns=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    'vertical_turb_flux_divergence_3to20', \n",
    "    'vertical_advection_simple_2to20',  \n",
    "    'ds/dt', \n",
    "    'air_density_flux'\n",
    "]\n",
    "colors = ['#ff7f0e', '#1f77b4', 'grey', '#2ca02c']\n",
    "(alt.Chart(src_cons_terms_upvalley_nobs).mark_line().transform_fold(\n",
    "    vars\n",
    ").encode(\n",
    "    alt.X('hoursminutes(time):T').axis(labelAlign='center'),\n",
    "    alt.Y('median(value):Q').title('Flux density (g/m^3/s)'),\n",
    "    alt.Color('key:N').scale(domain=vars, range=colors)\n",
    ").properties(width=200, height=200, title='Upvalley Winds') | alt.Chart(src_cons_terms_dovalley_nobs).mark_line().transform_fold(\n",
    "    vars\n",
    ").encode(\n",
    "    alt.X('hoursminutes(time):T').axis(labelAlign='center'),\n",
    "    alt.Y('median(value):Q').title('Flux density (g/m^3/s)'),\n",
    "    alt.Color('key:N').scale(domain=vars, range=colors)\n",
    ").properties(width=200, height=200, title='Downvalley Winds')).resolve_scale(\n",
    "    y='shared'\n",
    ").display(\n",
    "    renderer='svg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    # 'vertical_turb_flux_divergence_3to20', \n",
    "    # 'vertical_advection_simple_2to20',  \n",
    "    # 'ds/dt', \n",
    "    'air_density_flux'\n",
    "]\n",
    "colors = [\n",
    "    # 'grey', \n",
    "    '#2ca02c']\n",
    "(alt.Chart(src_cons_terms_upvalley_nobs).mark_line().transform_fold(\n",
    "    vars\n",
    ").encode(\n",
    "    alt.X('hoursminutes(time):T').axis(labelAlign='center'),\n",
    "    alt.Y('median(value):Q').title('Flux density (g/m^3/s)'),\n",
    "    alt.Color('key:N').scale(domain=vars, range=colors)\n",
    ").properties(width=200, height=200, title='Upvalley Winds') | alt.Chart(src_cons_terms_dovalley_nobs).mark_line().transform_fold(\n",
    "    vars\n",
    ").encode(\n",
    "    alt.X('hoursminutes(time):T').axis(labelAlign='center'),\n",
    "    alt.Y('median(value):Q').title('Flux density (g/m^3/s)'),\n",
    "    alt.Color('key:N').scale(domain=vars, range=colors)\n",
    ").properties(width=200, height=200, title='Downvalley Winds')).resolve_scale(\n",
    "    y='shared'\n",
    ").display(\n",
    "    renderer='svg'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upvalley_wind_times = tidy_df[tidy_df.variable == 'dir_3m_c'].dropna().query(\"value < 152\").query(\"value > 92\").drop_duplicates().time\n",
    "downvalley_wind_times = tidy_df[tidy_df.variable == 'dir_3m_c'].dropna().query(\"value < 342\").query(\"value > 292\").drop_duplicates().time\n",
    "all_wind_times = tidy_df[tidy_df.variable == 'dir_3m_c'].drop_duplicates().time\n",
    "print(round(len(upvalley_wind_times)/len(all_wind_times),3))\n",
    "print(round(len(downvalley_wind_times)/len(all_wind_times),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windrose import WindroseAxes\n",
    "src = tidy_df[tidy_df.time.isin(downvalley_wind_times)][\n",
    "    tidy_df.variable.isin(['spd_20m_c', 'dir_20m_c'])\n",
    "].pivot_table(values = 'value', index='time', columns=['measurement']).reset_index()\n",
    "ax = WindroseAxes.from_ax(figsize=(2,2))\n",
    "ax.bar(src['wind direction'], src['wind speed'], normed=True, opening=.9, edgecolor='white', bins=1, nsector=17)\n",
    "ax.set_yticks([])\n",
    "# ax.set_yticklabels(['10%','25%'])\n",
    "plt.title(\"20m wind rose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windrose import WindroseAxes\n",
    "src = tidy_df[tidy_df.time.isin(upvalley_wind_times)][\n",
    "    tidy_df.variable.isin(['spd_20m_c', 'dir_20m_c'])\n",
    "].pivot_table(values = 'value', index='time', columns=['measurement']).reset_index()\n",
    "ax = WindroseAxes.from_ax(figsize=(2,2))\n",
    "ax.bar(src['wind direction'], src['wind speed'], normed=True, opening=.9, edgecolor='white', bins=1, nsector=17)\n",
    "ax.set_yticks([])\n",
    "# ax.set_yticklabels(['10%','25%'])\n",
    "plt.title(\"20m wind rose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.Chart().transform_calculate(y = '0').mark_rule().encode(y='y:Q') + alt.Chart(\n",
    "    tidy_df[tidy_df.measurement == 'w'][tidy_df.time.isin(upvalley_nobs_times)]\n",
    ").mark_line().encode(\n",
    "    alt.X('hours(time):T').axis(labelAlign='center', values=[0,6,12,18,]),\n",
    "    alt.Y('mean(value):Q').title('Vertical velocity (m/s)'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.StrokeDash('tower:N')\n",
    ")) | (alt.Chart().transform_calculate(y = '0').mark_rule().encode(y='y:Q') + alt.Chart(\n",
    "    tidy_df[tidy_df.measurement == 'w'][tidy_df.time.isin(downvalley_nobs_times)]\n",
    ").mark_line().encode(\n",
    "    alt.X('hours(time):T').axis(labelAlign='center', values=[0,6,12,18,]),\n",
    "    alt.Y('mean(value):Q').title('Vertical velocity (m/s)'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.StrokeDash('tower:N')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze seasonal advection corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 3-10m and 3-20m estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__3m_c).cumsum().plot()\n",
    "w_h2o__10m_c_cumsum = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__10m_c).cumsum()\n",
    "w_h2o__20m_c_cumsum = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__20m_c).cumsum()\n",
    "\n",
    "w_h2o__10m_c_corrected_cumsum = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__10m_c\n",
    "        + (\n",
    "            10*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].vertical_advection_simple_3to10\n",
    "        )\n",
    "    )\n",
    ").cumsum()\n",
    "w_h2o__20m_c_corrected_cumsum = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__20m_c\n",
    "        + (\n",
    "            20*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].vertical_advection_simple_3to20\n",
    "        )\n",
    "    )\n",
    ").cumsum()\n",
    "\n",
    "w_h2o__10m_c_cumsum.plot(           color = 'tab:blue',     linestyle = '-')\n",
    "w_h2o__20m_c_cumsum.plot(           color = 'tab:orange',   linestyle = '-')\n",
    "w_h2o__10m_c_corrected_cumsum.plot( color = 'tab:blue',     linestyle = 'dotted',   label='With vertical advection correction, 10m')\n",
    "w_h2o__20m_c_corrected_cumsum.plot( color = 'tab:orange',   linestyle = 'dotted',   label='With vertical advection correction, 20m')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Cumulative sublimation (mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10m, ec\\t\\t', round(w_h2o__10m_c_cumsum.iloc[-1], 1))\n",
    "print('10m, corrected\\t', round(w_h2o__10m_c_corrected_cumsum.iloc[-1], 1))\n",
    "print('20m, ec\\t\\t', round(w_h2o__20m_c_cumsum.iloc[-1], 1))\n",
    "print('20m, corrected\\t', round(w_h2o__20m_c_corrected_cumsum.iloc[-1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__3m_c).cumsum().plot()\n",
    "w_h2o__10m_c_cumsum = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c).cumsum()\n",
    "w_h2o__20m_c_cumsum = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__20m_c).cumsum()\n",
    "\n",
    "w_h2o__10m_c_corrected_cumsum = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c\n",
    "        + (\n",
    "            10*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].vertical_advection_simple_3to10\n",
    "        )\n",
    "    )\n",
    ").cumsum()\n",
    "w_h2o__20m_c_corrected_cumsum = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__20m_c\n",
    "        + (\n",
    "            20*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].vertical_advection_simple_3to20\n",
    "        )\n",
    "    )\n",
    ").cumsum()\n",
    "\n",
    "w_h2o__10m_c_cumsum.plot(           color = 'tab:blue',     linestyle = '-')\n",
    "w_h2o__20m_c_cumsum.plot(           color = 'tab:orange',   linestyle = '-')\n",
    "w_h2o__10m_c_corrected_cumsum.plot( color = 'tab:blue',     linestyle = '--',   label='With vertical advection correction, 10m')\n",
    "w_h2o__20m_c_corrected_cumsum.plot( color = 'tab:orange',   linestyle = '--',   label='With vertical advection correction, 20m')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Cumulative sublimation (mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10m, ec\\t\\t', round(w_h2o__10m_c_cumsum.iloc[-1], 1))\n",
    "print('10m, corrected\\t', round(w_h2o__10m_c_corrected_cumsum.iloc[-1], 1))\n",
    "print('20m, ec\\t\\t', round(w_h2o__20m_c_cumsum.iloc[-1], 1))\n",
    "print('20m, corrected\\t', round(w_h2o__20m_c_corrected_cumsum.iloc[-1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__3m_c).cumsum().plot()\n",
    "w_h2o__10m_c_cumsum = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__10m_c).cumsum()\n",
    "w_h2o__20m_c_cumsum = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__20m_c).cumsum()\n",
    "\n",
    "w_h2o__10m_c_corrected_cumsum = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__10m_c\n",
    "        + (\n",
    "            10*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].vertical_advection_simple_2to10\n",
    "        )\n",
    "    )\n",
    ").cumsum()\n",
    "w_h2o__20m_c_corrected_cumsum = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__20m_c\n",
    "        + (\n",
    "            20*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].vertical_advection_simple_2to20\n",
    "        )\n",
    "    )\n",
    ").cumsum()\n",
    "\n",
    "w_h2o__10m_c_cumsum.plot(           color = 'tab:blue',     linestyle = '-')\n",
    "w_h2o__20m_c_cumsum.plot(           color = 'tab:orange',   linestyle = '-')\n",
    "w_h2o__10m_c_corrected_cumsum.plot( color = 'tab:blue',     linestyle = '--',   label='With vertical advection correction, 10m')\n",
    "w_h2o__20m_c_corrected_cumsum.plot( color = 'tab:orange',   linestyle = '--',   label='With vertical advection correction, 20m')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Cumulative sublimation (mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10m, ec\\t\\t', round(w_h2o__10m_c_cumsum.iloc[-1], 1))\n",
    "print('10m, corrected\\t', round(w_h2o__10m_c_corrected_cumsum.iloc[-1], 1))\n",
    "print('20m, ec\\t\\t', round(w_h2o__20m_c_cumsum.iloc[-1], 1))\n",
    "print('20m, corrected\\t', round(w_h2o__20m_c_corrected_cumsum.iloc[-1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_diffs_10m = []\n",
    "daily_diffs_20m = []\n",
    "for date in pd.Series(w_h2o__10m_c_cumsum.index.date).unique():\n",
    "    daily_sub_corrected_10m = w_h2o__10m_c_corrected_cumsum.loc[\n",
    "        date: date+dt.timedelta(days=1)][-1] - w_h2o__10m_c_corrected_cumsum.loc[date: date+dt.timedelta(days=1)][0]\n",
    "    daily_sub_10m = w_h2o__10m_c_cumsum.loc[\n",
    "        date: date+dt.timedelta(days=1)][-1] - w_h2o__10m_c_cumsum.loc[date: date+dt.timedelta(days=1)][0]\n",
    "    daily_sub_corrected_20m = w_h2o__20m_c_corrected_cumsum.loc[\n",
    "        date: date+dt.timedelta(days=1)][-1] - w_h2o__20m_c_corrected_cumsum.loc[date: date+dt.timedelta(days=1)][0]\n",
    "    daily_sub_20m = w_h2o__20m_c_cumsum.loc[\n",
    "        date: date+dt.timedelta(days=1)][-1] - w_h2o__20m_c_cumsum.loc[date: date+dt.timedelta(days=1)][0]\n",
    "    daily_diffs_10m.append(\n",
    "        (daily_sub_corrected_10m - daily_sub_10m) / daily_sub_10m\n",
    "    )\n",
    "    daily_diffs_20m.append(\n",
    "        (daily_sub_corrected_20m - daily_sub_20m) / daily_sub_20m\n",
    "    )\n",
    "daily_diffs_df = pd.DataFrame({\n",
    "    'date' : pd.Series(w_h2o__10m_c_cumsum.index.date).unique(),\n",
    "    'daily_diffs_10m' : daily_diffs_10m,\n",
    "    'daily_diffs_20m' : daily_diffs_20m\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_h2o__10m_c_cumsum.loc['2022-12-18'].plot()\n",
    "w_h2o__10m_c_corrected_cumsum.loc['2022-12-18'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_diffs_df.sort_values('daily_diffs_10m', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_diffs_df.dropna().daily_diffs_10m.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_diffs_df.dropna().daily_diffs_10m.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_diffs_df.dropna().daily_diffs_10m.quantile(0))\n",
    "print(daily_diffs_df.dropna().daily_diffs_10m.quantile(.25))\n",
    "print(daily_diffs_df.dropna().daily_diffs_10m.quantile(.50))\n",
    "print(daily_diffs_df.dropna().daily_diffs_10m.quantile(.75))\n",
    "print(daily_diffs_df.dropna().daily_diffs_10m.quantile(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_vert_simple_df_2to10.loc['2023-04-11'][[\n",
    "    'w','ds','vertical_advection_simple_2to10'\n",
    "]].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(daily_diffs_df).mark_bar().encode(\n",
    "    alt.X('daily_diffs_10m:Q').bin(\n",
    "        extent=[-25, 125], step=5\n",
    "    ).axis(\n",
    "        values=[-25, 0, 25, 50, 75, 100, 125]\n",
    "    ).title('% change in daily sublimation w/ advection correction'),\n",
    "    alt.Y('count():Q').scale(type='symlog').axis(values=[0,1,2,10,20,50,100])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(daily_diffs_df).mark_bar().encode(\n",
    "    alt.X('daily_diffs_20m:Q').bin(\n",
    "        extent=[-25, 125], step=5\n",
    "    ).axis(\n",
    "        values=[-25, 0, 25, 50, 75, 100, 125]\n",
    "    ).title('% change in daily sublimation w/ advection correction'),\n",
    "    alt.Y('count():Q').scale(type='symlog').axis(values=[0,1,2,10,20,50,100])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_3m = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__3m_c)\n",
    "ec_5m = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__5m_c)\n",
    "ec_10m = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__10m_c)\n",
    "ec_20m = ((1800/1000)*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__20m_c)\n",
    "\n",
    "ec_advection_corrected_10m = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__10m_c\n",
    "        + (\n",
    "            10*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].vertical_advection_simple_3to10\n",
    "        )\n",
    "    )\n",
    ")\n",
    "ec_advection_corrected_20m = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].w_h2o__20m_c\n",
    "        + (\n",
    "            20*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230508'].vertical_advection_simple_3to20\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "cumsub_df = pd.DataFrame({\n",
    "    'EC (3m)' : ec_3m,\n",
    "    'EC (5m)' : ec_5m,\n",
    "    'EC (10m)' : ec_10m,\n",
    "    'EC (20m)' : ec_20m,\n",
    "    'EC w/ advection correction (10m)' : ec_advection_corrected_10m,\n",
    "    'EC w/ advection correction (20m)' : ec_advection_corrected_20m,\n",
    "})\n",
    "# calculate a combined 3m/10m estimate, selecting height based on blowing snow\n",
    "cumsub_df['EC (3 and 10m)'] = cumsub_df.apply(\n",
    "    lambda row: row['EC (10m)'] if row.name in bs_times else row['EC (3m)'],\n",
    "    axis=1\n",
    ")\n",
    "cumsub_df = cumsub_df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = [\n",
    "        'EC (3m)', \n",
    "        'EC (5m)', \n",
    "        'EC (10m)', \n",
    "        'EC w/ advection correction (10m)',\n",
    "        'EC (20m)', \n",
    "        'EC w/ advection correction (20m)',\n",
    "        'EC (3 and 10m)',\n",
    "    ]\n",
    "color_range = ['#1f77b4', '#ff7f0e', '#2ca02c', '#2ca02c', '#d62728', '#d62728', '#9467bd']\n",
    "dash_range = [[1,0], [1,0], [1,0], [4,2], [1,0], [4,2], [1,0]]\n",
    "alt.Chart(cumsub_df.reset_index()).transform_fold(\n",
    "    domain\n",
    ").transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    groupby=['key'],\n",
    "    frame =[-6,6]\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('rolling_avg:Q').title('Cumulative sublimation (mm SWE)').scale(\n",
    "        domain = [0,45]\n",
    "    ),\n",
    "    alt.Color('key:N').title('Sublimation estimate').scale(domain=domain, range=color_range),\n",
    "    alt.StrokeDash('key:N').scale(domain=domain, range=dash_range)\n",
    ").properties(width=300, height=300).display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(cumsub_df.reset_index()).transform_fold(\n",
    "    domain\n",
    ").mark_bar().encode(\n",
    "    alt.Y('key:N').title('Sublimation estimate').sort(domain),\n",
    "    alt.X('max(value):Q').title('Seasonal sublimation (mm SWE)'),\n",
    ").properties(width=300, height=300).display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsub_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### December case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = advection_1d_fluxdensity_nonnorm_df.loc['20221221 1200': '20221223 0000'][[\n",
    "        'w_h2o__3m_c',\n",
    "        'w_h2o__20m_c',\n",
    "        'vertical_advection_simple_3to10',\n",
    "        'vertical_advection_simple_3to10_uncertainty',\n",
    "        'vertical_turb_flux_divergence_3to10',\n",
    "        'vertical_turb_flux_divergence_3to20',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt',\n",
    "        'lateral_advection_3m_uncertainty',\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_advection_simple_3to20_uncertainty',\n",
    "    ]].reset_index()\n",
    "\n",
    "\n",
    "src['vertical_advection_lb'] = src['vertical_advection_simple_3to10'] - src['vertical_advection_simple_3to10_uncertainty']\n",
    "src['vertical_advection_ub'] = src['vertical_advection_simple_3to10'] + src['vertical_advection_simple_3to10_uncertainty']\n",
    "\n",
    "lines_chart = alt.Chart(src).transform_fold([\n",
    "    'vertical_advection_simple_3to10',\n",
    "    # 'vertical_advection_simple_3to20',\n",
    "    'vertical_turb_flux_divergence_3to10',\n",
    "    # 'vertical_turb_flux_divergence_3to20',\n",
    "    # 'ds/dt'\n",
    "]).mark_line().encode(\n",
    "    alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "    alt.Y('value:Q').title(['Water vapor flux density', '(g/m^3/s)']).scale(\n",
    "        domain = [-0.002, 0.005], clamp=True\n",
    "    ),\n",
    "    alt.Color('key:N', )\n",
    ").properties(width=250, height = 166.66) \n",
    "\n",
    "vert_adv_uncert_chart = alt.Chart(src).mark_area(\n",
    "    color = '#1f77b4',\n",
    "    opacity=0.35\n",
    ").encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('vertical_advection_lb:Q').title(''),\n",
    "    alt.Y2('vertical_advection_ub:Q').title(''),\n",
    ")    \n",
    "\n",
    "bs_chart = alt.Chart(\n",
    "    tidy_df[tidy_df.measurement == 'snow flux'].set_index('time').loc['20221221 1200': '20221223 0000'].reset_index()\n",
    ").mark_line(color='black').encode(\n",
    "    alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "    alt.Y('value:Q').title(['Blowing snow flux', '(g/m^2/s)']),\n",
    "    alt.StrokeDash('height:N', legend=None)\n",
    ")\n",
    "\n",
    "w_q_chart = alt.Chart(\n",
    "    tidy_df[tidy_df.variable.isin(\n",
    "        [\n",
    "            'w_h2o__2m_c_raw', 'w_h2o__3m_c_raw', \n",
    "            'w_h2o__5m_c_raw', \n",
    "            'w_h2o__10m_c_raw', 'w_h2o__15m_c_raw','w_h2o__20m_c_raw'])\n",
    "    ].set_index('time').loc['20221221 1200': '20221223 0000'].reset_index()\n",
    ").transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-1,1],\n",
    "    groupby = ['height']\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'). axis().title(None),\n",
    "    alt.Y('rolling_avg:Q').title([\"w'q' (g/m^2/s)\"]),\n",
    "    alt.Color('height:O').scale(scheme='turbo')\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    bs_chart.properties(width=250, height = 83.33)\n",
    "    &\n",
    "    w_q_chart.properties(width=250, height = 83.33)\n",
    "    &\n",
    "    (vert_adv_uncert_chart + lines_chart)\n",
    ").resolve_scale(\n",
    "    x='shared', color='independent', strokeDash='independent'\n",
    ").display(renderer='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### February case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = advection_1d_fluxdensity_nonnorm_df.loc['20230211': '20230212'][[\n",
    "        'w_h2o__3m_c',\n",
    "        'w_h2o__20m_c',\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to10',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt'\n",
    "    ]].reset_index()\n",
    "\n",
    "feb_casestudy_differential_form = (\n",
    "    alt.Chart(src).transform_fold([\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to10',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt'\n",
    "    ]).mark_line().encode(\n",
    "        alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "        alt.Y('value:Q').title(['Water vapor flux density', '(g/m^2/s)']),\n",
    "        alt.Color('key:N', )\n",
    "    ).properties(width=400, height = 200) &\n",
    "    alt.Chart(\n",
    "        tidy_df[tidy_df.measurement == 'snow flux'].set_index('time').loc['20230211': '20230212'].reset_index()\n",
    "    ).mark_line(color='black').encode(\n",
    "        alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "        alt.Y('value:Q').title(['Blowing snow flux', '(g/m^2/s)']),\n",
    "        alt.StrokeDash('height:N', legend=None)\n",
    "    ).properties(width=400, height = 200)\n",
    ").resolve_scale(x='shared', color='independent', strokeDash='independent')\n",
    "\n",
    "feb_casestudy_differential_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### April/May case studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nice_advection_timeseries(date, date2=None, frame=[-2,2], width=300, height = 200, ydomain=[-0.001,0.001]):\n",
    "    if date2 is None:\n",
    "        date2 = date\n",
    "    src = advection_1d_fluxdensity_nonnorm_df.loc[date: date2][[\n",
    "            'w_h2o__3m_c',\n",
    "            'w_h2o__20m_c',\n",
    "            'vertical_advection_simple_3to10',\n",
    "            'vertical_advection_simple_3to20',\n",
    "            'vertical_advection_simple_3to20_uncertainty',\n",
    "            'vertical_turb_flux_divergence_3to20',\n",
    "            'lateral_advection_3m',\n",
    "            'lateral_advection_3m_uncertainty',\n",
    "            'ds/dt'\n",
    "        ]].reset_index()\n",
    "\n",
    "    src['vertical_advection_lb'] = src['vertical_advection_simple_3to20'] - src['vertical_advection_simple_3to20_uncertainty']\n",
    "    src['vertical_advection_ub'] = src['vertical_advection_simple_3to20'] + src['vertical_advection_simple_3to20_uncertainty']\n",
    "    src['lateral_advection_lb'] = src['lateral_advection_3m'] - src['lateral_advection_3m_uncertainty']\n",
    "    src['lateral_advection_ub'] = src['lateral_advection_3m'] + src['lateral_advection_3m_uncertainty']\n",
    "\n",
    "    flux_div_chart = alt.Chart(src).transform_fold([\n",
    "        # 'vertical_advection_simple_3to10',\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to20',\n",
    "        # 'lateral_advection_3m',\n",
    "        # 'ds/dt'\n",
    "    ]).transform_window(\n",
    "        rolling_avg = 'mean(value)',\n",
    "        frame=frame,\n",
    "        groupby = ['key']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['Water vapor flux density', '(g/m^2/s)']).scale(domain=ydomain, clamp=True),\n",
    "        alt.Color('key:N')\n",
    "    ).properties(width=width, height = height)\n",
    "\n",
    "    vert_adv_errorbar = alt.Chart(src).transform_window(\n",
    "        rollavg_vert_adv_lb = 'mean(vertical_advection_lb)',\n",
    "        rollavg_vert_adv_ub = 'mean(vertical_advection_ub)',\n",
    "        frame=frame,\n",
    "        groupby = ['key']\n",
    "    ).mark_area(\n",
    "        opacity = 0.3,\n",
    "        color = '#1f77b4'\n",
    "    ).encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rollavg_vert_adv_lb:Q').title(''),\n",
    "        alt.Y2('rollavg_vert_adv_ub:Q').title(''),\n",
    "    )\n",
    "\n",
    "\n",
    "    return  vert_adv_errorbar + flux_div_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chart(date):\n",
    "    flux_div_chart = get_nice_advection_timeseries(date).properties(\n",
    "        width=300, height = 125\n",
    "    )\n",
    "\n",
    "    w_chart = alt.Chart(\n",
    "        tidy_df[tidy_df.variable.isin(\n",
    "            ['w_3m_c', 'w_5m_c', 'w_10m_c', 'w_15m_c','w_20m_c'])\n",
    "        ].set_index('time').sort_index().loc[date: date].reset_index()\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'mean(value)',\n",
    "        frame=[-2,2],\n",
    "        groupby = ['height']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['Vertical wind speed (m/s)']),\n",
    "        # alt.Y('value:Q').title(['Vertical wind speed (m/s)']),\n",
    "        alt.Color('height:O').scale(scheme='turbo')\n",
    "    ).properties(width=300, height = 125)\n",
    "\n",
    "    dir_chart = alt.Chart(\n",
    "        tidy_df[\n",
    "            tidy_df.variable == 'dir_20m_c'\n",
    "        ].set_index('time').loc[date: date].reset_index()\n",
    "    ).mark_line(color='black', strokeDash=[4,2]).encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('value:Q').title(['Wind direction']),\n",
    "    ).properties(width=300, height = 125)\n",
    "\n",
    "    mixingratio_chart = alt.Chart(\n",
    "        tidy_df.query(\"measurement == 'mixing ratio'\").set_index('time').loc[date: date].reset_index()\n",
    "    ).transform_filter(\n",
    "        'hours(datum.time)%3 == 0 & hours(datum.time)%6 != 0'\n",
    "    ).transform_calculate(\n",
    "        value_g_per_kg = '1000 * datum.value'\n",
    "    ).mark_line().encode(\n",
    "        alt.X('mean(value_g_per_kg):Q').sort('-y').title('s (g/kg)').scale(zero=True),\n",
    "        alt.Y('height:Q'),\n",
    "        alt.Facet('hours(time):O', spacing=5),\n",
    "    ).properties(width=70, height = 70)\n",
    "\n",
    "    # wspd_chart = alt.Chart(\n",
    "    #     tidy_df.query(\"measurement == 'wind speed'\").query(\"tower == 'c'\").set_index('time').loc[date: date].reset_index()\n",
    "    # ).transform_filter(\n",
    "    #     # 'hours(datum.time)%3 == 0 & hours(datum.time)%6 != 0'\n",
    "    #     'hours(datum.time)%1 == 0'\n",
    "    # ).mark_point().encode(\n",
    "    #     alt.X('mean(value):Q').sort('-y'),\n",
    "    #     alt.Y('height:Q'),\n",
    "    #     alt.Facet('hours(time):O', spacing=5),\n",
    "    # ).properties(width=70, height = 70)\n",
    "\n",
    "    lhflux_chart = alt.Chart(\n",
    "        tidy_df[tidy_df.variable.isin(\n",
    "            ['w_h2o__3m_c_raw', \n",
    "             'w_h2o__5m_c_raw', \n",
    "             'w_h2o__10m_c_raw', 'w_h2o__15m_c_raw','w_h2o__20m_c_raw'])\n",
    "        ].set_index('time').loc[date: date].reset_index()\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'mean(value)',\n",
    "        frame=[-1,1],\n",
    "        groupby = ['height']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rolling_avg:Q').title([\"w'q' (g/m^2/s)\"]),\n",
    "        alt.Color('height:O').scale(scheme='turbo')\n",
    "    ).properties(width=300, height = 125)\n",
    "\n",
    "    ri_chart = alt.Chart(\n",
    "        tidy_df[tidy_df.variable.isin(\n",
    "            ['Ri_3m_c', 'Ri_20m_c'])\n",
    "        ].set_index('time').loc[date: date].reset_index()\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'median(value)',\n",
    "        frame=[-1,1],\n",
    "        groupby = ['height']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['Ri']).scale(domain=[-1,2], clamp=True),\n",
    "        alt.Color('height:O').scale(scheme='turbo')\n",
    "    ).properties(width=300, height = 125)\n",
    "\n",
    "    T_chart = alt.Chart(\n",
    "        tidy_df[tidy_df.variable.isin(\n",
    "            ['Tsurf_c', 'T_3m_c', 'T_20m_c'])\n",
    "        ].set_index('time').loc[date: date].reset_index()\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'median(value)',\n",
    "        frame=[-1,1],\n",
    "        groupby = ['height']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['T (˚C)']),\n",
    "        alt.Color('height:O').scale(scheme='turbo')\n",
    "    ).properties(width=300, height = 125)\n",
    "\n",
    "    wspd_chart = alt.Chart(\n",
    "        tidy_df[tidy_df.variable.isin(\n",
    "            ['spd_3m_c', 'spd_20m_c'])\n",
    "        ].set_index('time').loc[date: date].reset_index()\n",
    "    ).transform_window(\n",
    "        rolling_avg = 'median(value)',\n",
    "        frame=[-1,1],\n",
    "        groupby = ['height']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis().title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['Wind speed (m/s)']),\n",
    "        alt.Color('height:O').scale(scheme='turbo')\n",
    "    ).properties(width=300, height = 125)\n",
    "\n",
    "    return (\n",
    "        lhflux_chart \n",
    "        & (w_chart + dir_chart).resolve_scale(y='independent') \n",
    "        & flux_div_chart \n",
    "        # & ri_chart & mixingratio_chart \n",
    "        # & wspd_chart \n",
    "        # & T_chart\n",
    "    ).resolve_scale(color='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_chart('20230505')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(get_chart('20230415') | get_chart('20230417') ).display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(get_chart('20230415') | get_chart('20230607') ).display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(get_chart('20230415') | get_chart('20230418') ).display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = alt.Chart().transform_calculate(y='0').mark_rule().encode(y='y:Q')\n",
    "local_downvalley_wind_times = tidy_df[\n",
    "    tidy_df.variable == 'dir_3m_c'\n",
    "].dropna().query(\"value < 360\").query(\"value > 252\").drop_duplicates().time\n",
    "# src = src[src.time.isin(local_downvalley_wind_times)]\n",
    "vars = [\n",
    "        'w_2m_c', 'w_3m_c', 'w_5m_c', 'w_10m_c', 'w_15m_c', 'w_20m_c',\n",
    "        'w_3m_d', 'w_10m_d',\n",
    "        'w_3m_ue', 'w_10m_ue',\n",
    "        'w_3m_uw', 'w_10m_uw',\n",
    "    ]\n",
    "(alt.Chart(\n",
    "    tidy_df[tidy_df.variable.isin(\n",
    "        ['dir_3m_c'] + vars\n",
    "    )].pivot(index='time', columns='variable', values='value')\n",
    ").transform_fold(vars).mark_boxplot(outliers=False).encode(\n",
    "    alt.X('dir_3m_c:Q').bin(maxbins=20),\n",
    "    alt.Y('value:Q').scale(domain=[-0.5, 0.5], clamp=True).title('Vertical wind speed (m/s)'),\n",
    "    alt.Facet('key:O', columns = 3).sort(vars)\n",
    ")).properties(height = 200, width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = alt.Chart().transform_calculate(y='0').mark_rule().encode(y='y:Q')\n",
    "local_downvalley_wind_times = tidy_df[\n",
    "    tidy_df.variable == 'dir_3m_c'\n",
    "].dropna().query(\"value < 360\").query(\"value > 252\").drop_duplicates().time\n",
    "# src = src[src.time.isin(local_downvalley_wind_times)]\n",
    "vars = [\n",
    "        'w_10m_c',\n",
    "        'w_10m_d',\n",
    "         'w_10m_ue',\n",
    "         'w_10m_uw',\n",
    "    ]\n",
    "(alt.Chart(\n",
    "    tidy_df[tidy_df.variable.isin(\n",
    "        ['dir_3m_c'] + vars\n",
    "    )].pivot(index='time', columns='variable', values='value')\n",
    ").transform_fold(vars).mark_boxplot(outliers=False).encode(\n",
    "    alt.X('dir_3m_c:Q').bin(maxbins=20),\n",
    "    alt.Y('value:Q').scale(domain=[-0.5, 0.5], clamp=True).title('Vertical wind speed (m/s)'),\n",
    "    alt.Facet('key:O', columns = 2).sort(vars)\n",
    ")).properties(height = 200, width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = (\n",
    "    (1800/1000)*(advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c)\n",
    ")\n",
    "corrected_10m = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c\n",
    "        + (\n",
    "            10*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].vertical_advection_simple_3to10\n",
    "        )\n",
    "    )\n",
    ")\n",
    "corrected_20m = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c\n",
    "        + (\n",
    "            20*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].vertical_advection_simple_3to20\n",
    "        )\n",
    "    )\n",
    ")\n",
    "raw.loc['20230415': '20230415'].cumsum().plot(label = 'raw')\n",
    "corrected_10m.loc['20230415': '20230415'].cumsum().plot(label = 'corrected (10m)')\n",
    "corrected_20m.loc['20230415': '20230415'].cumsum().plot(label = 'corrected (20m)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = (\n",
    "    (1800/1000)*(advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c)\n",
    ")\n",
    "corrected_10m = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c\n",
    "        + (\n",
    "            10*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].vertical_advection_simple_3to10\n",
    "        )\n",
    "    )\n",
    ")\n",
    "corrected_20m = (\n",
    "    (1800/1000)*(\n",
    "        advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].w_h2o__10m_c\n",
    "        + (\n",
    "            20*advection_1d_fluxdensity_nonnorm_df.loc['20221130': '20230619'].vertical_advection_simple_3to20\n",
    "        )\n",
    "    )\n",
    ")\n",
    "raw.loc['20230607': '20230607'].cumsum().plot(label = 'raw')\n",
    "corrected_10m.loc['20230607': '20230607'].cumsum().plot(label = 'corrected (10m)')\n",
    "corrected_20m.loc['20230607': '20230607'].cumsum().plot(label = 'corrected (20m)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = [\n",
    "    'w_h2o_',   'u_h2o_',   'v_h2o_', \n",
    "    'w_tc_',    'u_tc_',    'v_tc_',   \n",
    "    'u_w_', 'v_w_', \n",
    "    'turbulent kinetic energy',\n",
    "    'mixing ratio',\n",
    "    'potential temperature',\n",
    "    'w',\n",
    "]\n",
    "heights = [3, 5, 10, 15, 20]\n",
    "date = '20230417'\n",
    "src = tidy_df[tidy_df.measurement.isin(measurements)]\n",
    "src = src[ ~ src.variable.str.contains('predicted')]\n",
    "src = src.set_index('time').loc[date: date].reset_index()\n",
    "src = src.query(\"tower == 'c'\")\n",
    "src = src[src.height.isin(heights)]\n",
    "\n",
    "alt.Chart(src).mark_line().encode(\n",
    "    alt.X('time:T'). axis().title(None),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.Facet(\"measurement:N\", columns = 3).sort(\n",
    "        measurements\n",
    "    )\n",
    ").properties(width=300, height = 125).resolve_scale(\n",
    "    y='independent'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_mixingratio_vars = [\n",
    "    'Tsurfmixingratio_c',\n",
    "    'mixingratio_1m_c',\n",
    "    'mixingratio_2m_c',\n",
    "    'mixingratio_3m_c',\n",
    "    'mixingratio_4m_c',\n",
    "    'mixingratio_5m_c',\n",
    "    'mixingratio_6m_c',\n",
    "    'mixingratio_7m_c',\n",
    "    'mixingratio_8m_c',\n",
    "    'mixingratio_9m_c'\n",
    "    'mixingratio_10m_c',\n",
    "    'mixingratio_11m_c',\n",
    "    'mixingratio_12m_c',\n",
    "    'mixingratio_13m_c',\n",
    "    'mixingratio_14m_c',\n",
    "    'mixingratio_15m_c',\n",
    "    'mixingratio_16m_c',\n",
    "    'mixingratio_17m_c',\n",
    "    'mixingratio_18m_c',\n",
    "    'mixingratio_19m_c',\n",
    "    'mixingratio_20m_c',\n",
    "]\n",
    "s_compare_df = tidy_df[tidy_df.variable.isin(kps_mixingratio_vars)].set_index('time').loc['20230505':'20230505'][['value', 'height']]\n",
    "s_compare_df['site'] = 'kps'\n",
    "s_compare_df_annex = s_annex_df.sort_index().loc['20230505':'20230505'].rename(columns={'mixing_ratio_annex': 'value'})\n",
    "s_compare_df_annex = s_compare_df_annex.resample('30min').mean()\n",
    "s_compare_df_annex['height'] = 2.8\n",
    "s_compare_df_annex['site'] = 'annex'\n",
    "s_compare_df = pd.concat([s_compare_df.reset_index(), s_compare_df_annex.reset_index()])\n",
    "s_compare_df['value'] = s_compare_df['value']*1000\n",
    "alt.Chart(s_compare_df).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q').scale(zero=False).title('mixing ratio (g/kg)'),\n",
    "    alt.Color('height:N').scale(\n",
    "        domain = [2.8, 2, 3, 4],\n",
    "        range = ['black', '#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    )\n",
    ").properties(width=400, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.Chart(\n",
    "    tidy_df.query(\"measurement == 'wind speed'\").set_index('time').loc['20230415'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.StrokeDash('tower:N')\n",
    ") & alt.Chart(\n",
    "    tidy_df.query(\"measurement == 'temperature'\").set_index('time').loc['20230415'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.StrokeDash('tower:N')\n",
    ")).resolve_scale(color='independent', strokeDash='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.Chart(\n",
    "    tidy_df.query(\"measurement == 'wind speed'\").set_index('time').loc['20230417'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.StrokeDash('tower:N')\n",
    ") & alt.Chart(\n",
    "    tidy_df.query(\"measurement == 'temperature'\").set_index('time').loc['20230417'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('height:O').scale(scheme='turbo'),\n",
    "    alt.StrokeDash('tower:N')\n",
    ")).resolve_scale(color='independent', strokeDash='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_compare_df['site_and_height'] = s_compare_df['site'] + '_' + s_compare_df['height'].astype('str')\n",
    "s_compare_df = s_compare_df.pivot(index='time', values='value', columns='site_and_height')\n",
    "(s_compare_df['kps_3.0'] - s_compare_df['annex_2.8']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(s_compare_df['kps_3.0'] - s_compare_df['annex_2.8']).mean(), (s_compare_df['kps_3.0'] - s_compare_df['annex_2.8']).max(), (s_compare_df['kps_3.0'] - s_compare_df['annex_2.8']).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(s_compare_df['kps_20.0'] - s_compare_df['kps_3.0']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(s_compare_df['kps_20.0'] - s_compare_df['kps_3.0']).mean(),(s_compare_df['kps_20.0'] - s_compare_df['kps_3.0']).max(),(s_compare_df['kps_20.0'] - s_compare_df['kps_3.0']).min(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = s_compare_df.query(\"height <= 20\").query(\"height > 0\")\n",
    "alt.Chart(src).transform_filter(\n",
    "    'hours(datum.time) % 3 == 0 & hours(datum.time) >= 6 & hours(datum.time) <= 18'\n",
    ").mark_line(point=True).encode(\n",
    "    alt.X('mean(value):Q').scale(zero=False).title(['mixing ratio', '(g/kg)']).axis(values=[2,3,4]),\n",
    "    alt.Y('height').title('height (m)'),\n",
    "    alt.Color('site:N', sort='descending').scale(\n",
    "        domain = ['kps', 'annex'],\n",
    "        range = ['#ff7f0e', 'black', ],\n",
    "    ),\n",
    "    alt.Order('height'),\n",
    "    alt.Facet('hours(time):T', columns=5, spacing=2).header(format='%H:%M')\n",
    ").properties(width=75, height=100).resolve_scale(x='shared').display(renderer='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    tidy_df[tidy_df.variable == 'spd_3m_c'].set_index('time').loc['20230505':'20230505'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q').title('Horizontal wind speed (m/s)')\n",
    ").properties(width=400, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    tidy_df[tidy_df.measurement == 'w_h2o_'].query(\"tower == 'c'\").set_index('time').loc['20230505 1000 ': '20230505 1700'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('mean(value):Q').sort('-y'),\n",
    "    alt.Y('height:Q'),\n",
    "    alt.Color('minutes(time):N'),\n",
    "    alt.Facet('hours(time)', columns=8)\n",
    ").properties(height = 100, width= 100) &\\\n",
    "alt.Chart(\n",
    "    tidy_df[tidy_df.measurement == 'w'].query(\"tower == 'c'\").set_index('time').loc['20230505 1000 ': '20230505 1700'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('mean(value):Q').sort('-y'),\n",
    "    alt.Y('height:Q'),\n",
    "    alt.Color('minutes(time):N'),\n",
    "    alt.Facet('hours(time)', columns=8)\n",
    ").properties(height = 100, width= 100) &\\\n",
    "alt.Chart(\n",
    "    tidy_df[tidy_df.measurement == 'mixing ratio'].query(\"tower == 'c'\").set_index('time').loc['20230505 1000 ': '20230505 1700'].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('mean(value):Q').sort('-y'),\n",
    "    alt.Y('height:Q'),\n",
    "    alt.Color('minutes(time):N'),\n",
    "    alt.Facet('hours(time)', columns=8)\n",
    ").properties(height = 100, width= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src = tidy_df[tidy_df.measurement == 'wind direction'][tidy_df.height.isin([3,10,20])]\n",
    "src = src.set_index('time').loc['20230501':'20230508'].reset_index()\n",
    "alt.Chart(src).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.StrokeDash('height:O')\n",
    ").properties(width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = advection_1d_fluxdensity_nonnorm_df.loc['20230415': '20230420'][[\n",
    "        'w_h2o__3m_c',\n",
    "        'w_h2o__20m_c',\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to20',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt'\n",
    "    ]].reset_index()\n",
    "\n",
    "april_casestudy_differential_form = (\n",
    "    alt.Chart(src).transform_fold([\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to20',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt'\n",
    "    ]).transform_window(\n",
    "        rolling_avg = 'mean(value)',\n",
    "        frame=[-2,2],\n",
    "        groupby = ['key']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['Water vapor flux density', '(g/m^2/s)']),\n",
    "        alt.Color('key:N')\n",
    "    ).properties(width=400, height = 200) &\n",
    "    alt.Chart(\n",
    "        tidy_df[tidy_df.measurement == 'snow flux'].set_index('time').loc['20230415': '20230420'].reset_index()\n",
    "    ).mark_line(color='black').encode(\n",
    "        alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "        alt.Y('value:Q').title(['Blowing snow flux', '(g/m^2/s)']),\n",
    "        alt.StrokeDash('height:N', )\n",
    "    ).properties(width=400, height = 200)\n",
    ").resolve_scale(x='shared', color='independent', strokeDash='independent')\n",
    "\n",
    "april_casestudy_differential_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mid-May Case Study, lateral advection due to source heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = advection_1d_fluxdensity_nonnorm_df.loc['20230510': '20230520'][[\n",
    "        'w_h2o__3m_c',\n",
    "        'w_h2o__20m_c',\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to20',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt'\n",
    "    ]].reset_index()\n",
    "\n",
    "may_casestudy_differential_form = (\n",
    "    alt.Chart(src).transform_fold([\n",
    "        'vertical_advection_simple_3to20',\n",
    "        'vertical_turb_flux_divergence_3to20',\n",
    "        'lateral_advection_3m',\n",
    "        'ds/dt'\n",
    "    ]).transform_window(\n",
    "        rolling_avg = 'mean(value)',\n",
    "        frame=[-2,2],\n",
    "        groupby = ['key']\n",
    "    ).mark_line().encode(\n",
    "        alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "        alt.Y('rolling_avg:Q').title(['Water vapor flux density', '(g/m^2/s)']),\n",
    "        alt.Color('key:N')\n",
    "    ).properties(width=400, height = 200) &\n",
    "    alt.Chart(\n",
    "        tidy_df[tidy_df.measurement == 'snow flux'].set_index('time').loc['20230510': '20230520'].reset_index()\n",
    "    ).mark_line(color='black').encode(\n",
    "        alt.X('time:T'). axis(format='%m/%d').title(None),\n",
    "        alt.Y('value:Q').title(['Blowing snow flux', '(g/m^2/s)']),\n",
    "        alt.StrokeDash('height:N', )\n",
    "    ).properties(width=400, height = 200)\n",
    ").resolve_scale(x='shared', color='independent', strokeDash='independent')\n",
    "\n",
    "may_casestudy_differential_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare IRGA and Hygrometer measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.concat([\n",
    "    (1000*tidy_df[tidy_df.measurement=='specific humidity'].set_index(['time','height','tower', 'measurement'])),\n",
    "    tidy_df[tidy_df.measurement=='air density'].set_index(['time','height','tower', 'measurement']),\n",
    "    tidy_df[tidy_df.measurement=='Water vapor density'].set_index(['time','height','tower', 'measurement'])\n",
    "])[['value']]\n",
    "comparison_df = comparison_df.reset_index().pivot_table(values='value', columns='measurement', index=['time','height','tower'])\n",
    "comparison_df ['Water vapor density (hygr)'] = comparison_df['air density'] * comparison_df['specific humidity']\n",
    "comparison_df = comparison_df.rename(columns={'Water vapor density': 'Water vapor density (irga)'})\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "src = comparison_df.loc[:,3,'c'].reset_index()\n",
    "# max_val = math.ceil(\n",
    "#     src[['Water vapor density (hygr)', 'Water vapor density (irga)']].dropna().values.max()\n",
    "# )\n",
    "max_val = 7\n",
    "line = pd.DataFrame({\n",
    "    'Goals Conceded': [0, max_val],\n",
    "    'Goals': [0, max_val],\n",
    "})\n",
    "\n",
    "arr = np.array([0, max_val] * (len(src) // 2))\n",
    "if len(arr) < len(src):\n",
    "    src['one'] = list(arr) + [0]\n",
    "    src['onetoone'] = list(arr) + [0]\n",
    "else:\n",
    "    src['one'] = list(arr)\n",
    "    src['onetoone'] = list(arr)\n",
    "\n",
    "line_plot = alt.Chart().mark_line(color= 'grey').encode(\n",
    "    alt.X('one', title=''),\n",
    "    alt.Y('onetoone', title='')\n",
    ")\n",
    "scatter_plot = alt.Chart().mark_rect().encode(\n",
    "    alt.X('Water vapor density (hygr):Q').scale(domain = [0, max_val], clamp=True).bin(maxbins=75).axis(values=[0,1,2,3,4,5,6,7]).title('Water vapor density (hygr)'),\n",
    "    alt.Y('Water vapor density (irga):Q').scale(domain = [0, max_val], clamp=True).bin(maxbins=75).axis(values=[0,1,2,3,4,5,6,7]).title('Water vapor density (irga)'),\n",
    "    alt.Color('count()'),\n",
    ").properties(width=200, height=200)\n",
    "\n",
    "src['diff'] = (src.set_index('time')['Water vapor density (irga)'] - src.set_index('time')['Water vapor density (hygr)']).values\n",
    "\n",
    "\n",
    "meanerror_by_month = round(src.groupby(src.time.dt.month).mean().drop(columns='time')['diff'], 3)\n",
    "r2_by_month = round(src.groupby(src.time.dt.month)[[\n",
    "    'Water vapor density (hygr)', 'Water vapor density (irga)'\n",
    "]].apply(\n",
    "    lambda df: r2_score(df.dropna()['Water vapor density (hygr)'], df.dropna()['Water vapor density (irga)'])\n",
    "), 3)\n",
    "\n",
    "def r2_plot(month, title):\n",
    "    return alt.layer(\n",
    "        scatter_plot,\n",
    "        line_plot,\n",
    "        data=src[(src.time.dt.month == month)]\n",
    "    ).properties(title=f'{title} (ME: {meanerror_by_month.loc[month]}, R2: {r2_by_month.loc[month]})')\n",
    "\n",
    "(\n",
    "    r2_plot(11, 'Nov.') | r2_plot(12, 'Dec.') | r2_plot(1, 'Jan.') | r2_plot(2, 'Feb.') | r2_plot(3, 'Mar.') | r2_plot(4, 'Apr.') | r2_plot(5, 'May') \n",
    ") & (\n",
    "    alt.layer(\n",
    "        alt.Chart().mark_rule().transform_calculate(\n",
    "            y = '0'\n",
    "        ).mark_rule().encode(alt.Y('y:Q')),\n",
    "        alt.Chart().mark_line().encode(\n",
    "            alt.X('hoursminutes(time):T'),\n",
    "            alt.Y('mean(diff):Q').title('Mean difference (irga - hygr) (g/m^3)'),\n",
    "        ),\n",
    "        data = src[(src.time.dt.month != 10)]\n",
    "    ).properties(width=230, height=230).facet(\n",
    "        column=alt.Column('month(time):T', sort=[11,12,1,2,3,4,5,6])\n",
    "    )  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL vertical staring BL turbulence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import act.discovery, act.io\n",
    "# Inputs\n",
    "username = os.getenv(\"ARM_USERNAME\")\n",
    "token = os.getenv(\"ARM_TOKEN\")\n",
    "DATE_FORMAT_STR = '%Y-%m-%d'\n",
    "start_date = \"20230505\"\n",
    "end_date = \"20230506\"\n",
    "DLW_DATA_STREAM = 'gucdlprofwstats4newsM1.c1'\n",
    "DLW_DATA_STREAM_FILEEXT = '.cdf'\n",
    "DLW_OUTPUT_DIR = os.path.join(\"/Users/elischwat/Development/data/sublimationofsnow/\", DLW_DATA_STREAM)\n",
    "file_list = act.discovery.download_arm_data(\n",
    "            username, token, DLW_DATA_STREAM, start_date, end_date, output = DLW_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wstats_df = act.io.read_arm_netcdf(file_list).to_dataframe().reset_index()\n",
    "wstats_df = utils.modify_df_timezone(wstats_df, 'UTC', 'US/Mountain')\n",
    "wstats_df = wstats_df[(wstats_df.time > '20230505') & (wstats_df.time < '20230506')]\n",
    "wstats_df['time_low'] = wstats_df['time'] - dt.timedelta(minutes=5)\n",
    "wstats_df['time_high'] = wstats_df['time'] + dt.timedelta(minutes=5)\n",
    "wstats_df['height_low'] = wstats_df['height'] - 15\n",
    "wstats_df['height_high'] = wstats_df['height'] + 15\n",
    "wstats_df = wstats_df.rename(columns={'w_variance': 'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    wstats_df.set_index('time').query(\"height < 1000\").reset_index()\n",
    ").mark_bar().encode(\n",
    "    alt.X('w:Q').title([\"w\", \"(m/s)\"]).bin(step=0.25).axis(values=[-4,-2,-1,0,1,2,4]),\n",
    "    alt.Y('count():Q')\n",
    ").properties(\n",
    "    width=200, height = 200,\n",
    ") | alt.Chart(\n",
    "    wstats_df.set_index('time').query(\"height < 1000\").reset_index()\n",
    ").mark_rect().encode(\n",
    "    alt.X('time_low:T').title('time'),\n",
    "    alt.X2('time_high:T'),\n",
    "    alt.Y('height_low:Q').title('Height (m)'),\n",
    "    alt.Y2('height_high:Q'),\n",
    "    alt.Color('w:Q').title([\"w\", \"(m/s)\"]).scale(scheme='purpleorange', domain=[-1,1],),\n",
    "    tooltip='value'\n",
    ").properties(\n",
    "    width=500, height = 200,\n",
    "    title = 'Vertical velocity from Doppler Lidar at Gothic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = wstats_df.set_index('time').query(\"height < 1000\")[['w', 'height']]\n",
    "src = src.groupby([pd.Grouper(freq='30min'), 'height']).mean().reset_index()\n",
    "src['time_low'] = src['time'] - dt.timedelta(minutes=15)\n",
    "src['time_high'] = src['time'] + dt.timedelta(minutes=15)\n",
    "src['height_low'] = src['height'] - 15\n",
    "src['height_high'] = src['height'] + 15\n",
    "\n",
    "alt.Chart(\n",
    "    src\n",
    ").mark_rect().encode(\n",
    "    alt.X('time_low:T').title('time'),\n",
    "    alt.X2('time_high:T'),\n",
    "    alt.Y('height_low:Q').title('Height (m)'),\n",
    "    alt.Y2('height_high:Q'),\n",
    "    alt.Color('w:Q').title([\"w\", \"(m/s)\"]).scale(scheme='purpleorange', domain=[-1,1],),\n",
    ").properties(\n",
    "    width=500, height = 200,\n",
    "    title = 'Vertical velocity from Doppler Lidar at Gothic'\n",
    ") &\\\n",
    "alt.Chart(\n",
    "    wstats_df.set_index('time').query(\"height < 500\")[['w', 'height']].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('mean(w):Q')\n",
    ").properties(width=500, height = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(wstats_df).mark_bar().encode(\n",
    "    alt.X('value:Q').title([\"w'w'\", \"(m² s⁻²)\"]).bin(step=2),\n",
    "    alt.Y('count():Q')\n",
    ").properties(\n",
    "    width=200, height = 200,\n",
    ") | alt.Chart(\n",
    "    wstats_df.set_index('time').query(\"height < 2000\").reset_index()\n",
    ").mark_rect().encode(\n",
    "    alt.X('time_low:T').title('time'),\n",
    "    alt.X2('time_high:T'),\n",
    "    alt.Y('height_low:Q').title('Height (m)'),\n",
    "    alt.Y2('height_high:Q'),\n",
    "    alt.Color('value:Q').title([\"w'w'\", \"(m² s⁻²)\"]).scale(scheme='turbo'),\n",
    "    tooltip='value'\n",
    ").properties(\n",
    "    width=500, height = 200,\n",
    "    title = 'Vertical velocity variance from Doppler Lidar at Gothic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[\n",
    "        (tidy_df.time > '20230505') & (tidy_df.time < '20230506')\n",
    "    ].query(\"measurement == 'w_w_'\").query(\"tower == 'c'\")\n",
    "src['time_low'] = src['time'] - dt.timedelta(minutes=15)\n",
    "src['time_high'] = src['time'] + dt.timedelta(minutes=15)\n",
    "src['height_low'] = src['height'].apply(lambda h: {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    5: 3,\n",
    "    10: 6.25,\n",
    "    15: 10.25,\n",
    "    20: 14.5,\n",
    "}.get(h))\n",
    "src['height_high'] = src['height'].apply(lambda h: {\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    5: 6.25,\n",
    "    10: 10.25,\n",
    "    15: 14.5,\n",
    "    20: 20,\n",
    "}.get(h))\n",
    "\n",
    "alt.Chart(src).mark_bar().encode(\n",
    "    alt.X('value:Q').title([\"w'w' (m² s⁻²)\"]).bin(),\n",
    "    alt.Y('count():Q')\n",
    ").properties(\n",
    "    width=200, height = 200,\n",
    ") | alt.Chart(\n",
    "    src\n",
    ").mark_rect().encode(\n",
    "    alt.X('time_low:T').title('time'),\n",
    "    alt.X2('time_high:T'),\n",
    "    alt.Y('height_low:Q').title('Height (m)'),\n",
    "    alt.Y2('height_high:Q'),\n",
    "    alt.Color('value:Q').title([\"w'w'\", \"(m² s⁻²)\"]).scale(scheme='turbo'),\n",
    "    tooltip='value'\n",
    ").properties(\n",
    "    width=500, height = 200,\n",
    "    title = \"w'w' from Tower c\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_chart = alt.Chart(\n",
    "        wstats_df.set_index('time').query(\"height < 2000\").query(\"height >= 20\").reset_index()\n",
    "    ).mark_rect().encode(\n",
    "        alt.X('time_low:T').title('time').axis(None),\n",
    "        alt.X2('time_high:T'),\n",
    "        alt.Y('height_low:Q').title('Height (m)').scale(domain = [20, 2000]),\n",
    "        alt.Y2('height_high:Q'),\n",
    "        alt.Color('value:Q').title([\"w'w'\", \"(m² s⁻²)\"]).scale(scheme='turbo'),\n",
    "        tooltip='value'\n",
    "    ).properties(\n",
    "        width=500, height = 200,\n",
    "        title = 'Vertical velocity variance from Doppler Lidar at Gothic'\n",
    "    )\n",
    "lower_chart = alt.Chart(\n",
    "        src\n",
    "    ).mark_rect().encode(\n",
    "        alt.X('time_low:T').title('time'),\n",
    "        alt.X2('time_high:T'),\n",
    "        alt.Y('height_low:Q').title('Height (m)'),\n",
    "        alt.Y2('height_high:Q'),\n",
    "        alt.Color('value:Q').title([\"w'w'\", \"(m² s⁻²)\"]).scale(domain=[0,8], scheme='turbo'),\n",
    "        tooltip='value'\n",
    "    ).properties(\n",
    "        width=500, height = 100,\n",
    "    )\n",
    "alt.vconcat(\n",
    "    upper_chart,\n",
    "    lower_chart,\n",
    "    spacing = -2\n",
    ").resolve_scale(x='shared', color='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(src.loc['20230505']).mark_circle().encode(\n",
    "    alt.X('value:Q'),\n",
    "    alt.Y('height:Q')\n",
    ").properties(width=250,height=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sublimationofsnow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
