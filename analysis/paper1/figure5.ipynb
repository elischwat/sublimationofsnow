{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open SOS Measurement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is not allowed.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m tidy_df_30Min[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(tidy_df_30Min[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# limit data to our dates of interest, based on continuous snow cover at Kettle Ponds\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m tidy_df_5Min \u001b[38;5;241m=\u001b[39m \u001b[43mtidy_df_5Min\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     11\u001b[0m tidy_df_30Min \u001b[38;5;241m=\u001b[39m tidy_df_30Min\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mloc[start_date:end_date]\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/mambaforge/envs/sublimationofsnow/lib/python3.12/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/sublimationofsnow/lib/python3.12/site-packages/pandas/core/indexing.py:1373\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/mambaforge/envs/sublimationofsnow/lib/python3.12/site-packages/pandas/core/indexing.py:1405\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1404\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 1405\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/mambaforge/envs/sublimationofsnow/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:698\u001b[0m, in \u001b[0;36mDatetimeIndex.slice_indexer\u001b[0;34m(self, start, end, step)\u001b[0m\n\u001b[1;32m    695\u001b[0m     in_index \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m (end_casted \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_index:\n\u001b[0;32m--> 698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue based partial slicing on non-monotonic DatetimeIndexes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-existing keys is not allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    701\u001b[0m     )\n\u001b[1;32m    702\u001b[0m indexer \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m][::step]\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Value based partial slicing on non-monotonic DatetimeIndexes with non-existing keys is not allowed.'"
     ]
    }
   ],
   "source": [
    "start_date = '20221130'\n",
    "end_date = '20230509'\n",
    "# open files\n",
    "tidy_df_5Min = pd.read_parquet('../sos/tidy_df_20221130_20230517_noplanar_fit.parquet')\n",
    "tidy_df_30Min = pd.read_parquet('../sos/tidy_df_30Min_20221130_20230517_noplanar_fit.parquet')\n",
    "# convert time column to datetime\n",
    "tidy_df_5Min['time'] = pd.to_datetime(tidy_df_5Min['time'])\n",
    "tidy_df_30Min['time'] = pd.to_datetime(tidy_df_30Min['time'])\n",
    "# limit data to our dates of interest, based on continuous snow cover at Kettle Ponds\n",
    "tidy_df_5Min = tidy_df_5Min.set_index('time').loc[start_date:end_date].reset_index()\n",
    "tidy_df_30Min = tidy_df_30Min.set_index('time').loc[start_date:end_date].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick way to get variable info if we want it \n",
    "# import xarray as xr\n",
    "# ds = xr.open_dataset(\"/data2/elilouis/sublimationofsnow/sosnoqc/isfs_20221228.nc\")\n",
    "# ds['SWE_p2_c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: remove all LH flux data points with less than 90% of 20hz data being good\n",
    "### Step 2: remove all LH flux data points with magnitude greater than 1 g/m^2/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_lhflux_and_counts_variables = [\n",
    "    ('w_h2o__2m_c', 'counts_2m_c_1'), \n",
    "    ('w_h2o__3m_c', 'counts_3m_c_1'), \n",
    "    ('w_h2o__5m_c', 'counts_5m_c_1'), \n",
    "    ('w_h2o__10m_c', 'counts_10m_c_1'), \n",
    "    ('w_h2o__15m_c', 'counts_15m_c_1'), \n",
    "    ('w_h2o__20m_c', 'counts_20m_c_1'), \n",
    "\n",
    "\n",
    "    ('w_h2o__1m_d', 'counts_1m_d_1'), \n",
    "    ('w_h2o__3m_d', 'counts_3m_d_1'), \n",
    "    ('w_h2o__10m_d', 'counts_10m_d_1'), \n",
    "      \n",
    "    ('w_h2o__1m_ue', 'counts_1m_ue_1'), \n",
    "    ('w_h2o__3m_ue', 'counts_3m_ue_1'), \n",
    "    ('w_h2o__10m_ue', 'counts_10m_ue_1'), \n",
    "\n",
    "\n",
    "    ('w_h2o__1m_uw',  'counts_1m_uw_1'), \n",
    "    ('w_h2o__3m_uw', 'counts_3m_uw_1'), \n",
    "    ('w_h2o__10m_uw', 'counts_10m_uw_1'), \n",
    "]\n",
    "ec_lhflux_variables = list(zip(*ec_lhflux_and_counts_variables))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "all_lhflux_measurements.mean(), all_lhflux_measurements.std(), all_lhflux_measurements.min(), all_lhflux_measurements.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# Remove all data points at once - perform both steps 1 and 2 simultaneously\n",
    "####################################################################################\n",
    "# for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "#     print(flux_var, counts_var)\n",
    "#     counts_src = tidy_df_5Min[tidy_df_5Min.variable == counts_var]\n",
    "#     times_with_good_data_50percent = counts_src[counts_src.value >= 5400].time\n",
    "#     n_before_dropping = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "#     tidy_df_5Min.loc[\n",
    "#         (~tidy_df_5Min['time'].isin(times_with_good_data_50percent)) &\n",
    "#         (tidy_df_5Min['variable'] == flux_var),\n",
    "#         'value'\n",
    "#     ] = np.nan\n",
    "#     n_after_step_1 = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "\n",
    "#     variable_src = tidy_df_5Min[tidy_df_5Min.variable == flux_var]\n",
    "#     times_with_outofbounds_values = variable_src[np.abs(variable_src.value) > 1].time\n",
    "#     tidy_df_5Min.loc[\n",
    "#         (tidy_df_5Min['time'].isin(times_with_outofbounds_values)) & \n",
    "#         (tidy_df_5Min['variable'] == flux_var),\n",
    "#         'value'\n",
    "#     ] = np.nan\n",
    "#     n_after_step_2 = len(tidy_df_5Min.loc[(tidy_df_5Min['variable'] == flux_var)].dropna())\n",
    "#     print(n_before_dropping, n_after_step_1, n_after_step_2)\n",
    "#     print(round((n_before_dropping-n_after_step_2)/n_before_dropping, 3))\n",
    "\n",
    "####################################################################################\n",
    "# Perform steps 1 and 2 separately \n",
    "####################################################################################\n",
    "for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "    counts_src = tidy_df_5Min[tidy_df_5Min.variable == counts_var]\n",
    "    times_with_good_data_50percent = counts_src[counts_src.value >= 5400].time\n",
    "    tidy_df_5Min.loc[\n",
    "        (~tidy_df_5Min['time'].isin(times_with_good_data_50percent)) &\n",
    "        (tidy_df_5Min['variable'] == flux_var),\n",
    "        'value'\n",
    "    ] = np.nan\n",
    "\n",
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "mean = all_lhflux_measurements.mean() \n",
    "stddev = all_lhflux_measurements.std()\n",
    "print(mean, stddev, all_lhflux_measurements.min(), all_lhflux_measurements.max())\n",
    "\n",
    "for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "    variable_src = tidy_df_5Min[tidy_df_5Min.variable == flux_var]\n",
    "    times_with_outofbounds_values = variable_src[\n",
    "        ((variable_src.value) > (mean + 5*stddev)) |\n",
    "        ((variable_src.value) < (mean - 5*stddev))\n",
    "    ].time\n",
    "    tidy_df_5Min.loc[\n",
    "        (tidy_df_5Min['time'].isin(times_with_outofbounds_values)) & \n",
    "        (tidy_df_5Min['variable'] == flux_var),\n",
    "        'value'\n",
    "    ] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lhflux_measurements = tidy_df_5Min[tidy_df_5Min.variable.isin(ec_lhflux_variables)].value\n",
    "print(all_lhflux_measurements.mean(), all_lhflux_measurements.std(), all_lhflux_measurements.min(), all_lhflux_measurements.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Model Ensemble Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_parquet(\"model_results.parquet\")\n",
    "# add a bunch of columns that are descriptive, from the config column which has multiple bits of info\n",
    "model_df['z0'] = model_df['config'].apply(\n",
    "    lambda v: float(v.split(' ')[-1])\n",
    ")\n",
    "model_df['e_sat_curve'] = model_df['config'].apply(\n",
    "    lambda v: 'metpy' if 'metpy' in v else 'alduchov'\n",
    ")\n",
    "model_df['surface_measurement'] = model_df['config'].apply(\n",
    "    lambda v: v.split(' ')[-3]\n",
    ")\n",
    "model_df['scheme'] = model_df['config'].apply(\n",
    "    lambda v: 'andreas' if 'andreas lengths' in v else 'yang'\n",
    ")\n",
    "model_df['most_config'] = model_df['config'].apply(lambda s: ' '.join(s.split(' ')[:-3]))\n",
    "# remove the scalar roughness length parameterization info \n",
    "model_df['most_config'] = model_df['most_config'].str.replace(' andreas lengths', '')\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle a pesky outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.loc[(model_df.time == \"2023-01-22 1400\") & (model_df.surface_measurement == 'Tsurf_d'), 'latent heat flux'] = 0\n",
    "model_df.loc[(model_df.time == \"2023-01-22 1400\") & (model_df.surface_measurement == 'Tsurf_d'), 'sensible heat flux'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best performing model configuration\n",
    "best_model_df = model_df[\n",
    "    model_df['config'].isin([\n",
    "        'MO Holtslag de Bruin andreas lengths Tsurf_c e_sat_alduchov 1e-05',\n",
    "        'MO Holtslag de Bruin andreas lengths Tsurf_c e_sat_alduchov 0.0001'\n",
    "    ]) \n",
    "]\n",
    "best_model_df['z0'] = best_model_df['z0'].astype('str')\n",
    "best_model_df = best_model_df[['time', 'z0', 'latent heat flux']].pivot_table(\n",
    "    index='time', columns='z0',\n",
    ")\n",
    "best_model_df.columns = best_model_df.columns.to_flat_index().str.join('_')\n",
    "best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meas_df = tidy_df_30Min.query(\"variable == 'w_h2o__3m_c'\").set_index('time')[['value']].join(\n",
    "    best_model_df\n",
    ").reset_index().rename(columns={\n",
    "    'value': 'measured',\n",
    "    'latent heat flux_0.0001': 'modeled z0=1e-4',\n",
    "    'latent heat flux_1e-05': 'modeled z0=1e-5',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(\n",
    "    model_meas_df.dropna()['measured'],\n",
    "    model_meas_df.dropna()['modeled z0=1e-5'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comparison_plot(src):\n",
    "    one_to_one_line = alt.Chart(pd.DataFrame({\n",
    "        'x': [-0.05, -0.025, 0.0, 0.025, 0.05],\n",
    "        'y': [-0.05, -0.025, 0.0, 0.025, 0.05]\n",
    "    })).mark_line(\n",
    "        color='grey'\n",
    "    ).encode(x = 'x', y = 'y')\n",
    "\n",
    "    value_r2_score_1eneg4 = round(\n",
    "        r2_score(\n",
    "            src.dropna()['measured'],\n",
    "            src.dropna()['modeled z0=1e-4'],\n",
    "        ),\n",
    "        3\n",
    "    )\n",
    "    value_r2_score_1eneg5 = round(\n",
    "        r2_score(\n",
    "            src.dropna()['measured'],\n",
    "            src.dropna()['modeled z0=1e-5'],\n",
    "        ),\n",
    "        3\n",
    "    )\n",
    "    scale = alt.Scale(domain = [-0.05, 0.05], clamp=True)\n",
    "    axis = alt.Axis(values=[-0.05, -0.025, 0.0, 0.025, 0.05])\n",
    "    return (\n",
    "        # (\n",
    "        #     one_to_one_line+alt.Chart(src).mark_circle(size=10, opacity=0.1).encode(\n",
    "        #         alt.X(\"measured:Q\").scale(scale).axis(axis),\n",
    "        #         alt.Y(\"modeled z0=1e-4:Q\").scale(scale).axis(axis),\n",
    "        #     ).properties(width=200, height = 200, title=f\"r² = {value_r2_score_1eneg4} (n = {len(src)})\") | \\\n",
    "        #     one_to_one_line+alt.Chart(src).mark_rect().encode(\n",
    "        #         alt.X(\"measured:Q\").bin(maxbins=30).scale(scale).axis(axis),\n",
    "        #         alt.Y(\"modeled z0=1e-4:Q\").bin(maxbins=30).scale(scale).axis(axis),\n",
    "        #         alt.Color(\"count():Q\")\n",
    "        #     ).properties(width=200, height = 200, title=f\"r² = {value_r2_score_1eneg4} (n = {len(src)})\")\n",
    "        # ) &\\\n",
    "        (\n",
    "            one_to_one_line+alt.Chart(src).mark_circle(size=10, opacity=0.1).encode(\n",
    "                alt.X(\"measured:Q\").scale(scale).axis(axis),\n",
    "                alt.Y(\"modeled z0=1e-5:Q\").scale(scale).axis(axis),\n",
    "            ).properties(width=200, height = 200, title=f\"r² = {value_r2_score_1eneg5} (n = {len(src)})\") | \\\n",
    "            one_to_one_line+alt.Chart(src).mark_rect().encode(\n",
    "                alt.X(\"measured:Q\").bin(maxbins=30).scale(scale).axis(axis),\n",
    "                alt.Y(\"modeled z0=1e-5:Q\").bin(maxbins=30).scale(scale).axis(axis),\n",
    "                alt.Color(\"count():Q\")\n",
    "            ).properties(width=200, height = 200, title=f\"r² = {value_r2_score_1eneg5} (n = {len(src)})\")   \n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_times = tidy_df_30Min.query(\"variable == 'temp_gradient_3m_c'\").query(\n",
    "    \"value < -0.01\"\n",
    ").time\n",
    "stable_times = tidy_df_30Min.query(\"variable == 'temp_gradient_3m_c'\").query(\n",
    "    \"value > 0.01\"\n",
    ").time\n",
    "neutral_times = tidy_df_30Min.query(\"variable == 'temp_gradient_3m_c'\").query(\n",
    "    \"value <= 0.01 & value >= -0.01\"\n",
    ").time\n",
    "\n",
    "blowing_snow_times = pd.concat([\n",
    "    tidy_df_30Min.query(\"variable == 'SF_avg_2m_ue'\").query(\"value > 0\").time,\n",
    "    tidy_df_30Min.query(\"variable == 'SF_avg_1m_ue'\").query(\"value > 0\").time\n",
    "])\n",
    "clear_times = tidy_df_30Min.query(\"variable == 'SF_avg_2m_ue'\").time[\n",
    "    ~ tidy_df_30Min.query(\"variable == 'SF_avg_2m_ue'\").time.isin(blowing_snow_times)\n",
    "]\n",
    "\n",
    "winter_times = tidy_df_30Min.query(\"variable == 'SF_avg_2m_ue'\").set_index(\"time\").loc[:\"2023-02-28\"].index.values\n",
    "spring_times = tidy_df_30Min.query(\"variable == 'SF_avg_2m_ue'\").set_index(\"time\").loc[\"2023-03-01\":].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison_plot(model_meas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model_comparison_plot(model_meas_df[model_meas_df.time.isin(unstable_times.values)]).properties(title='Unstable data') |\\\n",
    "model_comparison_plot(model_meas_df[model_meas_df.time.isin(stable_times.values)]).properties(title='Stable data') |\\\n",
    "model_comparison_plot(model_meas_df[model_meas_df.time.isin(neutral_times.values)]).properties(title='Neutral data')).resolve_scale(color='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "model_comparison_plot(model_meas_df[model_meas_df.time.isin(blowing_snow_times.values)]).properties(title='Blowing snow data') |\\\n",
    "model_comparison_plot(model_meas_df[model_meas_df.time.isin(clear_times.values)]).properties(title='Clear data')).resolve_scale(color='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "model_comparison_plot(model_meas_df[model_meas_df.time.isin(winter_times.values)]).properties(title='Winter data') |\\\n",
    "model_comparison_plot(model_meas_df[model_meas_df.time.isin(spring_times.values)]).properties(title='Spring data')).resolve_scale(color='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
