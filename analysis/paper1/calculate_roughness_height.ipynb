{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "alt.renderers.enable('jupyterlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '20221130'\n",
    "end_date = '20230509'\n",
    "\n",
    "tidy_dataset_fn = f\"tidy_df_{start_date}_{end_date}_noplanar_fit.parquet\"\n",
    "tidy_daily_dataset_output_fn = f\"tidy_df_daily_{start_date}_{end_date}_noplanar_fit.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tidy_df_5Min = pd.read_parquet(\n",
    "        tidy_dataset_fn\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(\"No file such file exists for these dates.\")\n",
    "tidy_df_5Min['time'] = pd.to_datetime(tidy_df_5Min['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = tidy_df_5Min.query(\"variable == 'T_3m_c'\").set_index('time')['value']\n",
    "# na_groups = data.notna().cumsum()[data.isna()]\n",
    "# t_lengths_consecutive_na = na_groups.groupby(na_groups).agg(len)\n",
    "\n",
    "# data = tidy_df_5Min.query(\"variable == 'RH_3m_c'\").set_index('time')['value']\n",
    "# na_groups = data.notna().cumsum()[data.isna()]\n",
    "# rh_lengths_consecutive_na = na_groups.groupby(na_groups).agg(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine pot. virtual temperature gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(tidy_df_5Min[tidy_df_5Min.measurement == 'temperature gradient'].value).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    tidy_df_5Min.query(\"measurement == 'temperature gradient'\").query(\"height < 5\")\n",
    ").mark_line().encode(\n",
    "    x = 'time:T',\n",
    "    y = 'value:Q',\n",
    "    column='height:O'\n",
    ").properties(width=200, height = 200) & alt.Chart(\n",
    "    tidy_df_5Min.query(\"measurement == 'temperature gradient'\").query(\"height < 5\")\n",
    ").mark_bar().encode(\n",
    "    alt.X('value:Q').bin(step=0.1),\n",
    "    alt.Y(\"count():Q\"),    \n",
    "    alt.Column('height:O')\n",
    ").properties(width=200, height = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df_5Min.query(\"variable == 'temp_gradient_3m_c'\")\n",
    "neutral_times = src[src['value'].abs() < 0.01].time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    tidy_df_5Min[\n",
    "        tidy_df_5Min.time.isin(neutral_times.sample(16))\n",
    "    ].query(\"measurement == 'wind speed'\").query(\"tower == 'c'\")\n",
    ").mark_line().encode(\n",
    "    alt.X(\"value:Q\").title(\"Wind speed (m/s)\").sort('-y'),\n",
    "    alt.Y(\"height:Q\").title(\"Height (m)\"),\n",
    "    alt.Facet(\"time:O\", columns=8)\n",
    ").properties(width = 125, height = 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_df = tidy_df_5Min[\n",
    "    tidy_df_5Min.time.isin(neutral_times)\n",
    "].query(\"tower == 'c'\")\n",
    "src_snowdepth = tidy_df_5Min[\n",
    "    tidy_df_5Min.measurement == 'snow depth'\n",
    "]\n",
    "src_snowdepth = src_snowdepth[['time', 'value']].set_index('time').rename(columns={'value': 'snow_depth'})\n",
    "z0_df = z0_df[z0_df.measurement.isin([\n",
    "    'wind speed',\n",
    "    'shear velocity',\n",
    "    'snow depth'\n",
    "])]\n",
    "z0_df = z0_df[~z0_df.variable.str.contains(\"predicted\")]\n",
    "z0_df = z0_df.pivot_table(index=['time'], values='value', columns='variable')\n",
    "z0_df = z0_df.join(src_snowdepth)\n",
    "z0_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out data without monotonically increasing wind speeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z0_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monotonically_increasing(l):\n",
    "    return all(x < y for x, y in zip(l, l[1:]))\n",
    "\n",
    "z0_df['is_monotonic_increasing'] = z0_df.apply(\n",
    "    lambda row: monotonically_increasing([\n",
    "            row['spd_2m_c'], \n",
    "            row['spd_3m_c'], \n",
    "            row['spd_5m_c'], \n",
    "            row['spd_10m_c'], \n",
    "            row['spd_15m_c'], \n",
    "            row['spd_20m_c']\n",
    "    ]),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_df = z0_df[z0_df.is_monotonic_increasing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(z0_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for $z_0$ assuming $d = 0$\n",
    "\n",
    "https://www.eol.ucar.edu/content/calculation-roughness-length-and-displacement-height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "von_karman = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.0\n",
    "z0_df['z0_2m_c'] = (2 - d - z0_df['snow_depth'])/np.exp(z0_df['spd_2m_c']*von_karman/z0_df['u*_2m_c'])\n",
    "z0_df['z0_3m_c'] = (3 - d - z0_df['snow_depth'])/np.exp(z0_df['spd_3m_c']*von_karman/z0_df['u*_3m_c'])\n",
    "z0_df['z0_5m_c'] = (5 - d - z0_df['snow_depth'])/np.exp(z0_df['spd_5m_c']*von_karman/z0_df['u*_5m_c'])\n",
    "z0_df['z0_10m_c'] = (10 - d - z0_df['snow_depth'])/np.exp(z0_df['spd_10m_c']*von_karman/z0_df['u*_10m_c'])\n",
    "z0_df['z0_15m_c'] = (15 - d - z0_df['snow_depth'])/np.exp(z0_df['spd_15m_c']*von_karman/z0_df['u*_15m_c'])\n",
    "z0_df['z0_20m_c'] = (20 - d - z0_df['snow_depth'])/np.exp(z0_df['spd_20m_c']*von_karman/z0_df['u*_20m_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "        'z0_2m_c', \n",
    "        'z0_3m_c', \n",
    "        'z0_5m_c', \n",
    "        'z0_10m_c', \n",
    "        'z0_15m_c', \n",
    "        'z0_20m_c', \n",
    "    ]\n",
    "alt.Chart(\n",
    "    z0_df[variables].reset_index()\n",
    ").transform_fold(\n",
    "    variables\n",
    ").transform_filter(\n",
    "    alt.FieldOneOfPredicate('key', ['z0_2m_c', 'z0_3m_c'])\n",
    ").mark_circle().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y(\"value:Q\").scale(type='log'),\n",
    "    alt.Row(\"key:N\", sort=variables)\n",
    ").properties(height = 100, width = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(z0_df).mark_circle().encode(\n",
    "    alt.X(\"z0_3m_c\").scale(domain=[0.000000001, 10], type='log'),\n",
    "    alt.Y(\"z0_2m_c\").scale(domain=[0.000000001, 10], type='log')\n",
    ").properties(width = 150, height = 150, title = str(round(r2_score(\n",
    "        z0_df[\"z0_3m_c\"],\n",
    "        z0_df[\"z0_2m_c\"]\n",
    "    ), 3))\n",
    ") | alt.Chart(z0_df).mark_circle().encode(\n",
    "    alt.X(\"z0_3m_c\").scale(domain=[0.000000001, 10], type='log'),\n",
    "    alt.Y(\"z0_5m_c\").scale(domain=[0.000000001, 10], type='log')\n",
    ").properties(width = 150, height = 150, title = str(round(r2_score(\n",
    "        z0_df[\"z0_3m_c\"],\n",
    "        z0_df[\"z0_5m_c\"]\n",
    "    ), 3))\n",
    ") | alt.Chart(z0_df).mark_circle().encode(\n",
    "    alt.X(\"z0_3m_c\").scale(domain=[0.000000001, 10], type='log'),\n",
    "    alt.Y(\"z0_10m_c\").scale(domain=[0.000000001, 10], type='log')\n",
    ").properties(width = 150, height = 150, title = str(round(r2_score(\n",
    "        z0_df[\"z0_3m_c\"],\n",
    "        z0_df[\"z0_10m_c\"]\n",
    "    ), 3))\n",
    ") | alt.Chart(z0_df).mark_circle().encode(\n",
    "    alt.X(\"z0_3m_c\").scale(domain=[0.000000001, 10], type='log'),\n",
    "    alt.Y(\"z0_15m_c\").scale(domain=[0.000000001, 10], type='log')\n",
    ").properties(width = 150, height = 150, title = str(round(r2_score(\n",
    "        z0_df[\"z0_3m_c\"],\n",
    "        z0_df[\"z0_15m_c\"]\n",
    "    ), 3))\n",
    ") | alt.Chart(z0_df).mark_circle().encode(\n",
    "    alt.X(\"z0_3m_c\").scale(domain=[0.000000001, 10], type='log'),\n",
    "    alt.Y(\"z0_20m_c\").scale(domain=[0.000000001, 10], type='log')\n",
    ").properties(width = 150, height = 150, title = str(round(r2_score(\n",
    "        z0_df[\"z0_3m_c\"],\n",
    "        z0_df[\"z0_20m_c\"]\n",
    "    ), 3))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    z0_df[['z0_3m_c']].resample(\"1D\").median().reset_index()\n",
    ").mark_circle(size=50).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"z0_3m_c\").scale(type='log')\n",
    ") + alt.Chart(\n",
    "    z0_df[['z0_3m_c']].resample(\"1D\").median().reset_index()\n",
    ").mark_bar(width=1).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"z0_3m_c\").scale(type='log')\n",
    ").properties(height = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_df_weekly = z0_df[['z0_3m_c']].resample(\"W-MON\").median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_df[['z0_3m_c']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_z0_values_chart = alt.Chart(\n",
    "    z0_df_weekly\n",
    ").mark_circle(size=100).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"z0_3m_c\").scale(type='log')\n",
    ") + alt.Chart(\n",
    "    z0_df_weekly\n",
    ").mark_bar(width=1).encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"z0_3m_c\").scale(type='log')\n",
    ").properties(height = 100)\n",
    "basic_z0_values_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Andreas et al. 2010 Method, NOAA/SPLASH (Chris Cox) solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdk = 273.15 \n",
    "# surface temp mean\n",
    "Tsm = tidy_df_5Min.query(\"variable == 'Tsurf_c'\")['value'].values \n",
    "# air temp mean\n",
    "Tam = tidy_df_5Min.query(\"variable == 'T_3m_c'\")['value'].values \n",
    "# height of sonic\n",
    "z_level_n = 3 - tidy_df_5Min.query(\"variable == 'SnowDepth_d'\")['value'].values \n",
    "# wt-covariance, vertical flux of the sonic temperature  [deg m/s]\n",
    "wT_csp = tidy_df_5Min.query(\"variable == 'w_tc__3m_c'\")['value'].values   \n",
    "wq_csp = tidy_df_5Min.query(\"variable == 'w_h2o__3m_c'\")['value'].values   \n",
    "wsp = tidy_df_5Min.query(\"variable == 'spd_3m_c'\")['value'].values \n",
    "ustar = tidy_df_5Min.query(\"variable == 'u*_3m_c'\")['value'].values \n",
    "\n",
    "surface_pot_temp = tidy_df_5Min.query(\"variable == 'Tsurfpot_c'\")['value'].values\n",
    "air_pot_temp  = tidy_df_5Min.query(\"variable == 'Tpot_3m_c'\")['value'].values\n",
    "surface_mixing_ratio = tidy_df_5Min.query(\"variable == 'Tsurfmixingratio_c'\")['value'].values\n",
    "air_mixing_ratio = tidy_df_5Min.query(\"variable == 'mixingratio_3m_c'\")['value'].values\n",
    "surface_specifichumidity = surface_mixing_ratio / (1 + surface_mixing_ratio)\n",
    "air_specifichumidity  = air_mixing_ratio / (1 + air_mixing_ratio)\n",
    "\n",
    "# Obukhov length\n",
    "surflayr_avg_airtemp = 0.5*(Tsm + Tam)\n",
    "surflayr_avg_specifichumidity = 0.5*(surface_specifichumidity + air_specifichumidity)\n",
    "surflayr_avg_virtualtemp = 0.5*(\n",
    "    tidy_df_5Min.query(\"variable == 'Tvirtual_3m_c'\")['value'].values + \n",
    "    tidy_df_5Min.query(\"variable == 'Tsurfvirtual_c'\")['value'].values\n",
    ")\n",
    "# right version of equation 2.3 in Andreas 2010\n",
    "# L = - (\n",
    "#     surflayr_avg_airtemp/( 0.4*9.81 )\n",
    "# ) * (\n",
    "#     ustar**3 / (\n",
    "#         wT_csp + wq_csp* (0.61*surflayr_avg_airtemp)/(\n",
    "#             1 + 0.61*surflayr_avg_specifichumidity\n",
    "#           )\n",
    "#     )\n",
    "# )\n",
    "# left version of equation 2.3 in Andreas 2010\n",
    "L = - (\n",
    "    (\n",
    "        tidy_df_5Min.query(\"variable == 'Tvirtual_3m_c'\")['value'].values\n",
    "    )/( 0.4*9.81 )\n",
    ") * (\n",
    "    ustar**3 / wT_csp\n",
    ")\n",
    "\n",
    "# Monin-Obukhov stability parameter, z/L:\n",
    "zeta_level_n = z_level_n/L\n",
    "\n",
    "# Drag coefficient, Cd:\n",
    "Cd = ustar**2/wsp**2 #- wu_csp/(wsp**2)\n",
    "\n",
    "Ch = wT_csp / (wsp * (surface_pot_temp - air_pot_temp))\n",
    "\n",
    "Ce = wq_csp / (wsp * (surface_specifichumidity - air_specifichumidity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../splash/\")\n",
    "import calc_z0\n",
    "z0_values = calc_z0.calc_z0(z_level_n, Cd, zeta_level_n)\n",
    "z0T_values = calc_z0.calc_z0T(z_level_n, Cd, Ch, zeta_level_n)\n",
    "z0q_values = calc_z0.calc_z0Q(z_level_n, Cd, Ce, zeta_level_n)\n",
    "\n",
    "time_values = tidy_df_5Min.time.unique()\n",
    "\n",
    "z0_andreas_df = pd.DataFrame({\n",
    "    \"time\": time_values, \n",
    "    \"z0\":   z0_values,\n",
    "    \"z0T\": z0T_values,\n",
    "    \"z0q\": z0q_values,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove values >= 0.1, <= 7e-8 (Andreas et al., 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z0_andreas_df.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_andreas_df['z0'] = z0_andreas_df['z0'].where(\n",
    "    (z0_andreas_df['z0'] > 7e-8)\n",
    "    &\n",
    "    (z0_andreas_df['z0'] < 0.1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z0_andreas_df.dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the strict filtering criteria of Andreas et al. (2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_values = tidy_df_5Min.query(\"variable == 'Tsurf_c'\").set_index('time').sort_index().index.values\n",
    "stress = tidy_df_5Min.query(\"variable == 'u_w_rot__3m_c'\")\n",
    "stress_good_times = stress[stress.value > 0].time\n",
    "\n",
    "shflux = tidy_df_5Min.query(\"variable == 'w_tc__3m_c'\")\n",
    "shflux_good_times = shflux[np.abs(shflux.value) > 0.005].time\n",
    "\n",
    "lhflux = tidy_df_5Min.query(\"variable == 'w_h2o__3m_c'\")\n",
    "lhflux_good_times = lhflux[np.abs(lhflux.value)/1000 > 2.5e-7].time\n",
    "\n",
    "tdiff = (tidy_df_5Min[tidy_df_5Min.variable == 'Tsurfpot_c'].set_index('time')[['value']] - \n",
    "tidy_df_5Min[tidy_df_5Min.variable == 'Tpot_3m_c'].set_index('time')[['value']])\n",
    "tdiff_good_times = tdiff[tdiff.value > 0.5].index\n",
    "\n",
    "all_good_times = set(stress_good_times).intersection(\n",
    "    set(shflux_good_times)\n",
    ").intersection(\n",
    "    set(lhflux_good_times)\n",
    ").intersection(\n",
    "    set(tdiff_good_times)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tidy_df_5Min.time.unique()))\n",
    "print(len(stress_good_times))\n",
    "print(len(shflux_good_times))\n",
    "print(len(lhflux_good_times))\n",
    "print(len(tdiff_good_times))\n",
    "print(len(all_good_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_andreas_df_strict = z0_andreas_df[z0_andreas_df.time.isin(all_good_times)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z0_andreas_df.dropna()), len(z0_andreas_df_strict.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.Chart(\n",
    "    np.log10(z0_andreas_df.set_index('time')).reset_index()\n",
    ").mark_bar().encode(\n",
    "    alt.X(\"z0:Q\").bin(maxbins=30),\n",
    "    alt.Y(\"count():Q\")\n",
    ")\n",
    "|\n",
    "alt.Chart(\n",
    "    np.log10(z0_andreas_df_strict.set_index('time')).reset_index()\n",
    ").mark_bar().encode(\n",
    "    alt.X(\"z0:Q\").bin(maxbins=30),\n",
    "    alt.Y(\"count():Q\")\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate weekly medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_andreas_df_weekly = z0_andreas_df.set_index('time').resample('W-MON').median().reset_index()\n",
    "z0_andreas_df_strict_weekly = z0_andreas_df_strict.set_index('time').resample('W-MON').median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_andreas_df_weekly = pd.merge(\n",
    "    z0_andreas_df_weekly[['time', 'z0']].rename(columns={'z0': 'all data'}),\n",
    "    z0_andreas_df_strict_weekly[['time', 'z0']].rename(columns={'z0': 'filtered'}),\n",
    "    on='time',\n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_andreas_df_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z0_andreas_df.median())\n",
    "print()\n",
    "print(z0_andreas_df_strict.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_z0 = alt.Chart(\n",
    "    z0_andreas_df\n",
    ").mark_circle(opacity=0.1, size=5).encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y(\"z0:Q\").scale(type='log').axis(format=\"e\"),\n",
    ")\n",
    "weekly_median_z0 = alt.Chart(\n",
    "    z0_andreas_df_weekly.iloc[:-1]\n",
    ").transform_fold(\n",
    "    ['all data', 'filtered']\n",
    ").mark_point(size=40, color='black').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y(\"value:Q\").title(\"zâ‚€\"),\n",
    "    alt.Shape(\"key:N\").scale(range=['circle', 'cross']).title([\"Weekly\", \"average\"])\n",
    ")\n",
    "\n",
    "upper_line = alt.Chart(pd.DataFrame({'y':[5e-3]})).mark_rule(color='grey', size=2, strokeDash=[2,2]).encode(y='y')\n",
    "lower_line = alt.Chart(pd.DataFrame({'y':[2e-4]})).mark_rule(color='grey', size=2, strokeDash=[2,2]).encode(y='y')\n",
    "\n",
    "z0_calculations_chart = (all_z0 + weekly_median_z0).properties(width = 250, height = 100).configure_axis(grid=False)\n",
    "z0_calculations_chart = z0_calculations_chart + upper_line + lower_line\n",
    "z0_calculations_chart.save(\"z0_calculations_chart.png\", ppi=400)\n",
    "z0_calculations_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save roughness length values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0_andreas_df.to_parquet(\"z0estimates/z0_andreas_df.parquet\")\n",
    "z0_andreas_df_strict.to_parquet(\"z0estimates/z0_andreas_df_strict.parquet\")\n",
    "z0_andreas_df_weekly.to_parquet(\"z0estimates/z0_andreas_df_weekly.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
