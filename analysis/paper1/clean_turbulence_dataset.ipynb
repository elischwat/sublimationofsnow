{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Really should be called `clean latent heat flux data`**\n",
    "\n",
    "This notebook:\n",
    "- Examines how blowing snow fluxes and \"bad\" EC data (data with quality control flags raised) are related\n",
    "- Removes LH flux data points from the 5 minute dataset that have flags raised for >10% of the instantaneous (20hz) measurements included in each 5-minute Reynolds average\n",
    "  - Analyzes how different thresholds effect sublimation estimates\n",
    "- Removes LH flux data points outside a threshold 5*$\\sigma$ where $\\sigma$ is standard deviation\n",
    "- Interpolate data gaps upto 1-hour long\n",
    "  - Analyzes how changing the \"max gap size interpolated\" effects sublimation estimates\n",
    "- Adds \"Cumulative sublimation measured\"  measurements to the 5 minute dataset, and saves it to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "from sublimpy import turbulence\n",
    "import matplotlib.pyplot as plt\n",
    "from sublimpy import tidy\n",
    "import metpy.constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open SOS Measurement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '20221130'\n",
    "end_date = '20230509'\n",
    "# open files\n",
    "tidy_df = pd.read_parquet(f'tidy_df_{start_date}_{end_date}_noplanar_fit.parquet')\n",
    "# convert time column to datetime\n",
    "tidy_df['time'] = pd.to_datetime(tidy_df['time'])\n",
    "# limit data to our dates of interest, based on continuous snow cover at Kettle Ponds\n",
    "tidy_df = tidy_df.set_index('time').sort_index().loc[start_date:end_date].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set file path to save the modified tidy_df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fn = f'tidy_df_{start_date}_{end_date}_noplanar_fit_clean.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the relevant turbulent flux measurement variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_lhflux_and_counts_variables = [\n",
    "    # ('w_h2o__2m_c', 'counts_2m_c_1'), \n",
    "    ('w_h2o__3m_c', 'counts_3m_c_1'), \n",
    "    ('w_h2o__5m_c', 'counts_5m_c_1'), \n",
    "    ('w_h2o__10m_c', 'counts_10m_c_1'), \n",
    "    ('w_h2o__15m_c', 'counts_15m_c_1'), \n",
    "    ('w_h2o__20m_c', 'counts_20m_c_1'), \n",
    "\n",
    "\n",
    "    # ('w_h2o__1m_d', 'counts_1m_d_1'), \n",
    "    ('w_h2o__3m_d', 'counts_3m_d_1'), \n",
    "    ('w_h2o__10m_d', 'counts_10m_d_1'), \n",
    "      \n",
    "    # ('w_h2o__1m_ue', 'counts_1m_ue_1'), \n",
    "    ('w_h2o__3m_ue', 'counts_3m_ue_1'), \n",
    "    ('w_h2o__10m_ue', 'counts_10m_ue_1'), \n",
    "\n",
    "\n",
    "    # ('w_h2o__1m_uw',  'counts_1m_uw_1'), \n",
    "    ('w_h2o__3m_uw', 'counts_3m_uw_1'), \n",
    "    ('w_h2o__10m_uw', 'counts_10m_uw_1'), \n",
    "]\n",
    "ec_lhflux_variables = list(zip(*ec_lhflux_and_counts_variables))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the quality of the EC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare data collection quality with blowing snow fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_variables = list(list(zip(*ec_lhflux_and_counts_variables))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[tidy_df.variable.isin(['SF_avg_1m_ue', 'SF_avg_2m_ue'])]\n",
    "src = src[src.value > 0]\n",
    "bs_times = set(src.time.unique())\n",
    "nobs_times = list(set(tidy_df.time.unique()) - bs_times)\n",
    "bs_times = list(bs_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[tidy_df.variable == 'counts_3m_c_1']\n",
    "src = pd.concat([\n",
    "    src[src.time.isin(bs_times)].assign(bs = 'blowing snow'),\n",
    "    src[src.time.isin(nobs_times)].assign(bs = 'no blowing snow')\n",
    "])\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.query(\"variable == 'counts_3m_c_1'\").query(\"value < 5400\")['bs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(src.query(\"variable == 'counts_3m_c_1'\")).mark_boxplot(outliers=True).encode(\n",
    "    alt.X(\"bs:O\"),\n",
    "    alt.Y(\"value:Q\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blowing_snow_vs_counts_src =     tidy_df[tidy_df.variable.isin(['SF_avg_2m_ue', 'SF_avg_1m_ue', 'counts_3m_c_1', 'counts_20m_c_1'])].pivot(\n",
    "        index='time',\n",
    "        columns='variable',\n",
    "        values='value'\n",
    "    ).reset_index()\n",
    "blowing_snow_vs_counts_src['Dec 22'] = blowing_snow_vs_counts_src.time.dt.date == dt.date(2022, 12, 22)\n",
    "\n",
    "rule = alt.Chart().transform_calculate(rule='5400').mark_rule(strokeDash=[4,2]).encode(y='rule:Q')\n",
    "\n",
    "counts_and_blowingsnow_3m_c_plot = (\n",
    "    alt.Chart(\n",
    "        blowing_snow_vs_counts_src.query(\"SF_avg_1m_ue>0\")\n",
    "    ).mark_circle(size=10).encode(\n",
    "        alt.X(\"SF_avg_1m_ue\").scale(type='log').title([\n",
    "            \"Blowing snow flux (g/m^2/s)\",\n",
    "            \"0-1m FlowCapt sensor\"\n",
    "        ]),\n",
    "        alt.Y(\"counts_3m_c_1\").title([\"Count unflagged 20hz w'q'\", \"measurements, 3m Tower C\"]),\n",
    "        alt.Color(\"Dec 22:N\").title(\"On Dec. 22\"),\n",
    "        tooltip='time'\n",
    "    ).properties(width=200, height=200)+rule | alt.Chart(\n",
    "        blowing_snow_vs_counts_src.query(\"SF_avg_2m_ue>0\")\n",
    "    ).mark_circle(size=10).encode(\n",
    "        alt.X(\"SF_avg_2m_ue\").scale(type='log').title([\n",
    "            \"Blowing snow flux (g/m^2/s)\",\n",
    "            \"1-2m FlowCapt sensor\"\n",
    "        ]),\n",
    "        alt.Y(\"counts_3m_c_1\").title([\"Count unflagged 20hz w'q'\", \"measurements, 3m Tower C\"]),\n",
    "        alt.Color(\"Dec 22:N\").title(\"On Dec. 22\"),\n",
    "        tooltip='time'\n",
    "    ).properties(width=200, height=200)+rule\n",
    ")\n",
    "counts_and_blowingsnow_3m_c_plot.save(\"counts_and_blowingsnow_3m_c_plot.png\", ppi=200)\n",
    "counts_and_blowingsnow_3m_c_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, axes = plt.subplots(2,1, sharey=True)\n",
    "sns.histplot(\n",
    "    blowing_snow_vs_counts_src.query(\"SF_avg_1m_ue == 0\")['counts_3m_c_1'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "sns.histplot(\n",
    "    blowing_snow_vs_counts_src.query(\"SF_avg_1m_ue > 0\")['counts_3m_c_1'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    blowing_snow_vs_counts_src.query(\"SF_avg_1m_ue == 0\")\n",
    ").mark_bar(size=10).encode(\n",
    "    alt.X(\"counts_3m_c_1:Q\").title([\"Count unflagged 20hz w'q'\", \"measurements, 3m Tower C\"]).bin(maxbins=1000),\n",
    "    alt.Y(\"count():Q\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alt.Chart(\n",
    "    blowing_snow_vs_counts_src.query(\"SF_avg_1m_ue == 0\")\n",
    ").mark_circle(size=10).encode(\n",
    "    alt.X(\"counts_3m_c_1:Q\").title([\"Count unflagged 20hz w'q'\", \"measurements, 3m Tower C\"]).bin(),\n",
    "    alt.Y(\"count():Q\"),\n",
    "    alt.Color(\"Dec 22:N\").title(\"On Dec. 22\"),\n",
    "    tooltip='time'\n",
    ").properties(width=200, height=200)+rule | alt.Chart(\n",
    "    blowing_snow_vs_counts_src.query(\"SF_avg_2m_ue == 0\")\n",
    ").mark_circle(size=10).encode(\n",
    "    alt.X(\"counts_3m_c_1:Q\").title([\"Count unflagged 20hz w'q'\", \"measurements, 3m Tower C\"]).bin(),\n",
    "    alt.Y(\"count():Q\"),\n",
    "    alt.Color(\"Dec 22:N\").title(\"On Dec. 22\"),\n",
    "    tooltip='time'\n",
    ").properties(width=200, height=200)+rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    alt.Chart(\n",
    "        blowing_snow_vs_counts_src.query(\"SF_avg_1m_ue>0\")\n",
    "    ).mark_circle(size=10).encode(\n",
    "        alt.X(\"SF_avg_1m_ue\").scale(type='log').title([\n",
    "            \"Blowing snow flux (g/m^2/s)\",\n",
    "            \"0-1m FlowCapt sensor\"\n",
    "        ]),\n",
    "        alt.Y(\"counts_20m_c_1\").title([\"Count unflagged 20hz w'q'\", \"measurements, 20m Tower C\"]),\n",
    "        alt.Color(\"Dec 22:N\").title(\"On Dec. 22\"),\n",
    "        tooltip='time'\n",
    "    ).properties(width=200, height=200)+rule | alt.Chart(\n",
    "        blowing_snow_vs_counts_src.query(\"SF_avg_2m_ue>0\")\n",
    "    ).mark_circle(size=10).encode(\n",
    "        alt.X(\"SF_avg_2m_ue\").scale(type='log').title([\n",
    "            \"Blowing snow flux (g/m^2/s)\",\n",
    "            \"1-2m FlowCapt sensor\"\n",
    "        ]),\n",
    "        alt.Y(\"counts_20m_c_1\").title([\"Count unflagged 20hz w'q'\", \"measurements, 20m Tower C\"]),\n",
    "        alt.Color(\"Dec 22:N\").title(\"On Dec. 22\"),\n",
    "        tooltip='time'\n",
    "    ).properties(width=200, height=200)+rule\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data points with more than 10% of the data flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the upper and lower thresholds for removing outliers, five times the standarad deviation - 5*$\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lhflux_measurements = tidy_df[tidy_df.variable.isin(ec_lhflux_variables)].value\n",
    "# lower_threshold = all_lhflux_measurements.mean() - 5*all_lhflux_measurements.std()\n",
    "# upper_threshold = all_lhflux_measurements.mean() + 5*all_lhflux_measurements.std()\n",
    "# don't actually do any outlier filtering like this anymore\n",
    "lower_threshold = all_lhflux_measurements.min() - 1\n",
    "upper_threshold = all_lhflux_measurements.max() + 1\n",
    "lower_threshold, upper_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "good_data_fractions = [\n",
    "    0, \n",
    "    0.05, 0.1, \n",
    "    0.25, 0.50, 0.75, \n",
    "    0.90, 0.95, \n",
    "    1\n",
    "]\n",
    "dataframes = []\n",
    "for good_data_fraction in good_data_fractions:\n",
    "    for flux_var, counts_var in ec_lhflux_and_counts_variables:\n",
    "        flux_values = tidy_df.query(f\"variable == '{flux_var}'\").value.values\n",
    "        nan_count_b4_processing = pd.isnull(flux_values).sum()\n",
    "        new_values = turbulence.clean_eddy_covariance(\n",
    "            flux_values,\n",
    "            tidy_df.query(f\"variable == '{counts_var}'\").value.values,\n",
    "            lower_threshold,\n",
    "            upper_threshold,\n",
    "            fraction_good_data_reqd = good_data_fraction,\n",
    "            counts_per_datapoint = 36000\n",
    "        )\n",
    "        nan_count_after_processing = pd.isnull(new_values).sum()\n",
    "        print(good_data_fraction, flux_var, nan_count_b4_processing, nan_count_after_processing)\n",
    "        dataframes.append(\n",
    "            pd.DataFrame.from_dict({\n",
    "                flux_var: new_values,\n",
    "                'good_data_fraction': np.full(len(new_values), good_data_fraction)\n",
    "            })\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_per_timestep = 60*30\n",
    "\n",
    "variable_ls = []\n",
    "height_ls = []\n",
    "percent_reqd_ls = []\n",
    "cumulative_sublimation_ls = []\n",
    "\n",
    "for dataframe in dataframes:\n",
    "    flux_var_name = dataframe.columns[0]\n",
    "    height = int(flux_var_name.split('_')[-2].split('m')[0])\n",
    "    tower = flux_var_name.split('_')[-1]\n",
    "    good_data_fraction = dataframe['good_data_fraction'].iloc[0]\n",
    "    new_var_name = f\"cumulative_sub_measured_{height}m_{tower}\"\n",
    "    cumulative_sublimation_values = np.nancumsum(\n",
    "        dataframe[flux_var_name]*seconds_per_timestep\n",
    "    )/metpy.constants.density_water.magnitude\n",
    "    ec_lhflux_variables = list(zip(*ec_lhflux_and_counts_variables))[0]\n",
    "    variable_ls.append(new_var_name)\n",
    "    height_ls.append(height)\n",
    "    percent_reqd_ls.append(good_data_fraction)\n",
    "    cumulative_sublimation_ls.append(cumulative_sublimation_values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentreqd_qc_df = pd.DataFrame({\n",
    "    'variable': variable_ls,\n",
    "    'height': height_ls,\n",
    "    'percent_reqd': percent_reqd_ls,\n",
    "    'cumulative_sublimation': cumulative_sublimation_ls,\n",
    "})\n",
    "percent_reqd_seasonal_sub_sensitivity_chart = alt.Chart(percentreqd_qc_df).mark_line(point=True).transform_filter(alt.datum.height > 1).encode(\n",
    "    alt.X(\"percent_reqd:Q\").title(\"% 'good' data req'd per 5min average\"),\n",
    "    alt.Y(\"cumulative_sublimation:Q\").title(\"Seasonal sublimation (mm)\"),\n",
    "    alt.Color(\"height:O\").scale(scheme='viridis'),\n",
    "    detail = 'variable:N',\n",
    "    tooltip = 'variable:N'\n",
    ")\n",
    "percent_reqd_seasonal_sub_sensitivity_chart.save(\"percent_reqd_seasonal_sub_sensitivity_chart.png\", ppi=200)\n",
    "percent_reqd_seasonal_sub_sensitivity_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select our data-required value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [df for df in dataframes if df['good_data_fraction'].iloc[0] == 0.90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine how calculated cumulative sublimation values var for different interpolation-window-limits, substitute clean data for old/dirty date (using 12-timestep gap limit), and add cumulative sublimation values to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_per_timestep = 60*30\n",
    "\n",
    "flux_var_name_ls = []\n",
    "height_ls = []\n",
    "interp_window_limit_ls = []\n",
    "cumsum_with_interp_ls = []\n",
    "\n",
    "for dataframe in dataframes:\n",
    "    flux_var_name = dataframe.columns[0]\n",
    "    height = int(flux_var_name.split('_')[-2].split('m')[0])\n",
    "    tower = flux_var_name.split('_')[-1]\n",
    "    new_var_name = f\"cumulative_sub_measured_{height}m_{tower}\"\n",
    "    # Print calculated cumulative sublimation values for different interpolation-window-limits\n",
    "    for interp_window_limit in [None, 1, 2, 5, 10, 12, 20, 30, 80, 100, 200, 300, 800, 1000]:\n",
    "            flux_var_name_ls.append(flux_var_name)\n",
    "            height_ls.append(height)\n",
    "            interp_window_limit_ls.append(interp_window_limit)\n",
    "            cumsum_with_interp_ls.append((np.nancumsum(\n",
    "                (dataframe[flux_var_name]*seconds_per_timestep).interpolate(method='linear', limit=interp_window_limit)\n",
    "            )/metpy.constants.density_water.magnitude).max()\n",
    "        )\n",
    "    \n",
    "    # remove the old flux values\n",
    "    tidy_df = tidy_df[tidy_df.variable != flux_var_name]\n",
    "    \n",
    "    # # add the new (cleaned) flux values\n",
    "    tidy_df = tidy.tidy_df_add_variable(\n",
    "        tidy_df,\n",
    "        dataframe[flux_var_name].interpolate(method='linear', limit=2),\n",
    "        flux_var_name,\n",
    "        'w_h2o_',\n",
    "        height,\n",
    "        tower\n",
    "    )\n",
    "    # add the cumulative calculations values\n",
    "    tidy_df = tidy.tidy_df_add_variable(\n",
    "        tidy_df,\n",
    "        (\n",
    "              np.nancumsum(\n",
    "                (dataframe[flux_var_name]*seconds_per_timestep).interpolate(method='linear', limit=2)\n",
    "            )/metpy.constants.density_water.magnitude\n",
    "        ),\n",
    "        new_var_name,\n",
    "        \"Cumulative sublimation measured\",  \n",
    "        height,\n",
    "        tower\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataframe[flux_var_name]*seconds_per_timestep).interpolate(method='linear', limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapsize_qc_df= pd.DataFrame({\n",
    "    'variable': flux_var_name_ls,\n",
    "    'height': height_ls,\n",
    "    'max_interp_limit': interp_window_limit_ls,\n",
    "    'cumulative_sub': cumsum_with_interp_ls,\n",
    "})\n",
    "\n",
    "alt.Chart(gapsize_qc_df).mark_line(point=True).transform_filter(alt.datum.height > 1).encode(\n",
    "    alt.X(\"max_interp_limit:Q\").title(\"max gap size for interpolation\").scale(type='log'),\n",
    "    alt.Y(\"cumulative_sub:Q\").title(\"Seasonal sublimation (mm)\"),\n",
    "    alt.Color(\"height:O\").scale(scheme='viridis'),\n",
    "    detail = 'variable:N',\n",
    "    tooltip='variable:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_steps_df = pd.merge(\n",
    "    percentreqd_qc_df.query(\"percent_reqd == 0\")[['variable','cumulative_sublimation']].rename(\n",
    "        columns = {'cumulative_sublimation': 'cumulative_sublimation_raw'}\n",
    "    ),\n",
    "    gapsize_qc_df.assign(variable = gapsize_qc_df.variable.str.replace(\n",
    "        'w_h2o__', 'cumulative_sub_measured_'\n",
    "    )).query(\"max_interp_limit == 2\").rename(\n",
    "        columns = {'cumulative_sub': 'cumulative_sublimation_gapfilled'}\n",
    "    ),\n",
    "    on='variable'\n",
    ").merge(\n",
    "    percentreqd_qc_df.query(\"percent_reqd == 0.9\")[['variable','cumulative_sublimation']].rename(\n",
    "        columns = {'cumulative_sublimation': 'cumulative_sublimation_filtered'}\n",
    "    ),\n",
    "    on='variable'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_steps_df['tower'] = data_clean_steps_df.variable.apply(lambda s:s.split('_')[-1])\n",
    "data_clean_steps_df = data_clean_steps_df[\n",
    "    ['variable', 'tower', 'height', 'cumulative_sublimation_raw', 'cumulative_sublimation_filtered', 'cumulative_sublimation_gapfilled']\n",
    "].round(2)\n",
    "data_clean_steps_df = data_clean_steps_df.rename(columns={\n",
    "    'cumulative_sublimation_raw': 'raw',\n",
    "    'cumulative_sublimation_filtered': 'filtered',\n",
    "    'cumulative_sublimation_gapfilled': 'gapfilled',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_steps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    'raw',\t'filtered',\t'gapfilled'\n",
    "    ]\n",
    "data_cleaning_steps_affects_chart = alt.Chart(data_clean_steps_df).mark_line().transform_fold(\n",
    "    vars\n",
    ").encode(\n",
    "    alt.Y(\"key:O\", sort=vars).title(None),\n",
    "    alt.X(\"value:Q\").title(\"Cumulatuve sublimation (mm)\"),\n",
    "    alt.Color('height:N'),\n",
    "    detail = 'variable'\n",
    ")\n",
    "data_cleaning_steps_affects_chart.save(\"data_cleaning_steps_affects_chart.png\", ppi=200)\n",
    "data_cleaning_steps_affects_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df.to_parquet(output_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lah | grep parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data points we left out, based on the thresholds (for filtering data) that we determined earlier\n",
    "# These are the datapoints we don't trust and are excluding - we should get an idea of what's happening during these limited times\n",
    "* Measurements during times where SF_avg_XX_ue measurements are > 10^0, and have “good data” counts less than 0.9*6000 \n",
    "* If too much data, only remove isolated incidents (I.e. less than 2 of those data points in a row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    tidy_df[\n",
    "        tidy_df.variable == 'cumulative_sub_measured_10m_d'\n",
    "    ].set_index('time').loc[\n",
    "        \"2023-04-24\":\"2023-04-26\"\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = tidy_df[\n",
    "    tidy_df.variable.isin(['SF_avg_2m_ue', 'SF_avg_1m_ue'])\n",
    "].query(\"value > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = bad_data.sort_values('time')\n",
    "bad_data['month'] = bad_data.time.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    bad_data\n",
    ").mark_tick().encode(\n",
    "    alt.X(\"time:T\").title(None),\n",
    "    alt.Row(\"month:O\").sort([12,1,2,3,4])\n",
    ").resolve_scale(x='independent', y='shared').properties(width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a few case studies based on the plot of bad data occurences above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_study_ls = [\n",
    "    (\"20221213\", \"20221215\"),\n",
    "    (\"20221221\", \"20221223\"),\n",
    "    (\"2023-01-10 12:00:00\" , \"2023-01-10 14:00:00\"),\n",
    "    (\"20230205\", \"20230207\"),\n",
    "    (\"20230308\", \"20230310\"),\n",
    "    (\"20230330\", \"20230401\"),\n",
    "    (\"20230403\", \"20230404\"),\n",
    "    (\"20230424 2300\", \"20230425 0200\"),\n",
    "    \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = pd.read_parquet(f'tidy_df_{start_date}_{end_date}_noplanar_fit.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = tidy_df[\n",
    "        tidy_df.variable.isin(list(sum(ec_lhflux_and_counts_variables, ())) + [\n",
    "            'spd_3m_c', 'spd_5m_c', 'spd_10m_c', 'spd_15m_c', 'spd_20m_c',\n",
    "            'spd_3m_d', 'spd_10m_d',\n",
    "            'spd_3m_ue', 'spd_10m_ue',\n",
    "            'spd_3m_uw', 'spd_10m_uw',\n",
    "        ])\n",
    "    ].set_index('time').sort_index()\n",
    "src['tower and height'] = src.apply(lambda row : row['tower'] + ' ' + str(row['height']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropped_case_study_src = src[\n",
    "        case_study_ls[1][0]: case_study_ls[1][1]\n",
    "    ].reset_index().query(\"tower == 'c'\").query(\"height == 3\")\n",
    "\n",
    "base_chart = alt.Chart().mark_line().properties(\n",
    "    height = 100,\n",
    "    width = 200\n",
    ")\n",
    "data_dropped_case_study_plot = (\n",
    "    alt.layer(\n",
    "        base_chart, data=data_dropped_case_study_src.query(\n",
    "            \"measurement == 'eddy covariance h2o high rate count'\"\n",
    "        )\n",
    "    ).encode(\n",
    "        alt.X(\"time:T\"),\n",
    "        alt.Y(\"value:Q\").title([\"Count unflagged 20hz w'q'\", \"measurements, 3m Tower C\"]),\n",
    "    ) & \n",
    "    alt.layer(\n",
    "        base_chart, data=data_dropped_case_study_src.query(\n",
    "            \"measurement == 'w_h2o_'\"\n",
    "        )\n",
    "    ).encode(\n",
    "        alt.X(\"time:T\"),\n",
    "        alt.Y(\"value:Q\").title([\"w'q'\", \"3m Tower C\"]),\n",
    "    ) & \n",
    "    alt.layer(\n",
    "        base_chart, data=data_dropped_case_study_src.query(\n",
    "            \"measurement == 'wind speed'\"\n",
    "        )\n",
    "    ).encode(\n",
    "        alt.X(\"time:T\"),\n",
    "        alt.Y(\"value:Q\").title([\"Wind speed\", \"3m Tower C\"]),\n",
    "    )\n",
    ").resolve_scale(x='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data_dropped_case_study_src = src[\n",
    "        case_study_ls[0][0]: case_study_ls[0][1]\n",
    "    ].reset_index().query(\"tower == 'ue'\").query(\"height == 10\")\n",
    "\n",
    "base_chart = alt.Chart().mark_line().properties(\n",
    "    height = 100,\n",
    "    width = 200\n",
    ")\n",
    "no_data_dropped_case_study_plot = (\n",
    "    alt.layer(\n",
    "        base_chart, data=no_data_dropped_case_study_src.query(\n",
    "            \"measurement == 'eddy covariance h2o high rate count'\"\n",
    "        )\n",
    "    ).encode(\n",
    "        alt.X(\"time:T\"),\n",
    "        alt.Y(\"value:Q\").title([\"Count unflagged 20hz w'q'\", \"measurements, 10m Tower UE\"]),\n",
    "    ) & \n",
    "    alt.layer(\n",
    "        base_chart, data=no_data_dropped_case_study_src.query(\n",
    "            \"measurement == 'w_h2o_'\"\n",
    "        )\n",
    "    ).encode(\n",
    "        alt.X(\"time:T\"),\n",
    "        alt.Y(\"value:Q\").title([\"w'q'\", \"10m Tower UE\"]),\n",
    "    ) & \n",
    "    alt.layer(\n",
    "        base_chart, data=no_data_dropped_case_study_src.query(\n",
    "            \"measurement == 'wind speed'\"\n",
    "        )\n",
    "    ).encode(\n",
    "        alt.X(\"time:T\"),\n",
    "        alt.Y(\"value:Q\").title([\"Wind speed\", \"10m Tower UE\"]),\n",
    "    )\n",
    ").resolve_scale(x='shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dropped_casestudies_chart = (no_data_dropped_case_study_plot | data_dropped_case_study_plot)\n",
    "data_dropped_casestudies_chart.save(\"data_dropped_casestudies_chart.png\", ppi=200)\n",
    "data_dropped_casestudies_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[0][0]: case_study_ls[0][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[1][0]: case_study_ls[1][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[2][0]: case_study_ls[2][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[3][0]: case_study_ls[3][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[4][0]: case_study_ls[4][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[5][0]: case_study_ls[5][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[6][0]: case_study_ls[6][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    src[\n",
    "        case_study_ls[7][0]: case_study_ls[7][1]\n",
    "    ].reset_index()\n",
    ").mark_line().encode(\n",
    "    alt.X(\"time:T\"),\n",
    "    alt.Y(\"value:Q\").scale(zero=False),\n",
    "    # alt.Color(\"tower:N\"),\n",
    "    alt.Row(\"tower and height:O\"),\n",
    "    alt.Column(\"measurement:N\")\n",
    ").resolve_scale(y='independent').properties(\n",
    "    height = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sublimationofsnow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
