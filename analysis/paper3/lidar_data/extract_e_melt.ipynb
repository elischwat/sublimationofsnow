{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from metpy.units import units\n",
    "import pandas as pd\n",
    "import rioxarray as rix\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import pint_xarray\n",
    "from sublimpy import variables, utils, tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the SOS tidy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_tidy_fn = f\"../../paper1/process_slow_data/tidy_df_20221101_20230619_planar_fit_multiplane_q7_flags9000_pf10.parquet\"\n",
    "sos_df = pd.read_parquet(sos_tidy_fn)\n",
    "sos_df['time'] = pd.to_datetime(sos_df['time'])\n",
    "sos_df = utils.modify_df_timezone(sos_df, 'UTC', 'US/Mountain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_l2 = \"/Users/elischwat/Development/data/sublimationofsnow/lidar_rasters/l2_test_20230505_20230530_hourly.nc\"\n",
    "fn_l6 = \"/Users/elischwat/Development/data/sublimationofsnow/lidar_rasters/l6_test_20230505_20230530_hourly.nc\"\n",
    "towers_location_fn = \"../landsat_data/towers.geojson\"\n",
    "profile_lines_fn = \"/Users/elischwat/Downloads/snow_patch_profiles.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2_lazy = xr.open_dataset(fn_l2, chunks={'time': 100, 'x': 100, 'y':100}).sel(time=slice('20230510', '20230525'))\n",
    "ds_l6_lazy = xr.open_dataset(fn_l6, chunks={'time': 100, 'x': 100, 'y':100}).sel(time=slice('20230510', '20230525'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Georeference the lidar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towers_gdf = gpd.read_file(towers_location_fn)\n",
    "towers_gdf = towers_gdf.to_crs(\"EPSG:32613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_l2_lazy = ds_l2_lazy.assign_coords(\n",
    "    x = ds_l2_lazy.x + towers_gdf.set_index('Tower').loc['c']['geometry'].x,\n",
    "    y = ds_l2_lazy.y + towers_gdf.set_index('Tower').loc['c']['geometry'].y\n",
    ").rio.write_crs(towers_gdf.crs)\n",
    "ds_l6_lazy = ds_l6_lazy.assign_coords(\n",
    "    x = ds_l6_lazy.x + towers_gdf.set_index('Tower').loc['c']['geometry'].x,\n",
    "    y = ds_l6_lazy.y + towers_gdf.set_index('Tower').loc['c']['geometry'].y\n",
    ").rio.write_crs(towers_gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open profile lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_lines_gdf = gpd.read_file(profile_lines_fn)\n",
    "def increase_line_resolution(line, resolution=0.2):    \n",
    "    line_length = line.length\n",
    "\n",
    "    # Generate points along the LineString at intervals of 0.1 units\n",
    "    num_points = int(line_length / resolution) + 1\n",
    "    generated_points = [line.interpolate(i*resolution) for i in range(num_points)]\n",
    "    return LineString(generated_points)\n",
    "\n",
    "profile_lines_gdf.geometry = profile_lines_gdf.geometry.apply(increase_line_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_lines_gdf.plot(color='red')\n",
    "ds_l2_lazy.isel(time=0).surface.plot()\n",
    "ds_l6_lazy.isel(time=0).surface.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know we want these profiles: [0, 1, 2, 4, 5, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_lines_gdf = profile_lines_gdf.iloc[[0, 1, 2, 4, 5, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_lines_gdf.plot(color='red')\n",
    "ds_l2_lazy.isel(time=0).surface.plot()\n",
    "ds_l6_lazy.isel(time=0).surface.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df_list = []\n",
    "for i, row in profile_lines_gdf.iterrows():\n",
    "    geom = row['geometry']\n",
    "    if row['patch'] == 'd':\n",
    "        ds_to_sample = ds_l2_lazy\n",
    "    elif row['patch'] == 'uw':\n",
    "        ds_to_sample = ds_l6_lazy\n",
    "    \n",
    "    # Create a list to store the results\n",
    "    nearest_values = []\n",
    "\n",
    "    # Iterate over each coordinate\n",
    "    first_coord = geom.coords[0]\n",
    "    for x, y in geom.coords:\n",
    "        distance_from_first_coord = np.sqrt((x - first_coord[0])**2 + (y - first_coord[1])**2) \n",
    "        # Extract the nearest value from ds_l2_lazy\n",
    "        nearest_value = ds_to_sample.surface.sel(x=x, y=y, method='nearest').compute()\n",
    "        nearest_values.append({'x': x, 'y': y, 'nearest_value': nearest_value, 'distance': distance_from_first_coord})\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    nearest_values_df = pd.DataFrame(nearest_values)\n",
    "\n",
    "    df = pd.concat(nearest_values_df.apply(\n",
    "        lambda row: row['nearest_value'].to_dataframe().assign(x = row['x'], y = row['y'], distance=row['distance']),\n",
    "        axis = 1\n",
    "    ).to_list())\n",
    "    df = df.assign(patch = str(row['patch']) + '_' + str(row['id']))\n",
    "    profile_df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart(src):\n",
    "    src_snow = src[src.index.day.isin([10, 11, 12, 13,14,15,16,17])]\n",
    "    src_ground = src[src.index.day == 25]\n",
    "    chart_ground = alt.Chart(src_ground.dropna().reset_index()).mark_line(\n",
    "        color='#341C02'\n",
    "    ).encode(\n",
    "        alt.X('distance:Q'),\n",
    "        alt.Y('mean(surface):Q').scale(zero=False),\n",
    "    ).properties(height=150)\n",
    "    chart_snow = alt.Chart(src_snow.dropna().reset_index()).mark_line().encode(\n",
    "        alt.X('distance:Q'),\n",
    "        alt.Y('mean(surface):Q').scale(zero=False),\n",
    "        alt.Color('date(time):O'),\n",
    "        tooltip = 'date(time)',\n",
    "        # tooltip = 'distance',\n",
    "    ).properties(height=150)\n",
    "    return chart_snow + chart_ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (chart(profile_df_list[0]) | chart(profile_df_list[1]) | chart(profile_df_list[2])) &\\\n",
    "# (chart(profile_df_list[3]) | chart(profile_df_list[4]) | chart(profile_df_list[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine ablation rates (normalized) as a function of distance from the leading edge this is seriously imperfect b/c we don't really know where the leading edge is, and we don't appropriately deal with the fact that the ground is becoming exposed throughout or time period, plus there is error in the lidar measurements due to all of that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it manually, reseting the starting position each day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for profile #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = profile_df_list[1]\n",
    "src = src[src.index.hour == 0]\n",
    "src = src[src.index.day.isin([10,11,12,13,14,15,16,17,25])]\n",
    "alt.Chart(src.reset_index()).mark_line().encode(\n",
    "    alt.X('distance:Q'),\n",
    "    alt.Y('mean(surface):Q').scale(zero=False),\n",
    "    alt.Color('date(time):O').scale(scheme='turbo'),\n",
    "    tooltip='date(time):O'\n",
    ").properties(width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each day, we determined where the new \"windward toe\" was, and subtract that distance value\n",
    "# so that each day has \"distance\" relative to the actual location of the snow patch edge\n",
    "df_10 = profile_df_list[1].loc['20230510'].query(\"distance <= 35\")\n",
    "df_10 = df_10.assign(distance = df_10.distance - 5).query(\"distance > 0\")\n",
    "\n",
    "df_11 = profile_df_list[1].loc['20230511'].query(\"distance <= 35\")\n",
    "df_11 = df_11.assign(distance = df_11.distance - 5).query(\"distance > 0\")\n",
    "\n",
    "df_12 = profile_df_list[1].loc['20230512'].query(\"distance <= 35\")\n",
    "df_12 = df_12.assign(distance = df_12.distance - 6).query(\"distance > 0\")\n",
    "\n",
    "df_13 = profile_df_list[1].loc['20230513'].query(\"distance <= 35\")\n",
    "df_13 = df_13.assign(distance = df_13.distance - 7).query(\"distance > 0\")\n",
    "\n",
    "df_14 = profile_df_list[1].loc['20230514'].query(\"distance <= 35\")\n",
    "df_14 = df_14.assign(distance = df_14.distance - 8).query(\"distance > 0\")\n",
    "\n",
    "df_15 = profile_df_list[1].loc['20230515'].query(\"distance <= 35\")\n",
    "df_15 = df_15.assign(distance = df_15.distance - 11).query(\"distance > 0\")\n",
    "\n",
    "df_16 = profile_df_list[1].loc['20230516'].query(\"distance <= 35\")\n",
    "df_16 = df_16.assign(distance = df_16.distance - 13).query(\"distance > 0\")\n",
    "\n",
    "df_17 = profile_df_list[1].loc['20230517'].query(\"distance <= 35\")\n",
    "df_17 = df_17.assign(distance = df_17.distance - 15).query(\"distance > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adjusted_profiles = pd.concat([df_10, df_11, df_12, df_13, df_14, df_15, df_16, df_17])\n",
    "ds = combined_adjusted_profiles.reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray()\n",
    "ds = ds.differentiate('time', datetime_unit='h') \n",
    "df_patch1 = ds.to_dataframe().reset_index()[['distance', 'surface', 'time']]\n",
    "df_patch1['bin'] = pd.cut(df_patch1.distance, 12).apply(lambda interval: float((interval.left + interval.right)/2)).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for profile #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = profile_df_list[0]\n",
    "src = src[src.index.hour == 0]\n",
    "src = src[src.index.day.isin([10,11,12,13,14,15,16,17,25])]\n",
    "display(alt.Chart(src.reset_index()).mark_line().encode(\n",
    "    alt.X('distance:Q'),\n",
    "    alt.Y('mean(surface):Q').scale(zero=False),\n",
    "    alt.Color('date(time):O').scale(scheme='turbo'),\n",
    "    tooltip='date(time):O'\n",
    ").properties(width=1000))\n",
    "# for each day, we determined where the new \"windward toe\" was, and subtract that distance value\n",
    "# so that each day has \"distance\" relative to the actual location of the snow patch edge\n",
    "df_10 = profile_df_list[0].loc['20230510'].query(\"distance <= 35\")\n",
    "df_10 = df_10.assign(distance = df_10.distance - 6).query(\"distance > 0\")\n",
    "\n",
    "df_11 = profile_df_list[0].loc['20230511'].query(\"distance <= 35\")\n",
    "df_11 = df_11.assign(distance = df_11.distance - 6).query(\"distance > 0\")\n",
    "\n",
    "df_12 = profile_df_list[0].loc['20230512'].query(\"distance <= 35\")\n",
    "df_12 = df_12.assign(distance = df_12.distance - 6).query(\"distance > 0\")\n",
    "\n",
    "df_13 = profile_df_list[0].loc['20230513'].query(\"distance <= 35\")\n",
    "df_13 = df_13.assign(distance = df_13.distance - 7).query(\"distance > 0\")\n",
    "\n",
    "df_14 = profile_df_list[0].loc['20230514'].query(\"distance <= 35\")\n",
    "df_14 = df_14.assign(distance = df_14.distance - 7).query(\"distance > 0\")\n",
    "\n",
    "df_15 = profile_df_list[0].loc['20230515'].query(\"distance <= 35\")\n",
    "df_15 = df_15.assign(distance = df_15.distance - 10).query(\"distance > 0\")\n",
    "\n",
    "df_16 = profile_df_list[0].loc['20230516'].query(\"distance <= 35\")\n",
    "df_16 = df_16.assign(distance = df_16.distance - 11).query(\"distance > 0\")\n",
    "\n",
    "df_17 = profile_df_list[0].loc['20230517'].query(\"distance <= 35\")\n",
    "df_17 = df_17.assign(distance = df_17.distance - 12).query(\"distance > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adjusted_profiles = pd.concat([df_10, df_11, df_12, df_13, df_14, df_15, df_16, df_17])\n",
    "ds = combined_adjusted_profiles.reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray()\n",
    "ds = ds.differentiate('time', datetime_unit='h') \n",
    "df_patch0 = ds.to_dataframe().reset_index()[['distance', 'surface', 'time']]\n",
    "df_patch0['bin'] = pd.cut(df_patch0.distance, 12).apply(lambda interval: float((interval.left + interval.right)/2)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chart(src):\n",
    "    return (\n",
    "        alt.Chart(src).mark_errorbar(extent='ci').encode(\n",
    "            alt.X('bin:Q'), \n",
    "            alt.Y('surface:Q').scale(zero=False),\n",
    "            alt.Color('patch:N')\n",
    "        ).properties(height=150)\n",
    "        + \n",
    "        alt.Chart(src).mark_circle(color='black').encode(\n",
    "            alt.X('bin:Q'), \n",
    "            alt.Y('mean(surface):Q').scale(zero=False),\n",
    "            alt.Color('patch:N')\n",
    "        ).properties(height=150)\n",
    "        +\n",
    "        alt.Chart(src).mark_line(color='black').encode(\n",
    "            alt.X('bin:Q'), \n",
    "            alt.Y('mean(surface):Q').scale(zero=False),\n",
    "            alt.Color('patch:N')\n",
    "        ).properties(height=150)\n",
    "        +\n",
    "        alt.Chart(pd.DataFrame({'y': [1]})).mark_rule(color='black').encode(\n",
    "            alt.Y('y:Q')\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patch0_normed = df_patch0.assign(surface = df_patch0.surface / df_patch0.surface.mean())\n",
    "df_patch1_normed = df_patch1.assign(surface = df_patch1.surface / df_patch1.surface.mean())\n",
    "src = pd.concat([df_patch0_normed.assign(patch=0),df_patch1_normed.assign(patch=1)])\n",
    "get_chart(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [[10,11,12,13], [15,16,17]]:\n",
    "    df_patch0_normed = df_patch0[df_patch0.time.dt.day.isin(d)]\n",
    "    df_patch1_normed = df_patch1[df_patch1.time.dt.day.isin(d)]\n",
    "    df_patch0_normed = df_patch0_normed.assign(surface = df_patch0_normed.surface / df_patch0_normed.surface.mean())\n",
    "    df_patch1_normed = df_patch1_normed.assign(surface = df_patch1_normed.surface / df_patch1_normed.surface.mean())\n",
    "\n",
    "    src = pd.concat([df_patch0_normed.assign(patch=0),df_patch1_normed.assign(patch=1)])\n",
    "    display(get_chart(src).properties(title=str(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(10,18):\n",
    "    df_patch0_normed = df_patch0[df_patch0.time.dt.day == d]\n",
    "    df_patch1_normed = df_patch1[df_patch1.time.dt.day == d]\n",
    "    df_patch0_normed = df_patch0_normed.assign(surface = df_patch0_normed.surface / df_patch0_normed.surface.mean())\n",
    "    df_patch1_normed = df_patch1_normed.assign(surface = df_patch1_normed.surface / df_patch1_normed.surface.mean())\n",
    "\n",
    "    src = pd.concat([df_patch0_normed.assign(patch=0),df_patch1_normed.assign(patch=1)])\n",
    "    display(get_chart(src).properties(title=str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_ablation_rate(ds, first_ablation_distance, last_ablation_distance, last_date):\n",
    "    ds = ds[ds.distance < last_ablation_distance]\n",
    "    ds = ds.assign(distance = ds.distance - first_ablation_distance)\n",
    "    ds = ds[ds.distance > 0]\n",
    "    # only look through the 17th\n",
    "    ds = ds.sort_index().loc[:last_date]\n",
    "    ds = ds.reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray()\n",
    "    \n",
    "    # remove data points that are equal to or below the profile on the last timestamp:\n",
    "    ds = ds.where(ds > ds.sel(time=ds.time.max()))\n",
    "    # OR, apply cumulative minimum:\n",
    "    # ds.copy(\n",
    "    #     values = np.cumulative.minimum(\n",
    "    #         ds.values,\n",
    "    #         axis\n",
    "    # )\n",
    "\n",
    "    # ds = ds.sel(time = slice(None, None, 24)).diff('time')\n",
    "    ds = ds.differentiate('time', datetime_unit='h') \n",
    "    df = ds.to_dataframe().reset_index().query(\"surface < 0\")[['distance', 'surface', 'time']]\n",
    "    df['bin'] = pd.cut(df.distance, 12).apply(lambda interval: float((interval.left + interval.right)/2)).astype(float)\n",
    "    df.surface = df.surface / df.surface.mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only include times during downvalley-ish winds\n",
    "wind_dir_src = sos_df[sos_df.variable.isin([\n",
    "    'dir_3m_c',\n",
    "    'dir_5m_c',\n",
    "    'dir_20m_c',\n",
    "])]\n",
    "wind_dir_src = wind_dir_src[wind_dir_src.time > '20230509']\n",
    "wind_dir_src = wind_dir_src[wind_dir_src.time < '20230524']\n",
    "down_valley_wind_times = wind_dir_src[wind_dir_src.value > 250][wind_dir_src.value < 360].query(\"variable == 'dir_3m_c'\").time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = pd.concat([\n",
    "    calculate_normalized_ablation_rate(profile_df_list[0], 7.5, 35, '20230517').assign(patch=0),\n",
    "    calculate_normalized_ablation_rate(profile_df_list[1], 7.5, 35, '20230517').assign(patch = 1),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "src_only_downvalley = src[src.time.isin(down_valley_wind_times)]\n",
    "\n",
    "\n",
    "get_chart(src) | get_chart(src_only_downvalley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in sorted(src.time.dt.day.unique()):\n",
    "    display(get_chart(src[src.time.dt.day==day]).properties(title=str(day)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.Chart(src).mark_boxplot(outliers=False,    size=10).encode(\n",
    "    alt.X('bin:Q'), \n",
    "    alt.Y('surface:Q').scale(zero=False),\n",
    ").properties(width=200,height=200) + alt.Chart(src).mark_circle().encode(\n",
    "    alt.X('bin:Q'), \n",
    "    alt.Y('mean(surface):Q').scale(zero=False),\n",
    ").properties(width=200,height=200)).facet('patch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Lidar-based melt rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Only include data points (distance values) where we know melt occurred on all the days of interest. We use the plots above to determine the range in distance values to include.\n",
    "2. Apply an accumulating minimum filter - which removes positive SWE signals\n",
    "3. Calculate daily/hourly ∆SWE (difference the datasets time-wise)\n",
    "4. Calculate the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Only include data points (distance values) where we know melt occurred\n",
    "patch_uw_profile_1 = profile_df_list[0].reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray().sel(distance = slice(15,30))\n",
    "patch_uw_profile_2 = profile_df_list[1].reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray().sel(distance = slice(20, 33))\n",
    "patch_uw_profile_3 = profile_df_list[2].reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray().sel(distance = slice(17.5, 35))\n",
    "patch_d_profile_1 = profile_df_list[3].reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray().sel(distance = slice(12, 20))\n",
    "patch_d_profile_2 = profile_df_list[4].reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray().sel(distance = slice(10, 18))\n",
    "patch_d_profile_3 = profile_df_list[5].reset_index().set_index(['time', 'distance', 'patch'])['surface'].to_xarray().sel(distance = slice(22.5, 35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_ds_list = [\n",
    "    patch_uw_profile_1.sel(time = slice('20230510', '20230518')),\n",
    "    patch_uw_profile_2.sel(time = slice('20230510', '20230518')),\n",
    "    patch_uw_profile_3.sel(time = slice('20230510', '20230518')),\n",
    "    patch_d_profile_1.sel(time = slice('20230510', '20230518')),\n",
    "    patch_d_profile_2.sel(time = slice('20230510', '20230518')),\n",
    "    patch_d_profile_3.sel(time = slice('20230510', '20230518')),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply an accumulating minimum filter - which removes positive SWE signals\n",
    "for i, ds in enumerate(profile_ds_list):\n",
    "    profile_ds_list[i] = ds.copy(data = np.minimum.accumulate(ds.values, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calculate hourly and daily change rates\n",
    "diff_hourly_ds_list = []\n",
    "diff_daily_ds_list = []\n",
    "for i, ds in enumerate(profile_ds_list):\n",
    "    diff_hourly_ds_list.append( ds.differentiate('time', datetime_unit='h') )\n",
    "    diff_daily_ds_list.append( ds.sel(time = slice(None, None, 24)).differentiate('time', datetime_unit='h') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_hourly_ds_list[0].isel(distance=slice(0,20)).mean('distance').plot()\n",
    "\n",
    "diff_hourly_ds_list[0].isel(distance=slice(20,40)).mean('distance').plot()\n",
    "\n",
    "diff_hourly_ds_list[0].isel(distance=slice(40,60)).mean('distance').plot()\n",
    "diff_hourly_ds_list[0].isel(distance=slice(60,80)).mean('distance').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate the profile-averaged hourly and daily change rates \n",
    "mean_diff_hourly_ds_list = []\n",
    "mean_diff_daily_ds_list = []\n",
    "\n",
    "for i, ds in enumerate(diff_hourly_ds_list):\n",
    "    mean_diff_hourly_ds_list.append(ds.mean('distance'))\n",
    "\n",
    "for i, ds in enumerate(diff_daily_ds_list):\n",
    "    mean_diff_daily_ds_list.append(ds.mean('distance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in mean_diff_daily_ds_list:\n",
    "    ds.plot(label = ds.patch.values)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in mean_diff_hourly_ds_list:\n",
    "    ds.plot(label = ds.patch.values)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to W/m^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_density = 400 * units(\"kg/m^3\")\n",
    "specific_heat_of_fusion = 334 * units(\"kJ/kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emelt_daily_ds_list = []\n",
    "for ds in mean_diff_daily_ds_list:\n",
    "    emelt_daily_ds_list.append((\n",
    "        (\n",
    "            (\n",
    "                ds / (60*60*24)\n",
    "            ) * units(\"m^3/s\") * snow_density * specific_heat_of_fusion\n",
    "        ) / (1*units(\"m^2\"))\n",
    "    ).pint.to(\"W/m^2\"))\n",
    "\n",
    "\n",
    "\n",
    "emelt_hourly_ds_list = []\n",
    "for ds in mean_diff_hourly_ds_list:\n",
    "    emelt_hourly_ds_list.append((\n",
    "        (\n",
    "            (\n",
    "                ds / (60*60)\n",
    "            ) * units(\"m^3/s\") * snow_density * specific_heat_of_fusion\n",
    "        ) / (1*units(\"m^2\"))\n",
    "    ).pint.to(\"W/m^2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot: daily-averaged melt energy, using 24-hr timesteps in lidar data (e.g. use every 24th scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in emelt_daily_ds_list:\n",
    "    ds.plot(label = ds.patch.values)\n",
    "plt.legend()\n",
    "plt.xlim(dt.datetime(2023, 5, 13), dt.datetime(2023, 5, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot: daily-averaged melt energy, aggregated from hourly-averaged melt energy, from 1-hr timesteps in lidar data (e.g. use every scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in emelt_hourly_ds_list:\n",
    "    ds.resample(time='24h').mean().plot(label = ds.patch.values)\n",
    "plt.legend()\n",
    "plt.xlim(dt.datetime(2023, 5, 13), dt.datetime(2023, 5, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot: hourly-averaged melt energy, from 1-hr timesteps in lidar data (e.g. use every scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in emelt_hourly_ds_list:\n",
    "    ds.plot(label = ds.patch.values)\n",
    "plt.legend()\n",
    "plt.xlim(dt.datetime(2023, 5, 13), dt.datetime(2023, 5, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy balance calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data - SOS and SPLASH measurements\n",
    "\n",
    "\n",
    "Note that the SOS radiometers were down in the middle of our study period. So we get radiometrics from the SPLASH KPS ANNEX site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the SOS dataset is missing radiation measurements during our study period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_df.query(\"variable == 'Rlw_in_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()\n",
    "sos_df.query(\"variable == 'Rlw_out_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()\n",
    "sos_df.query(\"variable == 'Rsw_in_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()\n",
    "sos_df.query(\"variable == 'Rsw_out_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the SPLASH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_download_dir = \"/Users/elischwat/Development/data/sublimationofsnow/asfs/ASFS-30_Level2_SPLASH2021-2023/\"\n",
    "kps_file_list = sorted([\n",
    "    os.path.join(kps_download_dir, f) for f in os.listdir(kps_download_dir) \n",
    "    if 'sledseb.asfs30.level2.0.10min.' in f\n",
    "])[385:]\n",
    "kps_file_list = [f for f in kps_file_list if f[-18:-10] in \n",
    "    [\n",
    "        '20230508', '20230509', '20230510', '20230511', '20230512', '20230513', \n",
    "        '20230514', '20230515', '20230516', '20230517', '20230518', '20230519', \n",
    "        '20230520', '20230521', '20230522', '20230523', '20230524', '20230525'    \n",
    "    ]\n",
    "]\n",
    "kpsann_ds = xr.open_mfdataset(kps_file_list)\n",
    "kpsann_df = kpsann_ds[[\n",
    "    'time', 'temp', 'atmos_pressure',  'skin_temp_surface',\n",
    "    'down_long_hemisp', 'up_long_hemisp', 'down_short_hemisp', 'up_short_hemisp',\n",
    "]].to_dataframe()\n",
    "kpsann_df_30min = kpsann_df.reset_index().set_index('time').resample('30min').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check SPLASH has all four radiation terms for our study period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpsann_df[[\n",
    "    'down_long_hemisp', 'up_long_hemisp', 'down_short_hemisp', 'up_short_hemisp',\n",
    "]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the 5min SOS datasets. Use radiation measurements from the 5min SOS datasets, along with the SPLASH datasets, to ensure we have complete radiometric measurements in one dataset, representing Kettle Ponds area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_df.query(\"variable == 'Tsurf_c'\").set_index('time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up SOS 5min datasets\n",
    "files = [\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230508.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230509.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230510.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230511.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230512.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230513.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230514.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230515.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230516.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230517.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230518.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230519.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230520.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230521.nc\",\n",
    "    \"/Users/elischwat/Development/data/sublimationofsnow/sosqc/sos_isfs_qc_geo_tiltcor_5min_v20241227/isfs_sos_qc_geo_tiltcor_5min_v2_20230522.nc\",\n",
    "]\n",
    "datasets = [xr.open_dataset(file) for file in files]\n",
    "sos_ds = xr.concat(datasets, dim='time')\n",
    "\n",
    "# gather the variables we need for surface temp calculations and resample to 30min\n",
    "sos_ds = sos_ds[[\n",
    "    'Rpile_in_9m_d', 'Tcase_in_9m_d', 'Rpile_out_9m_d', 'Tcase_out_9m_d', \n",
    "    'Rpile_in_uw', 'Tcase_uw', 'Rpile_out_uw', 'Tcase_uw', \n",
    "    'IDir_c', 'IDir_d', 'IDir_uw', 'IDir_ue', 'Vtherm_c', \n",
    "    'Vtherm_d', 'Vtherm_uw', 'Vtherm_ue', 'Vpile_c', 'Vpile_d', 'Vpile_uw', 'Vpile_ue', \n",
    "]].resample(time='30min').mean()\n",
    "\n",
    "# gather the SPLASH KPS-Annex measurements of Rlw_in\n",
    "kpsann_down_long_hemisp = kpsann_df[[\n",
    "    'down_long_hemisp', 'up_long_hemisp', 'down_short_hemisp', 'up_short_hemisp',\n",
    "]].to_xarray().sel(\n",
    "    time = slice(sos_ds.time.values.min(), sos_ds.time.values.max())\n",
    ").resample(time='30min').mean()\n",
    "\n",
    "# add the KPS-Annex Rlw_in to the SOS dataset\n",
    "sos_ds['Rlw_in_9m_d'] = kpsann_down_long_hemisp['down_long_hemisp']\n",
    "sos_ds['Rlw_out_9m_d'] = kpsann_down_long_hemisp['up_long_hemisp']\n",
    "sos_ds['Rsw_in_9m_d'] = kpsann_down_long_hemisp['down_short_hemisp']\n",
    "sos_ds['Rsw_out_9m_d'] = kpsann_down_long_hemisp['up_short_hemisp']\n",
    "new_variables = [\n",
    "        'Tsurf_c', 'Tsurf_d', 'Tsurf_uw', 'Tsurf_ue',\n",
    "         'Rlw_in_9m_d', 'Rlw_out_9m_d', 'Rsw_in_9m_d', 'Rsw_out_9m_d'\n",
    "    ]\n",
    "sos_ds = variables.add_surface_temps(sos_ds)[new_variables]\n",
    "sos_ds = utils.modify_xarray_timezone(sos_ds, 'UTC', 'US/Mountain')\n",
    "new_tidy_df = tidy.get_tidy_dataset(sos_ds, variable_names=new_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the datasets\n",
    "all_variables_outside_timeperiod = sos_df[ \n",
    "        (sos_df.time < new_tidy_df.time.min())\n",
    "        |\n",
    "        (sos_df.time > new_tidy_df.time.max())\n",
    "    ]\n",
    "variables_not_being_replaced_inside_timeperiod = sos_df[ \n",
    "        (~ sos_df.variable.isin(new_variables))\n",
    "        &\n",
    "        (sos_df.time >= new_tidy_df.time.min())\n",
    "        &\n",
    "        (sos_df.time <= new_tidy_df.time.max())\n",
    "    ]\n",
    "sos_df_gapfilled = pd.concat([\n",
    "    all_variables_outside_timeperiod,\n",
    "    variables_not_being_replaced_inside_timeperiod,\n",
    "    new_tidy_df\n",
    "])\n",
    "sos_df = sos_df_gapfilled.set_index('time').sort_index().reset_index()\n",
    "sos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_df.query(\"variable == 'Tsurf_c'\").set_index('time').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin(['Tsurf_c', 'Tsurf_d', 'Tsurf_ue', 'Tsurf_uw'])]\n",
    "src = src[src.time >= '20230512 ']\n",
    "src = src[src.time < '20230522']\n",
    "alt.Chart(src).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('tower:N')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that everything made it into our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_df.query(\"variable == 'Rlw_in_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()\n",
    "sos_df.query(\"variable == 'Rlw_out_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()\n",
    "sos_df.query(\"variable == 'Rsw_in_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()\n",
    "sos_df.query(\"variable == 'Rsw_out_9m_d'\").set_index('time').sort_index().loc['20230510': '20230518'].value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_ALBEDO = 0.6\n",
    "net_rad_df = sos_df[sos_df.variable.isin([\n",
    "    'Rsw_in_9m_d',\n",
    "    'Rsw_out_9m_d',\n",
    "    'Rlw_in_9m_d',\n",
    "    'Rlw_out_9m_d',\n",
    "])].pivot_table(index='time', columns='variable', values='value')\n",
    "\n",
    "net_rad_df['Rsw_out_9m_d_modeled'] = EST_ALBEDO*net_rad_df['Rsw_in_9m_d']\n",
    "\n",
    "net_rad_df['net radiation'] = (\n",
    "    net_rad_df['Rsw_in_9m_d'] - net_rad_df['Rsw_out_9m_d_modeled'] \n",
    "    + net_rad_df['Rlw_in_9m_d'] - net_rad_df['Rlw_out_9m_d']\n",
    ")\n",
    "net_rad_df['albedo'] = net_rad_df['Rsw_out_9m_d_modeled'] / net_rad_df['Rsw_in_9m_d']\n",
    "# net_rad_df = net_rad_df[['net radiation']]\n",
    "net_rad_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turbulent fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turb_flux_df = sos_df[sos_df.variable.isin([\n",
    "    'w_h2o__3m_c',\n",
    "    'w_tc__3m_c'\n",
    "])].pivot_table(index='time', columns='variable', values='value')\n",
    "\n",
    "latent_heat_sublimation = 2838 #J/g\n",
    "turb_flux_df['w_h2o__3m_c'] = - turb_flux_df['w_h2o__3m_c'] * latent_heat_sublimation\n",
    "\n",
    "specific_heat_capacity_air = 1.005 # J/K/g\n",
    "air_density = 1000 # g/m^3                                       \n",
    "turb_flux_df['w_tc__3m_c'] = - turb_flux_df['w_tc__3m_c'] * specific_heat_capacity_air * air_density\n",
    "\n",
    "turb_flux_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melt energy, from snow pillows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpillow_melt_energy_df = sos_df[sos_df.variable.isin([\n",
    "    'SWE_p2_c', 'SWE_p4_c', \n",
    "    'SWE_p1_c', 'SWE_p3_c', \n",
    "])].set_index('time').sort_index().loc[\n",
    "    '20230510': '20230517'\n",
    "].reset_index().pivot_table(\n",
    "    index = ['time', 'tower'],\n",
    "    values='value',\n",
    "    columns='measurement'\n",
    ").reset_index()\n",
    "\n",
    "# Create a 60min xr dataset\n",
    "snowpillow_melt_energy_ds = snowpillow_melt_energy_df.set_index(['time', 'tower']).to_xarray()['SWE'].resample(time='60min').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpillow_melt_energy_ds.plot(col='tower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a very loose filter, removing data outside a rolling window of 4x std dev, to remove that one spike "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = snowpillow_melt_energy_ds.sel(tower = 'd')\n",
    "# Assuming `data` is a pandas Series or DataFrame column\n",
    "window_size = 5  # Define the rolling window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling mean and standard deviation\n",
    "rolling_mean = snowpillow_melt_energy_ds.rolling(time=window_size, center=True, min_periods=1).mean()\n",
    "rolling_std = snowpillow_melt_energy_ds.rolling(time=window_size, center=True, min_periods=1).std()\n",
    "\n",
    "# Define the bounds\n",
    "lower_bound = rolling_mean - 1.8 * rolling_std\n",
    "upper_bound = rolling_mean + 1.8 * rolling_std\n",
    "\n",
    "# Remove data outside the bounds\n",
    "filtered_data = snowpillow_melt_energy_ds.where((snowpillow_melt_energy_ds >= lower_bound) & (snowpillow_melt_energy_ds <= upper_bound))\n",
    "\n",
    "# Display the filtered data\n",
    "filtered_data.plot(col='tower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this removed just a single data point, which we infill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpillow_melt_energy_ds = filtered_data.ffill('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpillow_melt_energy_ds.plot(col='tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a cumulative minimum. This filters data, and removes data that represent increases in SWE over time.\n",
    "snowpillow_melt_energy_filtered_ds = snowpillow_melt_energy_ds.copy(data = np.minimum.accumulate(snowpillow_melt_energy_ds.values))\n",
    "\n",
    "# calculate mm/hr from \n",
    "mm_hr = snowpillow_melt_energy_ds.differentiate('time', datetime_unit = 'h')\n",
    "mm_hr_filtered = snowpillow_melt_energy_filtered_ds.differentiate('time', datetime_unit = 'h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the filtered measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(15,4.3))\n",
    "snowpillow_melt_energy_ds.sel(tower='c').plot(ax = axes[0], color='tab:blue')\n",
    "snowpillow_melt_energy_ds.sel(tower='d').plot(ax = axes[0], color='tab:orange')\n",
    "snowpillow_melt_energy_ds.sel(tower='uw').plot(ax = axes[0], color='tab:red')\n",
    "snowpillow_melt_energy_ds.sel(tower='ue').plot(ax = axes[0], color='tab:purple')\n",
    "snowpillow_melt_energy_filtered_ds.sel(tower='c').plot(linestyle=':', ax = axes[0], color='tab:blue')\n",
    "snowpillow_melt_energy_filtered_ds.sel(tower='d').plot(linestyle=':', ax = axes[0], color='tab:orange')\n",
    "snowpillow_melt_energy_filtered_ds.sel(tower='uw').plot(linestyle=':', ax = axes[0], color='tab:red')\n",
    "snowpillow_melt_energy_filtered_ds.sel(tower='ue').plot(linestyle=':', ax = axes[0], color='tab:purple')\n",
    "\n",
    "mm_hr.sel(tower = 'c').plot(ax = axes[1], color='tab:blue')\n",
    "mm_hr.sel(tower = 'd').plot(ax = axes[1], color='tab:orange')\n",
    "mm_hr.sel(tower = 'uw').plot(ax = axes[1], color='tab:red')\n",
    "mm_hr.sel(tower = 'uw').plot(ax = axes[1], color='tab:purple')\n",
    "\n",
    "mm_hr_filtered.sel(tower = 'c').plot(ax = axes[2], color='tab:blue')\n",
    "mm_hr_filtered.sel(tower = 'd').plot(ax = axes[2], color='tab:orange')\n",
    "mm_hr_filtered.sel(tower = 'uw').plot(ax = axes[2], color='tab:red')\n",
    "mm_hr_filtered.sel(tower = 'uw').plot(ax = axes[2], color='tab:purple')\n",
    "\n",
    "axes[0].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(15,4.3))\n",
    "snowpillow_melt_energy_ds.sel(tower='c').plot(ax = axes[0], color='tab:blue', label='tower c')\n",
    "snowpillow_melt_energy_ds.sel(tower='ue').plot(ax = axes[0], color='tab:orange', label='tower ue')\n",
    "snowpillow_melt_energy_filtered_ds.sel(tower='c').plot(linestyle=':', ax = axes[0], color='tab:blue', label='tower c, filtered')\n",
    "snowpillow_melt_energy_filtered_ds.sel(tower='ue').plot(linestyle=':', ax = axes[0], color='tab:orange', label='tower ue, filtered')\n",
    "\n",
    "mm_hr.sel(tower = 'c').plot(ax = axes[1], color='tab:blue', label='tower c')\n",
    "mm_hr.sel(tower = 'ue').plot(ax = axes[1], color='tab:orange', label='tower ue')\n",
    "\n",
    "mm_hr_filtered.sel(tower = 'c').plot(ax = axes[2], color='tab:blue', linestyle='--', label='tower c, filtered')\n",
    "mm_hr_filtered.sel(tower = 'ue').plot(ax = axes[2], color='tab:orange', linestyle='--', label='tower ue, filtered')\n",
    "\n",
    "axes[0].set_ylabel('SWE (mm)')\n",
    "axes[1].set_ylabel('∆SWE, hourly (mm)')\n",
    "axes[2].set_ylabel('∆SWE, hourly (mm),\\nfiltered with cumulative mininmum')\n",
    "axes[1].set_ylim(-17.5, 5)\n",
    "axes[2].set_ylim(-17.5, 5)\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "axes[2].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert snow pillow SWE change to W/m^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpillow_melt_energy_df = (\n",
    "    (\n",
    "        (\n",
    "            mm_hr_filtered\n",
    "        ) * units(\"mm/hr\") * snow_density * specific_heat_of_fusion\n",
    "    )\n",
    ").pint.to(\"W/m^2\").rename('melt energy').to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare LIDAR E_melt and Snow Pillow E_melt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_melt_energy_df = pd.concat([ds.to_dataframe() for ds in emelt_hourly_ds_list]).rename(\n",
    "    columns = {'surface': 'melt energy'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_src = lidar_melt_energy_df.xs(slice('20230510', '20230517'), level=0, drop_level=False).reset_index()\n",
    "snowpillow_src = snowpillow_melt_energy_df.xs(slice('20230510', '20230517'), level=0, drop_level=False).reset_index()\n",
    "alt.Chart(lidar_src).mark_errorbar(extent='iqr').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('melt energy:Q'),\n",
    ").properties(width=900) + alt.Chart(lidar_src).mark_circle(color='grey').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('median(melt energy):Q'),\n",
    ").properties(width=900) + alt.Chart(snowpillow_src).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('melt energy:Q'),\n",
    "    alt.Color('tower:N'),\n",
    ").properties(width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(lidar_src).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('melt energy:Q'),\n",
    "    alt.Color('patch:N').scale(domain=['d_1', 'd_2', 'd_5', 'uw_0', 'uw_1', 'uw_2'], range=['blue', 'blue', 'blue', 'red', 'red', 'red'])\n",
    ").properties(width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes of all the different Emelt estimates, in wide format\n",
    "lidar_src_wide = lidar_src.pivot_table(index='time', values='melt energy', columns='patch')\n",
    "lidar_src_wide.columns = [f\"Emelt_{col_name}\" for col_name in lidar_src_wide.columns]\n",
    "\n",
    "snowpillow_src_wide = snowpillow_src.pivot_table(index='time', values='melt energy', columns='tower')\n",
    "snowpillow_src_wide.columns = [f\"Emelt_{col_name}\" for col_name in snowpillow_src_wide.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lidar_src_wide.head(3))\n",
    "display(snowpillow_src_wide.head(3))\n",
    "display(turb_flux_df.head(3))\n",
    "display(net_rad_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_balance_df = lidar_src_wide.join(\n",
    "    snowpillow_src_wide\n",
    ").join(\n",
    "    turb_flux_df.resample('60min').mean()    \n",
    ").join(\n",
    "    net_rad_df.resample('60min').mean()['net radiation']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_balance_df['Emelt_lidar_median'] = energy_balance_df[[\n",
    "        'Emelt_d_1', 'Emelt_d_2', 'Emelt_d_5', 'Emelt_uw_0', 'Emelt_uw_1', 'Emelt_uw_2', \n",
    "]].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_balance_df['residual'] = energy_balance_df[[\n",
    "#         'Emelt_lidar_median', 'net radiation', 'w_h2o__3m_c',\n",
    "# ]].sum(axis=1)\n",
    "energy_balance_df['residual_d_1'] = - energy_balance_df[['Emelt_d_1', 'net radiation', 'w_h2o__3m_c',       'w_tc__3m_c']].sum(axis=1)\n",
    "energy_balance_df['residual_d_2'] = - energy_balance_df[['Emelt_d_2', 'net radiation', 'w_h2o__3m_c',       'w_tc__3m_c']].sum(axis=1)\n",
    "energy_balance_df['residual_d_5'] = - energy_balance_df[['Emelt_d_5', 'net radiation', 'w_h2o__3m_c',       'w_tc__3m_c']].sum(axis=1)\n",
    "energy_balance_df['residual_uw_0'] =    - energy_balance_df[['Emelt_uw_0', 'net radiation', 'w_h2o__3m_c',  'w_tc__3m_c']].sum(axis=1)\n",
    "energy_balance_df['residual_uw_1'] =    - energy_balance_df[['Emelt_uw_1', 'net radiation', 'w_h2o__3m_c',  'w_tc__3m_c']].sum(axis=1)\n",
    "energy_balance_df['residual_uw_2'] =    - energy_balance_df[['Emelt_uw_2', 'net radiation', 'w_h2o__3m_c',  'w_tc__3m_c']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_band_chart = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").transform_fold([\n",
    "    'residual_d_1', 'residual_d_2', 'residual_d_5', 'residual_uw_0', 'residual_uw_1', 'residual_uw_2'\n",
    "]).mark_errorband(extent='iqr', color='grey', borders={'color':'lightgrey', 'strokeWidth': 1}).encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    ").properties(width=900)\n",
    "rad_and_turb_fluxes = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").transform_fold([\n",
    "    'net radiation', 'w_h2o__3m_c', 'w_tc__3m_c',\n",
    "]).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('key:N'),\n",
    ").properties(width=900)\n",
    "e_melt_median_chart = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").mark_circle(color='black').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('Emelt_lidar_median:Q'),\n",
    ").properties(width=900)\n",
    "e_melt_spread_chart = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").transform_fold([\n",
    "    'Emelt_d_1', 'Emelt_d_2', 'Emelt_d_5', 'Emelt_uw_0', 'Emelt_uw_1', 'Emelt_uw_2', \n",
    "]).mark_errorbar(extent='iqr').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    ").properties(width=900)\n",
    " \n",
    "e_balance_chart = (\n",
    "    residual_band_chart + e_melt_spread_chart + e_melt_median_chart + rad_and_turb_fluxes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_balance_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine EC flux divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metpy.units import units\n",
    "def w_tc_to_watts(values):\n",
    "    specific_heat_capacity_air = 1.0005 * units('kilojoules/(K*kg)')\n",
    "    air_density = 1 * units(\"kg/m^3\")\n",
    "    sensible_heat_flux_meas_units = values * units(\"K*m/s\")\n",
    "    return (sensible_heat_flux_meas_units * specific_heat_capacity_air * air_density).to(\"W/m^2\").magnitude\n",
    "def w_h2o_to_watts(values):\n",
    "    latent_heat_of_vaporization = 2838 * units(\"J/g\")\n",
    "    latent_heat_flux_meas_units = values * units(\"g/(m^2 * s)\")\n",
    "    return (latent_heat_flux_meas_units * latent_heat_of_vaporization).to(\"W/m^2\").magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_line = alt.Chart().mark_rule(color='black', strokeDash=[5, 5]).encode(\n",
    "    y=alt.datum(0)  # Set y=0\n",
    ").transform_calculate(\n",
    "    x='datum.x'  # Use a placeholder for x if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin([\n",
    "    'w_tc__1m_c', 'w_tc__2m_c', 'w_tc__3m_c', 'w_tc__5m_c', \n",
    "    # 'w_tc__1m_ue', 'w_tc__2m_ue', 'w_tc__3m_ue', \n",
    "    # 'w_tc__1m_uw', 'w_tc__2m_uw', 'w_tc__3m_uw', \n",
    "    # 'w_tc__1m_d', 'w_tc__2m_d', 'w_tc__3m_d', \n",
    "])]\n",
    "src = src[src.time > '20230510']\n",
    "src = src[src.time < '20230524']\n",
    "src = src.query(\"tower == 'c'\")\n",
    "src.value = w_tc_to_watts(src.value.values)\n",
    "w_tc_chart = alt.Chart(src).transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-2,2],\n",
    "    groupby = ['tower', 'height'],\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T').axis(format='May %d %H00'),\n",
    "    alt.Y('rolling_avg:Q'),\n",
    "    alt.Color('height:N'),\n",
    "    alt.StrokeDash('tower:N'),\n",
    ").properties(width=900) + zero_line\n",
    "w_tc_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin([\n",
    "    'w_h2o__1m_c', 'w_h2o__2m_c', 'w_h2o__3m_c', 'w_h2o__5m_c', \n",
    "    # 'w_h2o__1m_ue', 'w_h2o__2m_ue', 'w_h2o__3m_ue', \n",
    "    # 'w_h2o__1m_uw', 'w_h2o__2m_uw', 'w_h2o__3m_uw', \n",
    "    # 'w_h2o__1m_d', 'w_h2o__2m_d', 'w_h2o__3m_d', \n",
    "])]\n",
    "src = src[src.time > '20230510']\n",
    "src = src[src.time < '20230524']\n",
    "src = src.query(\"tower == 'c'\")\n",
    "src.value = w_h2o_to_watts(src.value.values)\n",
    "w_h2o_chart = alt.Chart(src).transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-2,2],\n",
    "    groupby = ['tower', 'height'],\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T').axis(format='May %d %H00'),\n",
    "    alt.Y('rolling_avg:Q'),\n",
    "    alt.Color('height:N'),\n",
    "    alt.StrokeDash('tower:N'),\n",
    ").properties(width=900) + zero_line\n",
    "w_h2o_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin([\n",
    "    'w_h2o__2m_c',\n",
    "    'w_h2o__2m_d',\n",
    "    'w_h2o__2m_ue',\n",
    "    'w_h2o__2m_uw',\n",
    "])]\n",
    "src = src[src.time > '20230510']\n",
    "src = src[src.time < '20230524']\n",
    "src.value = w_h2o_to_watts(src.value.values)\n",
    "w_h2o_chart = alt.Chart(src).transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-2,2],\n",
    "    groupby = ['tower', 'height'],\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T').axis(format='May %d %H00'),\n",
    "    alt.Y('rolling_avg:Q'),\n",
    "    # alt.Color('height:N'),\n",
    "    alt.StrokeDash('tower:N'),\n",
    ").properties(width=900) + zero_line\n",
    "w_h2o_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin([\n",
    "    'spd_2m_c',\n",
    "    'T_2m_c',\n",
    "])]\n",
    "src = src[src.time > '20230510']\n",
    "src = src[src.time < '20230524']\n",
    "w_h2o_chart = alt.Chart(src).transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-4,4],\n",
    "    groupby = ['tower', 'height', 'variable'],\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T').axis(format='May %d %H00'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('variable:N'),\n",
    "    alt.StrokeDash('tower:N'),\n",
    ").properties(width=1200) + zero_line\n",
    "w_h2o_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin([\n",
    "    'Tsurf_c',\n",
    "    'Tsurf_d',\n",
    "    'Tsurf_ue',\n",
    "    'Tsurf_uw',\n",
    "])]\n",
    "src = src[src.time > '20230510']\n",
    "src = src[src.time < '20230524']\n",
    "w_h2o_chart = alt.Chart(src).transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-2,2],\n",
    "    groupby = ['tower', 'height'],\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T').axis(format='May %d %H00'),\n",
    "    alt.Y('rolling_avg:Q'),\n",
    "    # alt.Color('height:N'),\n",
    "    alt.StrokeDash('tower:N'),\n",
    ").properties(width=900) + zero_line\n",
    "w_h2o_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_src = sos_df[sos_df.variable.isin([\n",
    "    'dir_3m_c',\n",
    "    'dir_5m_c',\n",
    "    'dir_20m_c',\n",
    "])]\n",
    "wind_dir_src = wind_dir_src[wind_dir_src.time > '20230510']\n",
    "wind_dir_src = wind_dir_src[wind_dir_src.time < '20230524']\n",
    "wind_dir_chart = alt.Chart(wind_dir_src).mark_circle().encode(\n",
    "    alt.X('time:T').axis(format='May %d %H00'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('height:N'),\n",
    ").properties(width=900) + zero_line\n",
    "wind_dir_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = sos_df[sos_df.variable.isin([\n",
    "    'Tsurf_c',\n",
    "    'Tsurf_d',\n",
    "    'Tsurf_ue',\n",
    "    'Tsurf_uw',\n",
    "])]\n",
    "alt.Chart(\n",
    "    src[src.time >= '20230510'][src.time < '20230518'].query(\"tower == 'uw'\")\n",
    ").transform_window(\n",
    "    rolling_avg = 'mean(value)',\n",
    "    frame=[-2,2],\n",
    "    groupby = ['tower', 'height'],\n",
    ").mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('tower:N'),\n",
    "    # alt.StrokeDash('tower:N'),\n",
    ").properties(width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that one average, between 0600 and 1200, surface temps increase 5˚C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_T_delta_t = 5*units(\"kelvin\") / (6*60*60 * units(\"seconds\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c_p of ice is ~2100\n",
    "c_p of snow is ~1005\n",
    "\n",
    "So a c_p in between the two is probably a fine estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_p = 1552 * units('joules/(kelvin*kg)')\n",
    "rho = 400 * units(\"kg/m^3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depth = 50 #cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(delta_T_delta_t * (snow_depth * units('cm'))*rho*c_p).to(units(\"W/m^2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the storage change term forreal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_surf_t = sos_df.query(\"variable == 'Tsurf_uw'\").set_index('time').loc['20230509':'20230518'].value.rolling(10, center=True).mean()\n",
    "dT_dt = rolling_surf_t.to_xarray().differentiate('time', datetime_unit = 's')\n",
    "dT_dt.values * units(\"kelvin/second\")\n",
    "\n",
    "snow_depth = 50 #cm\n",
    "storage_change_term_w_units = ((dT_dt.values * units(\"kelvin/second\")) * (snow_depth * units('cm'))*rho*c_p).to(units(\"W/m^2\"))\n",
    "storage_change = dT_dt.copy(data = storage_change_term_w_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_change.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_balance_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_band_chart = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").transform_fold([\n",
    "    'residual_d_1', 'residual_d_2', 'residual_d_5', 'residual_uw_0', 'residual_uw_1', 'residual_uw_2'\n",
    "]).mark_errorband(extent='iqr', color='grey', borders={'color':'lightgrey', 'strokeWidth': 1}).encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    ").properties(width=900)\n",
    "rad_and_turb_fluxes = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").transform_fold([\n",
    "    'net radiation', 'w_h2o__3m_c', 'w_tc__3m_c',\n",
    "]).mark_line().encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('key:N'),\n",
    ").properties(width=900)\n",
    "e_melt_median_chart = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").mark_circle(color='black').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('Emelt_lidar_median:Q'),\n",
    ").properties(width=900)\n",
    "e_melt_spread_chart = alt.Chart(\n",
    "    energy_balance_df.reset_index()\n",
    ").transform_fold([\n",
    "    'Emelt_d_1', 'Emelt_d_2', 'Emelt_d_5', 'Emelt_uw_0', 'Emelt_uw_1', 'Emelt_uw_2', \n",
    "]).mark_errorbar(extent='iqr').encode(\n",
    "    alt.X('time:T'),\n",
    "    alt.Y('value:Q'),\n",
    ").properties(width=900)\n",
    " \n",
    "e_balance_chart = (\n",
    "    residual_band_chart + e_melt_spread_chart + e_melt_median_chart + rad_and_turb_fluxes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sublimationofsnow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
