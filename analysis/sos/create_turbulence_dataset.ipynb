{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netcdf/numpy/xray/stats\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/elilouis/sublimationofsnow/\")\n",
    "import sosutils\n",
    "from metpy.units import units\n",
    "import metpy\n",
    "import pint_xarray\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "alt.renderers.enable('svg')\n",
    "import pytz\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from urllib.error import URLError\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_download_dir='/data2/elilouis/sublimationofsnow/sosnoqc'\n",
    "DATE_FORMAT_STR = '%Y%m%d'\n",
    "start_date = '20230101'; \n",
    "end_date = dt.datetime.strftime(dt.date.today() - dt.timedelta(days=1), DATE_FORMAT_STR)\n",
    "PLANAR_FIT = True\n",
    "\n",
    "# start_date = '20230219'\n",
    "end_date = '20230110'\n",
    "\n",
    "\n",
    "\n",
    "datelist = pd.date_range(\n",
    "    dt.datetime.strptime(start_date, DATE_FORMAT_STR),\n",
    "    dt.datetime.strptime(end_date, DATE_FORMAT_STR),\n",
    "    freq='d'\n",
    ").strftime(DATE_FORMAT_STR).tolist()\n",
    "\n",
    "VARIABLE_NAMES = [\n",
    "    # Sonic Anemometer Data for 4 towers\n",
    "    'tc_1m_uw',     'spd_1m_uw',     'dir_1m_uw',     'u_1m_uw',   'v_1m_uw',   'w_1m_uw',   'u_u__1m_uw',    'v_v__1m_uw',    'w_w__1m_uw',    \n",
    "        'u_w__1m_uw',    'v_w__1m_uw',  'u_tc__1m_uw',  'v_tc__1m_uw',   'u_h2o__1m_uw',  'v_h2o__1m_uw',   'w_tc__1m_uw',   'w_h2o__1m_uw',\n",
    "    'tc_3m_uw',     'spd_3m_uw',     'dir_3m_uw',     'u_3m_uw',   'v_3m_uw',   'w_3m_uw',   'u_u__3m_uw',    'v_v__3m_uw',    'w_w__3m_uw',    \n",
    "        'u_w__3m_uw',    'v_w__3m_uw',  'u_tc__3m_uw',  'v_tc__3m_uw',   'u_h2o__3m_uw',  'v_h2o__3m_uw',   'w_tc__3m_uw',   'w_h2o__3m_uw',\n",
    "    'tc_10m_uw',    'spd_10m_uw',    'dir_10m_uw',    'u_10m_uw',  'v_10m_uw',  'w_10m_uw',  'u_u__10m_uw',   'v_v__10m_uw',   'w_w__10m_uw',   \n",
    "        'u_w__10m_uw',   'v_w__10m_uw', 'u_tc__10m_uw', 'v_tc__10m_uw',  'u_h2o__10m_uw', 'v_h2o__10m_uw',  'w_tc__10m_uw',  'w_h2o__10m_uw',\n",
    "\n",
    "    'tc_1m_ue',     'spd_1m_ue',     'dir_1m_ue',     'u_1m_ue',   'v_1m_ue',   'w_1m_ue',   'u_u__1m_ue',    'v_v__1m_ue',    'w_w__1m_ue',    \n",
    "        'u_w__1m_ue',    'v_w__1m_ue',  'u_tc__1m_ue',  'v_tc__1m_ue',   'u_h2o__1m_ue',  'v_h2o__1m_ue',   'w_tc__1m_ue',   'w_h2o__1m_ue',\n",
    "    'tc_3m_ue',     'spd_3m_ue',     'dir_3m_ue',     'u_3m_ue',   'v_3m_ue',   'w_3m_ue',   'u_u__3m_ue',    'v_v__3m_ue',    'w_w__3m_ue',    \n",
    "        'u_w__3m_ue',    'v_w__3m_ue',  'u_tc__3m_ue',  'v_tc__3m_ue',   'u_h2o__3m_ue',  'v_h2o__3m_ue',   'w_tc__3m_ue',   'w_h2o__3m_ue',\n",
    "    'tc_10m_ue',    'spd_10m_ue',    'dir_10m_ue',    'u_10m_ue',  'v_10m_ue',  'w_10m_ue',  'u_u__10m_ue',   'v_v__10m_ue',   'w_w__10m_ue',   \n",
    "        'u_w__10m_ue',   'v_w__10m_ue', 'u_tc__10m_ue', 'v_tc__10m_ue',  'u_h2o__10m_ue', 'v_h2o__10m_ue',  'w_tc__10m_ue',  'w_h2o__10m_ue',\n",
    "\n",
    "    'tc_1m_d',      'spd_1m_d',     'dir_1m_d',     'u_1m_d',   'v_1m_d',   'w_1m_d',   'u_u__1m_d',    'v_v__1m_d',    'w_w__1m_d',    \n",
    "        'u_w__1m_d',    'v_w__1m_d',  'u_tc__1m_d',  'v_tc__1m_d',   'u_h2o__1m_d',  'v_h2o__1m_d',   'w_tc__1m_d',   'w_h2o__1m_d',\n",
    "    'tc_3m_d',      'spd_3m_d',     'dir_3m_d',     'u_3m_d',   'v_3m_d',   'w_3m_d',   'u_u__3m_d',    'v_v__3m_d',    'w_w__3m_d',    \n",
    "        'u_w__3m_d',    'v_w__3m_d',  'u_tc__3m_d',  'v_tc__3m_d',   'u_h2o__3m_d',  'v_h2o__3m_d',   'w_tc__3m_d',   'w_h2o__3m_d',\n",
    "    'tc_10m_d',     'spd_10m_d',    'dir_10m_d',    'u_10m_d',  'v_10m_d',  'w_10m_d',  'u_u__10m_d',   'v_v__10m_d',   'w_w__10m_d',   \n",
    "        'u_w__10m_d',   'v_w__10m_d', 'u_tc__10m_d', 'v_tc__10m_d',  'u_h2o__10m_d', 'v_h2o__10m_d',  'w_tc__10m_d',  'w_h2o__10m_d',\n",
    "\n",
    "    'tc_2m_c',  'spd_2m_c',     'dir_2m_c',     'u_2m_c',   'v_2m_c',   'w_2m_c',   'u_u__2m_c',    'v_v__2m_c',    'w_w__2m_c',    \n",
    "        'u_w__2m_c',    'v_w__2m_c',  'u_tc__2m_c',  'v_tc__2m_c',   'u_h2o__2m_c',  'v_h2o__2m_c',   'w_tc__2m_c',   'w_h2o__2m_c',\n",
    "    'tc_3m_c',  'spd_3m_c',     'dir_3m_c',     'u_3m_c',   'v_3m_c',   'w_3m_c',   'u_u__3m_c',    'v_v__3m_c',    'w_w__3m_c',    \n",
    "        'u_w__3m_c',    'v_w__3m_c',  'u_tc__3m_c',  'v_tc__3m_c',   'u_h2o__3m_c',  'v_h2o__3m_c',   'w_tc__3m_c',   'w_h2o__3m_c',\n",
    "    'tc_5m_c',  'spd_5m_c',     'dir_5m_c',     'u_5m_c',   'v_5m_c',   'w_5m_c',   'u_u__5m_c',    'v_v__5m_c',    'w_w__5m_c',    \n",
    "        'u_w__5m_c',    'v_w__5m_c',  'u_tc__5m_c',  'v_tc__5m_c',   'u_h2o__5m_c',  'v_h2o__5m_c',   'w_tc__5m_c',   'w_h2o__5m_c',\n",
    "    'tc_10m_c', 'spd_10m_c',    'dir_10m_c',    'u_10m_c',  'v_10m_c',  'w_10m_c',  'u_u__10m_c',   'v_v__10m_c',   'w_w__10m_c',   \n",
    "        'u_w__10m_c',   'v_w__10m_c', 'u_tc__10m_c', 'v_tc__10m_c',  'u_h2o__10m_c', 'v_h2o__10m_c',  'w_tc__10m_c',  'w_h2o__10m_c',\n",
    "    'tc_15m_c', 'spd_15m_c',    'dir_15m_c',    'u_15m_c',  'v_15m_c',  'w_15m_c',  'u_u__15m_c',   'v_v__15m_c',   'w_w__15m_c',   \n",
    "        'u_w__15m_c',   'v_w__15m_c', 'u_tc__15m_c', 'v_tc__15m_c',  'u_h2o__15m_c', 'v_h2o__15m_c',  'w_tc__15m_c',  'w_h2o__15m_c',\n",
    "    'tc_20m_c', 'spd_20m_c',    'dir_20m_c',    'u_20m_c',  'v_20m_c',  'w_20m_c',  'u_u__20m_c',   'v_v__20m_c',   'w_w__20m_c',   \n",
    "        'u_w__20m_c',   'v_w__20m_c', 'u_tc__20m_c', 'v_tc__20m_c',  'u_h2o__20m_c', 'v_h2o__20m_c',  'w_tc__20m_c',  'w_h2o__20m_c',\n",
    "\n",
    "    \n",
    "    # Temperature & Relative Humidity Array \n",
    "    'T_2m_c', 'T_3m_c', 'T_4m_c', 'T_5m_c', 'T_6m_c', 'T_7m_c', 'T_8m_c', 'T_9m_c', 'T_10m_c',\n",
    "    'T_11m_c', 'T_12m_c', 'T_13m_c', 'T_14m_c', 'T_15m_c', 'T_16m_c', 'T_17m_c', 'T_18m_c', 'T_19m_c', 'T_20m_c',\n",
    "\n",
    "    'RH_2m_c', 'RH_3m_c', 'RH_4m_c', 'RH_5m_c', 'RH_6m_c', 'RH_7m_c', 'RH_8m_c', 'RH_9m_c', 'RH_10m_c',\n",
    "    'RH_11m_c','RH_12m_c','RH_13m_c','RH_14m_c','RH_15m_c','RH_16m_c','RH_17m_c','RH_18m_c','RH_19m_c','RH_20m_c',\n",
    "\n",
    "    # Pressure Sensors\n",
    "    'P_20m_c',\n",
    "    'P_10m_c', 'P_10m_d', 'P_10m_uw', 'P_10m_ue',\n",
    "\n",
    "    # Blowing snow/FlowCapt Sensors\n",
    "    'SF_avg_1m_ue', 'SF_avg_2m_ue',\n",
    "\n",
    "    # Apogee sensors\n",
    "    \"Vtherm_c\", \"Vtherm_d\", \"Vtherm_ue\", \"Vtherm_uw\", \n",
    "    \"Vpile_c\", \"Vpile_d\", \"Vpile_ue\", \"Vpile_uw\",\n",
    "    \"IDir_c\", \"IDir_d\", \"IDir_ue\", \"IDir_uw\",\n",
    "\n",
    "    # Snow-level temperature arrays (towers D and UW)\n",
    "    'Tsnow_0_4m_d', 'Tsnow_0_5m_d', 'Tsnow_0_6m_d', 'Tsnow_0_7m_d', 'Tsnow_0_8m_d', 'Tsnow_0_9m_d', 'Tsnow_1_0m_d', 'Tsnow_1_1m_d', 'Tsnow_1_2m_d', 'Tsnow_1_3m_d', 'Tsnow_1_4m_d', 'Tsnow_1_5m_d',\n",
    "    'Tsnow_0_4m_uw', 'Tsnow_0_5m_uw', 'Tsnow_0_6m_uw', 'Tsnow_0_7m_uw', 'Tsnow_0_8m_uw', 'Tsnow_0_9m_uw', 'Tsnow_1_0m_uw', 'Tsnow_1_1m_uw', 'Tsnow_1_2m_uw', 'Tsnow_1_3m_uw', 'Tsnow_1_4m_uw', 'Tsnow_1_5m_uw',\n",
    "    \n",
    "    # Downward Facing Longwave Radiometer (tower D) - for measuring snow surface temperature\n",
    "    'Rpile_out_9m_d',\n",
    "    'Tcase_out_9m_d',\n",
    "    \n",
    "    # Upward facing shortwave radiometer (tower D) - for measuring incoming solar radiation!\n",
    "    'Rsw_in_9m_d',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SoS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching...skipping download for 20230101\n",
      "Caching...skipping download for 20230102\n",
      "Caching...skipping download for 20230103\n",
      "Caching...skipping download for 20230104\n",
      "Caching...skipping download for 20230105\n",
      "Caching...skipping download for 20230106\n",
      "Caching...skipping download for 20230107\n",
      "Caching...skipping download for 20230108\n",
      "Caching...skipping download for 20230109\n",
      "Caching...skipping download for 20230110\n"
     ]
    }
   ],
   "source": [
    "# We make sure that we aren't accessing variables that don't exist in the datasets\n",
    "# This is necessary because some daily NetCDF files don't have all the expected variables\n",
    "# (for example because an instrument was down). In that case, we want to add that variable\n",
    "# to the dataset, filled with nans, which sosutils.merge_datasets_with_different_variables\n",
    "# handles for us\n",
    "datasets = []\n",
    "for date in datelist:\n",
    "    try:\n",
    "        ds = xr.open_dataset(sosutils.download_sos_data_day(date, sos_download_dir, cache=True, planar_fit=PLANAR_FIT))\n",
    "    # Some dates are missing\n",
    "    except URLError:\n",
    "        print(f\"failed on {date}, skipping\")\n",
    "    datasets.append(ds[set(ds.data_vars).intersection(VARIABLE_NAMES)])\n",
    "sos_ds = sosutils.merge_datasets_with_different_variables(datasets, dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Potential Temperature, Surface Temperature, TKE\n",
    "\n",
    "Add new calculated variables to the dataset\n",
    "\n",
    "From EOL (https://www.eol.ucar.edu/content/calculation-long-wave-radiation)\n",
    "$$\n",
    "R_{lw} = R_{pile} + SB * T_{case}^4\n",
    "$$\n",
    "And the steven-boltzman law\n",
    "$$\n",
    "T_{surface} = \\Big( \\frac {R_{lw}}{ \\epsilon \\sigma } \\Big)^\\frac{1}{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential Temperature\n",
    "# iterate over pressure measurements\n",
    "for i in range(2,21):\n",
    "    height_adj_pressure = metpy.calc.add_height_to_pressure(\n",
    "        sos_ds['P_10m_c'] * units.millibar, \n",
    "        i*units.m - (10*units.m)\n",
    "    )\n",
    "    sos_ds[f'Tpot_{i}m_c'] = metpy.calc.potential_temperature(    \n",
    "        height_adj_pressure,\n",
    "        sos_ds[f'T_{i}m_c'] * units.celsius\n",
    "    ).pint.to(units.celsius)\n",
    "\n",
    "# Surface Temperature\n",
    "# calculate from apogees\n",
    "sos_ds['Tsurf_c'] = (['time'],  sosutils.apogee2temp(sos_ds, 'c').values)\n",
    "sos_ds['Tsurf_d'] = (['time'],  sosutils.apogee2temp(sos_ds, 'd').values)\n",
    "sos_ds['Tsurf_ue'] = (['time'],  sosutils.apogee2temp(sos_ds, 'ue').values)\n",
    "sos_ds['Tsurf_uw'] = (['time'],  sosutils.apogee2temp(sos_ds, 'uw').values)\n",
    "\n",
    "SB = 5.67e-08 # steven boltzman constant, W/m^2/degK^4\n",
    "SNOW_EMMISIVITY = 0.98\n",
    "sos_ds['Tsurf_rad_d'] = ((sos_ds['Rpile_out_9m_d'] + SB * (sos_ds['Tcase_out_9m_d']+273.15)**4)/(SNOW_EMMISIVITY*SB))**(1/4) - 273.15\n",
    "\n",
    "sos_ds['tke_2m_c'] = 0.5*(sos_ds['u_u__2m_c'] + sos_ds['v_v__2m_c'] + sos_ds['w_w__2m_c'])\n",
    "sos_ds['tke_3m_c'] = 0.5*(sos_ds['u_u__3m_c'] + sos_ds['v_v__3m_c'] + sos_ds['w_w__3m_c'])\n",
    "sos_ds['tke_5m_c'] = 0.5*(sos_ds['u_u__5m_c'] + sos_ds['v_v__5m_c'] + sos_ds['w_w__5m_c'])\n",
    "sos_ds['tke_10m_c'] = 0.5*(sos_ds['u_u__10m_c'] + sos_ds['v_v__10m_c'] + sos_ds['w_w__10m_c'])\n",
    "sos_ds['tke_15m_c'] = 0.5*(sos_ds['u_u__15m_c'] + sos_ds['v_v__15m_c'] + sos_ds['w_w__15m_c'])\n",
    "sos_ds['tke_20m_c'] = 0.5*(sos_ds['u_u__20m_c'] + sos_ds['v_v__20m_c'] + sos_ds['w_w__20m_c'])\n",
    "\n",
    "sos_ds['tke_1m_uw'] = 0.5*(sos_ds['u_u__1m_uw'] + sos_ds['v_v__1m_uw'] + sos_ds['w_w__1m_uw'])\n",
    "sos_ds['tke_3m_uw'] = 0.5*(sos_ds['u_u__3m_uw'] + sos_ds['v_v__3m_uw'] + sos_ds['w_w__3m_uw'])\n",
    "sos_ds['tke_10m_uw'] = 0.5*(sos_ds['u_u__10m_uw'] + sos_ds['v_v__10m_uw'] + sos_ds['w_w__10m_uw'])\n",
    "\n",
    "sos_ds['tke_1m_ue'] = 0.5*(sos_ds['u_u__1m_ue'] + sos_ds['v_v__1m_ue'] + sos_ds['w_w__1m_ue'])\n",
    "sos_ds['tke_3m_ue'] = 0.5*(sos_ds['u_u__3m_ue'] + sos_ds['v_v__3m_ue'] + sos_ds['w_w__3m_ue'])\n",
    "sos_ds['tke_10m_ue'] = 0.5*(sos_ds['u_u__10m_ue'] + sos_ds['v_v__10m_ue'] + sos_ds['w_w__10m_ue'])\n",
    "\n",
    "sos_ds['tke_1m_d'] = 0.5*(sos_ds['u_u__1m_d'] + sos_ds['v_v__1m_d'] + sos_ds['w_w__1m_d'])\n",
    "sos_ds['tke_3m_d'] = 0.5*(sos_ds['u_u__3m_d'] + sos_ds['v_v__3m_d'] + sos_ds['w_w__3m_d'])\n",
    "sos_ds['tke_10m_d'] = 0.5*(sos_ds['u_u__10m_d'] + sos_ds['v_v__10m_d'] + sos_ds['w_w__10m_d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth vertical latent heat flux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(3,2))\n",
    "sns.histplot(sos_ds['w_h2o__1m_uw'][np.abs(sos_ds['w_h2o__1m_uw']) < .01], stat='density')\n",
    "plt.xticks([-0.008, -0.004, 0, 0.004, 0.008], fontsize=8)\n",
    "plt.yticks([])\n",
    "plt.title(\"Latent heat flux measurements\\nat one sonic (1m, UW tower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad(data):\n",
    "    return np.mean(np.absolute(data - np.mean(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_ds['w_h2o__1m_uw'] = sos_ds['w_h2o__1m_uw'].where(np.absolute(sos_ds['w_h2o__1m_uw']) < 4*mad(sos_ds['w_h2o__1m_uw']))\n",
    "sos_ds['w_h2o__3m_uw'] = sos_ds['w_h2o__3m_uw'].where(np.absolute(sos_ds['w_h2o__3m_uw']) < 4*mad(sos_ds['w_h2o__3m_uw']))\n",
    "sos_ds['w_h2o__10m_uw'] = sos_ds['w_h2o__10m_uw'].where(np.absolute(sos_ds['w_h2o__10m_uw']) < 4*mad(sos_ds['w_h2o__10m_uw']))\n",
    "sos_ds['w_h2o__1m_ue'] = sos_ds['w_h2o__1m_ue'].where(np.absolute(sos_ds['w_h2o__1m_ue']) < 4*mad(sos_ds['w_h2o__1m_ue']))\n",
    "sos_ds['w_h2o__3m_ue'] = sos_ds['w_h2o__3m_ue'].where(np.absolute(sos_ds['w_h2o__3m_ue']) < 4*mad(sos_ds['w_h2o__3m_ue']))\n",
    "sos_ds['w_h2o__10m_ue'] = sos_ds['w_h2o__10m_ue'].where(np.absolute(sos_ds['w_h2o__10m_ue']) < 4*mad(sos_ds['w_h2o__10m_ue']))\n",
    "sos_ds['w_h2o__1m_d'] = sos_ds['w_h2o__1m_d'].where(np.absolute(sos_ds['w_h2o__1m_d']) < 4*mad(sos_ds['w_h2o__1m_d']))\n",
    "sos_ds['w_h2o__3m_d'] = sos_ds['w_h2o__3m_d'].where(np.absolute(sos_ds['w_h2o__3m_d']) < 4*mad(sos_ds['w_h2o__3m_d']))\n",
    "sos_ds['w_h2o__10m_d'] = sos_ds['w_h2o__10m_d'].where(np.absolute(sos_ds['w_h2o__10m_d']) < 4*mad(sos_ds['w_h2o__10m_d']))\n",
    "sos_ds['w_h2o__2m_c'] = sos_ds['w_h2o__2m_c'].where(np.absolute(sos_ds['w_h2o__2m_c']) < 4*mad(sos_ds['w_h2o__2m_c']))\n",
    "sos_ds['w_h2o__3m_c'] = sos_ds['w_h2o__3m_c'].where(np.absolute(sos_ds['w_h2o__3m_c']) < 4*mad(sos_ds['w_h2o__3m_c']))\n",
    "sos_ds['w_h2o__5m_c'] = sos_ds['w_h2o__5m_c'].where(np.absolute(sos_ds['w_h2o__5m_c']) < 4*mad(sos_ds['w_h2o__5m_c']))\n",
    "sos_ds['w_h2o__10m_c'] = sos_ds['w_h2o__10m_c'].where(np.absolute(sos_ds['w_h2o__10m_c']) < 4*mad(sos_ds['w_h2o__10m_c']))\n",
    "sos_ds['w_h2o__15m_c'] = sos_ds['w_h2o__15m_c'].where(np.absolute(sos_ds['w_h2o__15m_c']) < 4*mad(sos_ds['w_h2o__15m_c']))\n",
    "sos_ds['w_h2o__20m_c'] = sos_ds['w_h2o__20m_c'].where(np.absolute(sos_ds['w_h2o__20m_c']) < 4*mad(sos_ds['w_h2o__20m_c']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tidy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = sosutils.get_tidy_dataset(sos_ds, list(sos_ds.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = sosutils.modify_df_timezone(tidy_df, pytz.UTC, pytz.timezone('US/Mountain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df[tidy_df.measurement.apply(lambda x: x is None)].variable.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Ri and heat fluxes with turbpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOW_DEPTH = 0.9\n",
    "PRESSURE_HEIGHT = 10\n",
    "stab_titles, stab_methods, stab_dict = sosutils.get_turbpy_schemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df_30Min = pd.DataFrame(\n",
    "    tidy_df.set_index('time').groupby(\n",
    "        ['measurement', 'variable', 'height',  'tower']\n",
    "    )['value'].resample('30Min').mean()\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HELP\n",
    "Maybe its better to do these calculations with the original xarray dataset (like the calculations above). This would require that I explicitly declare all the variables used for modeled-flux calculations for each height/tower location which is probably better than the opaque things happening in sosutils.tidy_df_calculate_richardson_number_with_turbpy and sosutils.tidy_df_model_heat_fluxes_with_turbpy. Then I just need to come up with the new variable names and have those variable names parsed by the tidy_df functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tower in ['uw', 'ue', 'd', 'c']:\n",
    "    print(f\"Calculating modeled fluxes for tower {tower}\")\n",
    "    height_list = [2,3,5,10,20] if tower == 'c' else [1,3,10]\n",
    "    for height in height_list:\n",
    "        print(f\"for height {height}\")\n",
    "        print(\"calculating results\")\n",
    "        RiBulk = sosutils.tidy_df_calculate_richardson_number_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            tower = tower,\n",
    "            height = height,    \n",
    "            snowDepth = SNOW_DEPTH,\n",
    "            pressure_height = PRESSURE_HEIGHT\n",
    "        )\n",
    "\n",
    "        # run models and get results\n",
    "        (\n",
    "            stability_correction,\n",
    "            conductance_sensible,\n",
    "            conductance_latent,\n",
    "            sensible_heat,\n",
    "            latent_heat,\n",
    "            zeta\n",
    "        ) = sosutils.tidy_df_model_heat_fluxes_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            stab_titles, \n",
    "            stab_methods,\n",
    "            stab_dict,\n",
    "            tower, \n",
    "            height, \n",
    "            SNOW_DEPTH,\n",
    "            PRESSURE_HEIGHT\n",
    "        )\n",
    "\n",
    "        print(\"adding richardson number to dataset\")\n",
    "        # combine results into tidy_df and calculate:\n",
    "        # richardson number\n",
    "        tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "            tidy_df_30Min,\n",
    "            RiBulk,\n",
    "            f'Ri_{height}m_{tower}',\n",
    "            'Richardson Number',\n",
    "            height,\n",
    "            tower\n",
    "        )\n",
    "\n",
    "        print(\"adding modeled fluxes to dataset\")\n",
    "        # heat fluxes and the following calculations:\n",
    "        # *  vertical water vapor moisture flux (m/s * g/m^2) using the latent heat of sublimation\n",
    "        # Note that we use the opposite convention of turbpy - latent and sensible heat fluxes should be positive upward\n",
    "        # therefore there are negative signs below\n",
    "        for stab in stab_titles:\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab],\n",
    "                f'LH_modeled_{stab}_{height}m_{tower}',\n",
    "                f'latent heat flux modeled {stab}',\n",
    "                height,\n",
    "                tower,\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'w_h20_modeled_{stab}_{height}m_{tower}',\n",
    "                f'w_h2o_ modeled {stab}',\n",
    "                height,\n",
    "                tower,\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'SH_modeled_{stab}_{height}m_{tower}',\n",
    "                f'sensible heat flux modeled {stab}',\n",
    "                height,\n",
    "                tower,\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RI and modeled fluxes using the fancy radiometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get turby schemes\n",
    "stab_titles, stab_methods, stab_dict = sosutils.get_turbpy_schemes()\n",
    "\n",
    "SURFACE_TEMP_COL = 'Tsurf_rad_d'\n",
    "\n",
    "for tower in ['uw', 'ue', 'd', 'c']:\n",
    "#     print(f\"Calculating modeled fluxes for tower {tower}\")\n",
    "#     height_list = [2,3,5,10,20] if\n",
    "    print(f\"Calculating modeled fluxes for tower {tower}\")\n",
    "    height_list = [2,3,5,10,20] if tower == 'c' else [1,3,10]\n",
    "    for height in height_list:\n",
    "        print(f\"for height {height}\")\n",
    "        \n",
    "        RiBulk = sosutils.tidy_df_calculate_richardson_number_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            tower = tower,\n",
    "            height = height,\n",
    "            snowDepth = 1,\n",
    "            pressure_height = 10,\n",
    "            fillna_method = 'ffill',\n",
    "            surface_temp_col_substitute = SURFACE_TEMP_COL\n",
    "        )\n",
    "\n",
    "        tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "            tidy_df_30Min,\n",
    "            RiBulk,\n",
    "            f'Ri_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "            f'Richardson Number using {SURFACE_TEMP_COL}',\n",
    "            height,\n",
    "            tower\n",
    "        )\n",
    "\n",
    "\n",
    "        # run models and get results\n",
    "        (\n",
    "            stability_correction,\n",
    "            conductance_sensible,\n",
    "            conductance_latent,\n",
    "            sensible_heat,\n",
    "            latent_heat,\n",
    "            zeta\n",
    "        ) = sosutils.tidy_df_model_heat_fluxes_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            stab_titles, \n",
    "            stab_methods,\n",
    "            stab_dict,\n",
    "            tower, \n",
    "            height, \n",
    "            1,\n",
    "            10, \n",
    "            fillna_method='ffill',\n",
    "            surface_temp_col_substitute = SURFACE_TEMP_COL\n",
    "        )\n",
    "\n",
    "        # heat fluxes and the following calculations:\n",
    "        # *  vertical water vapor moisture flux (m/s * g/m^2) using the latent heat of sublimation\n",
    "        # Note that we use the opposite convention of turbpy - latent and sensible heat fluxes should be positive upward\n",
    "        # therefore there are negative signs below\n",
    "        for stab in stab_titles:\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab],\n",
    "                f'LH_modeled_{stab}_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "                f'latent heat flux modeled {stab} using {SURFACE_TEMP_COL}',\n",
    "                height,\n",
    "                tower\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'w_h20_modeled_{stab}_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "                f'w_h2o_ modeled {stab} using {SURFACE_TEMP_COL}',\n",
    "                height,\n",
    "                tower\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'SH_modeled_{stab}_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "                'sensible heat flux modeled {stab} using {SURFACE_TEMP_COL}',\n",
    "                height,\n",
    "                tower\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sublimation cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__2m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    2,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__3m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    3,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__5m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    5,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__10m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    10,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__20m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    20,\n",
    "    'c'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache downloaded and processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLANAR_FIT:\n",
    "    tidy_df_30Min.to_csv(f'tidy_df_30Min_{start_date}_{end_date}_planar_fit.csv', index=False)\n",
    "else:\n",
    "    tidy_df_30Min.to_csv(f'tidy_df_30Min_{start_date}_{end_date}_noplanar_fit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load disdrometer data and calculate \"days since precip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = act.discovery.download_data(\n",
    "    os.getenv(\"ARM_USERNAME\"),\n",
    "    os.getenv(\"ARM_TOKEN\"),\n",
    "    'gucldM1.b1',\n",
    "    start_date,\n",
    "    end_date,\n",
    "    output='/data2/elilouis/sublimationofsnow/gucldM1.b1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_ds = xr.open_mfdataset(files)\n",
    "disdro_df = disdro_ds.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df = disdro_df.set_index(\n",
    "    \"time\"\n",
    ")[['precip_rate']].resample(\n",
    "    \"1440Min\"\n",
    ").max().reset_index()\n",
    "\n",
    "disdro_daily_mean_precip_date_df = disdro_df.set_index(\n",
    "    \"time\"\n",
    ")[['precip_rate']].resample(\n",
    "    \"1440Min\"\n",
    ").max().reset_index()\n",
    "\n",
    "s = disdro_daily_max_precip_date_df.groupby(disdro_daily_max_precip_date_df['precip_rate'].ne(0).cumsum())['time'].transform('first')\n",
    "disdro_daily_max_precip_date_df['days_since_precip'] = (disdro_daily_max_precip_date_df['time'] - s).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_mean_precip_df = disdro_df.groupby(\"time\")['precip_rate'].max()\n",
    "\n",
    "daily_mean_precip_df = pd.DataFrame(daily_mean_precip_df.resample(\"1440Min\").mean()*24/10) # resample to one day in cm/hr SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df['daily_precip (cm)'] =  daily_mean_precip_df['precip_rate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Downloaded Disdrometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df.to_csv(\"disdro_daily_max_precip_date_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
