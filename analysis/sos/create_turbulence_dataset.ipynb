{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netcdf/numpy/xray/stats\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/elilouis/sublimationofsnow/\")\n",
    "import sosutils\n",
    "from metpy.units import units\n",
    "import metpy\n",
    "import pint_xarray\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "alt.renderers.enable('svg')\n",
    "import pytz\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from urllib.error import URLError\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_download_dir='/data2/elilouis/sublimationofsnow/sosnoqc'\n",
    "DATE_FORMAT_STR = '%Y%m%d'\n",
    "start_date = '20221201'; \n",
    "end_date = dt.datetime.strftime(dt.date.today() - dt.timedelta(days=1), DATE_FORMAT_STR)\n",
    "PLANAR_FIT = True\n",
    "\n",
    "# start_date = '20230219'\n",
    "end_date = '20230110'\n",
    "\n",
    "\n",
    "\n",
    "datelist = pd.date_range(\n",
    "    dt.datetime.strptime(start_date, DATE_FORMAT_STR),\n",
    "    dt.datetime.strptime(end_date, DATE_FORMAT_STR),\n",
    "    freq='d'\n",
    ").strftime(DATE_FORMAT_STR).tolist()\n",
    "\n",
    "VARIABLE_NAMES = [\n",
    "    # Sonic Anemometer Data for 4 towers\n",
    "    'tc_1m_uw',     'spd_1m_uw',     'dir_1m_uw',     'u_1m_uw',   'v_1m_uw',   'w_1m_uw',   'u_u__1m_uw',    'v_v__1m_uw',    'w_w__1m_uw',    \n",
    "        'u_w__1m_uw',    'v_w__1m_uw',  'u_tc__1m_uw',  'v_tc__1m_uw',   'u_h2o__1m_uw',  'v_h2o__1m_uw',   'w_tc__1m_uw',   'w_h2o__1m_uw',\n",
    "    'tc_3m_uw',     'spd_3m_uw',     'dir_3m_uw',     'u_3m_uw',   'v_3m_uw',   'w_3m_uw',   'u_u__3m_uw',    'v_v__3m_uw',    'w_w__3m_uw',    \n",
    "        'u_w__3m_uw',    'v_w__3m_uw',  'u_tc__3m_uw',  'v_tc__3m_uw',   'u_h2o__3m_uw',  'v_h2o__3m_uw',   'w_tc__3m_uw',   'w_h2o__3m_uw',\n",
    "    'tc_10m_uw',    'spd_10m_uw',    'dir_10m_uw',    'u_10m_uw',  'v_10m_uw',  'w_10m_uw',  'u_u__10m_uw',   'v_v__10m_uw',   'w_w__10m_uw',   \n",
    "        'u_w__10m_uw',   'v_w__10m_uw', 'u_tc__10m_uw', 'v_tc__10m_uw',  'u_h2o__10m_uw', 'v_h2o__10m_uw',  'w_tc__10m_uw',  'w_h2o__10m_uw',\n",
    "\n",
    "    'tc_1m_ue',     'spd_1m_ue',     'dir_1m_ue',     'u_1m_ue',   'v_1m_ue',   'w_1m_ue',   'u_u__1m_ue',    'v_v__1m_ue',    'w_w__1m_ue',    \n",
    "        'u_w__1m_ue',    'v_w__1m_ue',  'u_tc__1m_ue',  'v_tc__1m_ue',   'u_h2o__1m_ue',  'v_h2o__1m_ue',   'w_tc__1m_ue',   'w_h2o__1m_ue',\n",
    "    'tc_3m_ue',     'spd_3m_ue',     'dir_3m_ue',     'u_3m_ue',   'v_3m_ue',   'w_3m_ue',   'u_u__3m_ue',    'v_v__3m_ue',    'w_w__3m_ue',    \n",
    "        'u_w__3m_ue',    'v_w__3m_ue',  'u_tc__3m_ue',  'v_tc__3m_ue',   'u_h2o__3m_ue',  'v_h2o__3m_ue',   'w_tc__3m_ue',   'w_h2o__3m_ue',\n",
    "    'tc_10m_ue',    'spd_10m_ue',    'dir_10m_ue',    'u_10m_ue',  'v_10m_ue',  'w_10m_ue',  'u_u__10m_ue',   'v_v__10m_ue',   'w_w__10m_ue',   \n",
    "        'u_w__10m_ue',   'v_w__10m_ue', 'u_tc__10m_ue', 'v_tc__10m_ue',  'u_h2o__10m_ue', 'v_h2o__10m_ue',  'w_tc__10m_ue',  'w_h2o__10m_ue',\n",
    "\n",
    "    'tc_1m_d',      'spd_1m_d',     'dir_1m_d',     'u_1m_d',   'v_1m_d',   'w_1m_d',   'u_u__1m_d',    'v_v__1m_d',    'w_w__1m_d',    \n",
    "        'u_w__1m_d',    'v_w__1m_d',  'u_tc__1m_d',  'v_tc__1m_d',   'u_h2o__1m_d',  'v_h2o__1m_d',   'w_tc__1m_d',   'w_h2o__1m_d',\n",
    "    'tc_3m_d',      'spd_3m_d',     'dir_3m_d',     'u_3m_d',   'v_3m_d',   'w_3m_d',   'u_u__3m_d',    'v_v__3m_d',    'w_w__3m_d',    \n",
    "        'u_w__3m_d',    'v_w__3m_d',  'u_tc__3m_d',  'v_tc__3m_d',   'u_h2o__3m_d',  'v_h2o__3m_d',   'w_tc__3m_d',   'w_h2o__3m_d',\n",
    "    'tc_10m_d',     'spd_10m_d',    'dir_10m_d',    'u_10m_d',  'v_10m_d',  'w_10m_d',  'u_u__10m_d',   'v_v__10m_d',   'w_w__10m_d',   \n",
    "        'u_w__10m_d',   'v_w__10m_d', 'u_tc__10m_d', 'v_tc__10m_d',  'u_h2o__10m_d', 'v_h2o__10m_d',  'w_tc__10m_d',  'w_h2o__10m_d',\n",
    "\n",
    "    'tc_2m_c',  'spd_2m_c',     'dir_2m_c',     'u_2m_c',   'v_2m_c',   'w_2m_c',   'u_u__2m_c',    'v_v__2m_c',    'w_w__2m_c',    \n",
    "        'u_w__2m_c',    'v_w__2m_c',  'u_tc__2m_c',  'v_tc__2m_c',   'u_h2o__2m_c',  'v_h2o__2m_c',   'w_tc__2m_c',   'w_h2o__2m_c',\n",
    "    'tc_3m_c',  'spd_3m_c',     'dir_3m_c',     'u_3m_c',   'v_3m_c',   'w_3m_c',   'u_u__3m_c',    'v_v__3m_c',    'w_w__3m_c',    \n",
    "        'u_w__3m_c',    'v_w__3m_c',  'u_tc__3m_c',  'v_tc__3m_c',   'u_h2o__3m_c',  'v_h2o__3m_c',   'w_tc__3m_c',   'w_h2o__3m_c',\n",
    "    'tc_5m_c',  'spd_5m_c',     'dir_5m_c',     'u_5m_c',   'v_5m_c',   'w_5m_c',   'u_u__5m_c',    'v_v__5m_c',    'w_w__5m_c',    \n",
    "        'u_w__5m_c',    'v_w__5m_c',  'u_tc__5m_c',  'v_tc__5m_c',   'u_h2o__5m_c',  'v_h2o__5m_c',   'w_tc__5m_c',   'w_h2o__5m_c',\n",
    "    'tc_10m_c', 'spd_10m_c',    'dir_10m_c',    'u_10m_c',  'v_10m_c',  'w_10m_c',  'u_u__10m_c',   'v_v__10m_c',   'w_w__10m_c',   \n",
    "        'u_w__10m_c',   'v_w__10m_c', 'u_tc__10m_c', 'v_tc__10m_c',  'u_h2o__10m_c', 'v_h2o__10m_c',  'w_tc__10m_c',  'w_h2o__10m_c',\n",
    "    'tc_15m_c', 'spd_15m_c',    'dir_15m_c',    'u_15m_c',  'v_15m_c',  'w_15m_c',  'u_u__15m_c',   'v_v__15m_c',   'w_w__15m_c',   \n",
    "        'u_w__15m_c',   'v_w__15m_c', 'u_tc__15m_c', 'v_tc__15m_c',  'u_h2o__15m_c', 'v_h2o__15m_c',  'w_tc__15m_c',  'w_h2o__15m_c',\n",
    "    'tc_20m_c', 'spd_20m_c',    'dir_20m_c',    'u_20m_c',  'v_20m_c',  'w_20m_c',  'u_u__20m_c',   'v_v__20m_c',   'w_w__20m_c',   \n",
    "        'u_w__20m_c',   'v_w__20m_c', 'u_tc__20m_c', 'v_tc__20m_c',  'u_h2o__20m_c', 'v_h2o__20m_c',  'w_tc__20m_c',  'w_h2o__20m_c',\n",
    "\n",
    "    \n",
    "    # Temperature & Relative Humidity Array \n",
    "    'T_2m_c', 'T_3m_c', 'T_4m_c', 'T_5m_c', 'T_6m_c', 'T_7m_c', 'T_8m_c', 'T_9m_c', 'T_10m_c',\n",
    "    'T_11m_c', 'T_12m_c', 'T_13m_c', 'T_14m_c', 'T_15m_c', 'T_16m_c', 'T_17m_c', 'T_18m_c', 'T_19m_c', 'T_20m_c',\n",
    "\n",
    "    'RH_2m_c', 'RH_3m_c', 'RH_4m_c', 'RH_5m_c', 'RH_6m_c', 'RH_7m_c', 'RH_8m_c', 'RH_9m_c', 'RH_10m_c',\n",
    "    'RH_11m_c','RH_12m_c','RH_13m_c','RH_14m_c','RH_15m_c','RH_16m_c','RH_17m_c','RH_18m_c','RH_19m_c','RH_20m_c',\n",
    "\n",
    "    # Pressure Sensors\n",
    "    'P_20m_c',\n",
    "    'P_10m_c', 'P_10m_d', 'P_10m_uw', 'P_10m_ue',\n",
    "\n",
    "    # Blowing snow/FlowCapt Sensors\n",
    "    'SF_avg_1m_ue', 'SF_avg_2m_ue',\n",
    "\n",
    "    # Apogee sensors\n",
    "    \"Vtherm_c\", \"Vtherm_d\", \"Vtherm_ue\", \"Vtherm_uw\", \n",
    "    \"Vpile_c\", \"Vpile_d\", \"Vpile_ue\", \"Vpile_uw\",\n",
    "    \"IDir_c\", \"IDir_d\", \"IDir_ue\", \"IDir_uw\",\n",
    "\n",
    "    # Snow-level temperature arrays (towers D and UW)\n",
    "    'Tsnow_0_4m_d', 'Tsnow_0_5m_d', 'Tsnow_0_6m_d', 'Tsnow_0_7m_d', 'Tsnow_0_8m_d', 'Tsnow_0_9m_d', 'Tsnow_1_0m_d', 'Tsnow_1_1m_d', 'Tsnow_1_2m_d', 'Tsnow_1_3m_d', 'Tsnow_1_4m_d', 'Tsnow_1_5m_d',\n",
    "    'Tsnow_0_4m_uw', 'Tsnow_0_5m_uw', 'Tsnow_0_6m_uw', 'Tsnow_0_7m_uw', 'Tsnow_0_8m_uw', 'Tsnow_0_9m_uw', 'Tsnow_1_0m_uw', 'Tsnow_1_1m_uw', 'Tsnow_1_2m_uw', 'Tsnow_1_3m_uw', 'Tsnow_1_4m_uw', 'Tsnow_1_5m_uw',\n",
    "    \n",
    "    # Downward Facing Longwave Radiometer (tower D) - for measuring snow surface temperature\n",
    "    'Rpile_out_9m_d',\n",
    "    'Tcase_out_9m_d',\n",
    "    \n",
    "    # Upward facing shortwave radiometer (tower D) - for measuring incoming solar radiation!\n",
    "    'Rsw_in_9m_d',\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SoS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching...skipping download for 20221201\n",
      "failed on 20221202, skipping\n",
      "Caching...skipping download for 20221203\n",
      "Caching...skipping download for 20221204\n",
      "Caching...skipping download for 20221205\n",
      "Caching...skipping download for 20221206\n",
      "Caching...skipping download for 20221207\n",
      "Caching...skipping download for 20221208\n",
      "Caching...skipping download for 20221209\n",
      "Caching...skipping download for 20221210\n",
      "Caching...skipping download for 20221211\n",
      "Caching...skipping download for 20221212\n",
      "Caching...skipping download for 20221213\n",
      "Caching...skipping download for 20221214\n",
      "Caching...skipping download for 20221215\n",
      "Caching...skipping download for 20221216\n",
      "Caching...skipping download for 20221217\n",
      "Caching...skipping download for 20221218\n",
      "Caching...skipping download for 20221219\n",
      "Caching...skipping download for 20221220\n",
      "Caching...skipping download for 20221221\n",
      "Caching...skipping download for 20221222\n",
      "Caching...skipping download for 20221223\n",
      "Caching...skipping download for 20221224\n",
      "Caching...skipping download for 20221225\n",
      "Caching...skipping download for 20221226\n",
      "Caching...skipping download for 20221227\n",
      "Caching...skipping download for 20221228\n",
      "Caching...skipping download for 20221229\n",
      "Caching...skipping download for 20221230\n",
      "Caching...skipping download for 20221231\n",
      "Caching...skipping download for 20230101\n",
      "Caching...skipping download for 20230102\n",
      "Caching...skipping download for 20230103\n",
      "Caching...skipping download for 20230104\n",
      "Caching...skipping download for 20230105\n",
      "Caching...skipping download for 20230106\n",
      "Caching...skipping download for 20230107\n",
      "Caching...skipping download for 20230108\n",
      "Caching...skipping download for 20230109\n",
      "Caching...skipping download for 20230110\n"
     ]
    }
   ],
   "source": [
    "# We make sure that we aren't accessing variables that don't exist in the datasets\n",
    "# This is necessary because some daily NetCDF files don't have all the expected variables\n",
    "# (for example because an instrument was down). In that case, we want to add that variable\n",
    "# to the dataset, filled with nans, which sosutils.merge_datasets_with_different_variables\n",
    "# handles for us\n",
    "datasets = []\n",
    "datasets_safe = []\n",
    "for date in datelist:\n",
    "    try:\n",
    "        ds = xr.open_dataset(sosutils.download_sos_data_day(date, sos_download_dir, cache=True, planar_fit=PLANAR_FIT))\n",
    "    # Some dates are missing\n",
    "    except URLError:\n",
    "        print(f\"failed on {date}, skipping\")\n",
    "    ds_new = ds[set(ds.data_vars).intersection(VARIABLE_NAMES)]\n",
    "    datasets.append(ds_new)\n",
    "    datasets_safe.append(ds_new)\n",
    "sos_ds = sosutils.merge_datasets_with_different_variables(datasets, dim='time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill in missing timestamps (with nans)\n",
    "\n",
    "Note that this occurs if there is missing data at the beginning or end of day - those timestamps will be left out of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def date_range(start_date, end_date, increment, period):\n",
    "    result = []\n",
    "    nxt = start_date\n",
    "    delta = relativedelta(**{period:increment})\n",
    "    while nxt <= end_date:\n",
    "        result.append(nxt)\n",
    "        nxt += delta\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_list = date_range(pd.to_datetime(sos_ds.time.values[0]), pd.to_datetime(sos_ds.time.values[-1]), 5, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_ds = sos_ds.drop_duplicates(dim='time').reindex(time=dt_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate surface temperatures\n",
    "\n",
    "Add new calculated variables to the dataset\n",
    "\n",
    "From EOL (https://www.eol.ucar.edu/content/calculation-long-wave-radiation)\n",
    "$$\n",
    "R_{lw} = R_{pile} + SB * T_{case}^4\n",
    "$$\n",
    "And the steven-boltzman law\n",
    "$$\n",
    "T_{surface} = \\Big( \\frac {R_{lw}}{ \\epsilon \\sigma } \\Big)^\\frac{1}{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SB = 5.67e-08 # steven boltzman constant, W/m^2/degK^4\n",
    "SNOW_EMMISIVITY = 0.98\n",
    "sos_ds['Tsurf_rad_d'] = ((sos_ds['Rpile_out_9m_d'] + SB * (sos_ds['Tcase_out_9m_d']+273.15)**4)/(SNOW_EMMISIVITY*SB))**(1/4) - 273.15\n",
    "\n",
    "# Surface Temperature\n",
    "# calculate from apogees\n",
    "sos_ds['Tsurf_c'] = (['time'],  sosutils.apogee2temp(sos_ds, 'c').values)\n",
    "sos_ds['Tsurf_d'] = (['time'],  sosutils.apogee2temp(sos_ds, 'd').values)\n",
    "sos_ds['Tsurf_ue'] = (['time'],  sosutils.apogee2temp(sos_ds, 'ue').values)\n",
    "sos_ds['Tsurf_uw'] = (['time'],  sosutils.apogee2temp(sos_ds, 'uw').values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate potential and virtual potential temperatures in the air\n",
    "\n",
    "Note that we use the `metpy` library here, which assigns units to each dataarray, in a \"object oriented\" way using the `pint` library. You don't really have to worry about this, only to know that it can make working with the data more confusing. Know that at the end of the following cell, when we assign the new variables to the dataset, we remove any remnants of the `pint` library, and we assign an attribute `units` to each new variable so that they somewhat match the variables provided in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potential Temperature\n",
    "# iterate over pressure measurements\n",
    "for i in range(2,21):\n",
    "    absolute_temperature = sos_ds[f'T_{i}m_c'] * units.celsius\n",
    "    relative_humidity = sos_ds[f'RH_{i}m_c']\n",
    "    absolute_pressure = sos_ds['P_10m_c'] * units.millibar\n",
    "    height_relative_to_10m_pressure_sensor = i*units.m - (10*units.m)\n",
    "\n",
    "    height_adj_pressure = metpy.calc.add_height_to_pressure(\n",
    "        absolute_pressure, \n",
    "        height_relative_to_10m_pressure_sensor\n",
    "    )\n",
    "    potential_temperature = metpy.calc.potential_temperature(    \n",
    "            height_adj_pressure,\n",
    "            absolute_temperature\n",
    "    ).pint.to(units.celsius)\n",
    "    mixing_ratio = xr.DataArray(relative_humidity/100) * metpy.calc.saturation_mixing_ratio(\n",
    "        height_adj_pressure,\n",
    "        absolute_temperature\n",
    "    )\n",
    "    air_density = metpy.calc.density(height_adj_pressure, absolute_temperature, mixing_ratio)\n",
    "    virtual_potential_temperature = metpy.calc.virtual_temperature(\n",
    "        potential_temperature,\n",
    "        mixing_ratio,\n",
    "    )\n",
    "\n",
    "    virtual_temperature = metpy.calc.virtual_temperature(\n",
    "        absolute_temperature,\n",
    "        mixing_ratio,\n",
    "    )\n",
    "   \n",
    "    sos_ds[f'Tpot_{i}m_c'] = (['time'], potential_temperature.pint.magnitude)\n",
    "    sos_ds[f'Tpot_{i}m_c'] = sos_ds[f'Tpot_{i}m_c'].assign_attrs(units = str(potential_temperature.pint.units))\n",
    "\n",
    "    sos_ds[f'Tvirtual_{i}m_c'] = (['time'], virtual_temperature.pint.magnitude)\n",
    "    sos_ds[f'Tvirtual_{i}m_c'] = sos_ds[f'Tvirtual_{i}m_c'].assign_attrs(units = str(virtual_temperature.pint.units))\n",
    "\n",
    "    sos_ds[f'Tpotvirtual_{i}m_c'] = (['time'], virtual_potential_temperature.pint.magnitude)\n",
    "    sos_ds[f'Tpotvirtual_{i}m_c'] = sos_ds[f'Tpotvirtual_{i}m_c'].assign_attrs(units = str(virtual_potential_temperature.pint.units))\n",
    "\n",
    "    sos_ds[f'airdensity_{i}m_c'] = (['time'], air_density.pint.magnitude)\n",
    "    sos_ds[f'airdensity_{i}m_c'] = sos_ds[f'airdensity_{i}m_c'].assign_attrs(units = str(air_density.pint.units))\n",
    "\n",
    "    sos_ds[f'mixingratio_{i}m_c'] = (['time'], mixing_ratio.pint.magnitude)\n",
    "    sos_ds[f'mixingratio_{i}m_c'] = sos_ds[f'mixingratio_{i}m_c'].assign_attrs(units = str(mixing_ratio.pint.units))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate virtual potential temperatures at the snow surface\n",
    "\n",
    "These are pretty much the same calculations as above, except we use the snow surface temperature from the longwave radiometer instead of air temperature.\n",
    "\n",
    "Also, we assume that relative humidity at the snow surface is 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_relative_to_10m_pressure_sensor = - (10*units.m)\n",
    "absolute_temperature = sos_ds['Tsurf_rad_d']*units.celsius\n",
    "relative_humidity = 100\n",
    "\n",
    "potential_temperature = metpy.calc.potential_temperature(    \n",
    "    height_adj_pressure,\n",
    "    absolute_temperature\n",
    ").pint.to(units.celsius)\n",
    "\n",
    "mixing_ratio = xr.DataArray(relative_humidity/100) * metpy.calc.saturation_mixing_ratio(\n",
    "        height_adj_pressure,\n",
    "        absolute_temperature\n",
    "    )\n",
    "air_density = metpy.calc.density(height_adj_pressure, absolute_temperature, mixing_ratio)\n",
    "\n",
    "virtual_potential_temperature = metpy.calc.virtual_temperature(\n",
    "    potential_temperature,\n",
    "    mixing_ratio,\n",
    ")\n",
    "\n",
    "virtual_temperature = metpy.calc.virtual_temperature(\n",
    "    absolute_temperature,\n",
    "    mixing_ratio,\n",
    ")\n",
    "\n",
    "sos_ds[f'Tsurfvirtual_rad_c'] = (['time'], virtual_temperature.pint.magnitude)\n",
    "sos_ds[f'Tsurfvirtual_rad_c'] = sos_ds[f'Tsurfvirtual_rad_c'].assign_attrs(units = str(virtual_temperature.pint.units))\n",
    "\n",
    "sos_ds[f'Tsurfpotvirtual_rad_c'] = (['time'], virtual_potential_temperature.pint.magnitude)\n",
    "sos_ds[f'Tsurfpotvirtual_rad_c'] = sos_ds[f'Tsurfpotvirtual_rad_c'].assign_attrs(units = str(virtual_potential_temperature.pint.units))\n",
    "\n",
    "sos_ds[f'Tsurfairdensity_rad_c'] = (['time'], air_density.pint.magnitude)\n",
    "sos_ds[f'Tsurfairdensity_rad_c'] = sos_ds[f'Tsurfairdensity_rad_c'].assign_attrs(units = str(air_density.pint.units))\n",
    "\n",
    "sos_ds[f'Tsurfmixingratio_rad_c'] = (['time'], mixing_ratio.pint.magnitude)\n",
    "sos_ds[f'Tsurfmixingratio_rad_c'] = sos_ds[f'Tsurfmixingratio_rad_c'].assign_attrs(units = str(mixing_ratio.pint.units))\n",
    "\n",
    "sos_ds[f'Tsurfpot_rad_c'] = (['time'], potential_temperature.pint.magnitude)\n",
    "sos_ds[f'Tsurfpot_rad_c'] = sos_ds[f'Tsurfpot_rad_c'].assign_attrs(units = str(potential_temperature.pint.units))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate turbulent kinetic energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_ds['tke_2m_c'] = 0.5*(sos_ds['u_u__2m_c'] + sos_ds['v_v__2m_c'] + sos_ds['w_w__2m_c'])\n",
    "sos_ds['tke_3m_c'] = 0.5*(sos_ds['u_u__3m_c'] + sos_ds['v_v__3m_c'] + sos_ds['w_w__3m_c'])\n",
    "sos_ds['tke_5m_c'] = 0.5*(sos_ds['u_u__5m_c'] + sos_ds['v_v__5m_c'] + sos_ds['w_w__5m_c'])\n",
    "sos_ds['tke_10m_c'] = 0.5*(sos_ds['u_u__10m_c'] + sos_ds['v_v__10m_c'] + sos_ds['w_w__10m_c'])\n",
    "sos_ds['tke_15m_c'] = 0.5*(sos_ds['u_u__15m_c'] + sos_ds['v_v__15m_c'] + sos_ds['w_w__15m_c'])\n",
    "sos_ds['tke_20m_c'] = 0.5*(sos_ds['u_u__20m_c'] + sos_ds['v_v__20m_c'] + sos_ds['w_w__20m_c'])\n",
    "\n",
    "sos_ds['tke_1m_uw'] = 0.5*(sos_ds['u_u__1m_uw'] + sos_ds['v_v__1m_uw'] + sos_ds['w_w__1m_uw'])\n",
    "sos_ds['tke_3m_uw'] = 0.5*(sos_ds['u_u__3m_uw'] + sos_ds['v_v__3m_uw'] + sos_ds['w_w__3m_uw'])\n",
    "sos_ds['tke_10m_uw'] = 0.5*(sos_ds['u_u__10m_uw'] + sos_ds['v_v__10m_uw'] + sos_ds['w_w__10m_uw'])\n",
    "\n",
    "sos_ds['tke_1m_ue'] = 0.5*(sos_ds['u_u__1m_ue'] + sos_ds['v_v__1m_ue'] + sos_ds['w_w__1m_ue'])\n",
    "sos_ds['tke_3m_ue'] = 0.5*(sos_ds['u_u__3m_ue'] + sos_ds['v_v__3m_ue'] + sos_ds['w_w__3m_ue'])\n",
    "sos_ds['tke_10m_ue'] = 0.5*(sos_ds['u_u__10m_ue'] + sos_ds['v_v__10m_ue'] + sos_ds['w_w__10m_ue'])\n",
    "\n",
    "sos_ds['tke_1m_d'] = 0.5*(sos_ds['u_u__1m_d'] + sos_ds['v_v__1m_d'] + sos_ds['w_w__1m_d'])\n",
    "sos_ds['tke_3m_d'] = 0.5*(sos_ds['u_u__3m_d'] + sos_ds['v_v__3m_d'] + sos_ds['w_w__3m_d'])\n",
    "sos_ds['tke_10m_d'] = 0.5*(sos_ds['u_u__10m_d'] + sos_ds['v_v__10m_d'] + sos_ds['w_w__10m_d'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bouyancy term is the gradient in virtual potential temperature multiplied by gravity and divided by **absolute** virtual temperature. We calculate the gradient between the 2m sonic and the snow surface. Note that we use the **absolute** virtual temperature measured at the 2m instruments because this is a better estimate of average air temperature than the snow surface temperature (the temperature gradient is much steeper next to the snow surface than far from the snow surface). Also note that i've been bolding **absolute** virtual temperature because this value needs to be in units of Kelvin for this calculation.\n",
    "\n",
    "The flow shear term is the gradient in wind speed. We calculate it over the distance between the 2m sonic and the snow surface, where wind speed is 0. \n",
    "\n",
    "We know that measurements at 2m are not always 2m above the snow surface, but we just estimate for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_ds.to_netcdf(\"example_dataset.nc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth vertical latent heat flux data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,2))\n",
    "sns.histplot(sos_ds['w_h2o__1m_uw'][np.abs(sos_ds['w_h2o__1m_uw']) < .01], stat='density')\n",
    "plt.xticks([-0.008, -0.004, 0, 0.004, 0.008], fontsize=8)\n",
    "plt.yticks([])\n",
    "plt.title(\"Latent heat flux measurements\\nat one sonic (1m, UW tower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad(data):\n",
    "    return np.mean(np.absolute(data - np.mean(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_ds['w_h2o__1m_uw'] = sos_ds['w_h2o__1m_uw'].where(np.absolute(sos_ds['w_h2o__1m_uw']) < 4*mad(sos_ds['w_h2o__1m_uw']))\n",
    "sos_ds['w_h2o__3m_uw'] = sos_ds['w_h2o__3m_uw'].where(np.absolute(sos_ds['w_h2o__3m_uw']) < 4*mad(sos_ds['w_h2o__3m_uw']))\n",
    "sos_ds['w_h2o__10m_uw'] = sos_ds['w_h2o__10m_uw'].where(np.absolute(sos_ds['w_h2o__10m_uw']) < 4*mad(sos_ds['w_h2o__10m_uw']))\n",
    "sos_ds['w_h2o__1m_ue'] = sos_ds['w_h2o__1m_ue'].where(np.absolute(sos_ds['w_h2o__1m_ue']) < 4*mad(sos_ds['w_h2o__1m_ue']))\n",
    "sos_ds['w_h2o__3m_ue'] = sos_ds['w_h2o__3m_ue'].where(np.absolute(sos_ds['w_h2o__3m_ue']) < 4*mad(sos_ds['w_h2o__3m_ue']))\n",
    "sos_ds['w_h2o__10m_ue'] = sos_ds['w_h2o__10m_ue'].where(np.absolute(sos_ds['w_h2o__10m_ue']) < 4*mad(sos_ds['w_h2o__10m_ue']))\n",
    "sos_ds['w_h2o__1m_d'] = sos_ds['w_h2o__1m_d'].where(np.absolute(sos_ds['w_h2o__1m_d']) < 4*mad(sos_ds['w_h2o__1m_d']))\n",
    "sos_ds['w_h2o__3m_d'] = sos_ds['w_h2o__3m_d'].where(np.absolute(sos_ds['w_h2o__3m_d']) < 4*mad(sos_ds['w_h2o__3m_d']))\n",
    "sos_ds['w_h2o__10m_d'] = sos_ds['w_h2o__10m_d'].where(np.absolute(sos_ds['w_h2o__10m_d']) < 4*mad(sos_ds['w_h2o__10m_d']))\n",
    "sos_ds['w_h2o__2m_c'] = sos_ds['w_h2o__2m_c'].where(np.absolute(sos_ds['w_h2o__2m_c']) < 4*mad(sos_ds['w_h2o__2m_c']))\n",
    "sos_ds['w_h2o__3m_c'] = sos_ds['w_h2o__3m_c'].where(np.absolute(sos_ds['w_h2o__3m_c']) < 4*mad(sos_ds['w_h2o__3m_c']))\n",
    "sos_ds['w_h2o__5m_c'] = sos_ds['w_h2o__5m_c'].where(np.absolute(sos_ds['w_h2o__5m_c']) < 4*mad(sos_ds['w_h2o__5m_c']))\n",
    "sos_ds['w_h2o__10m_c'] = sos_ds['w_h2o__10m_c'].where(np.absolute(sos_ds['w_h2o__10m_c']) < 4*mad(sos_ds['w_h2o__10m_c']))\n",
    "sos_ds['w_h2o__15m_c'] = sos_ds['w_h2o__15m_c'].where(np.absolute(sos_ds['w_h2o__15m_c']) < 4*mad(sos_ds['w_h2o__15m_c']))\n",
    "sos_ds['w_h2o__20m_c'] = sos_ds['w_h2o__20m_c'].where(np.absolute(sos_ds['w_h2o__20m_c']) < 4*mad(sos_ds['w_h2o__20m_c']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tidy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = sosutils.get_tidy_dataset(sos_ds, list(sos_ds.data_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df = sosutils.modify_df_timezone(tidy_df, pytz.UTC, pytz.timezone('US/Mountain'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df[tidy_df.measurement.apply(lambda x: x is None)].variable.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Ri and heat fluxes with turbpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOW_DEPTH = 0.9\n",
    "PRESSURE_HEIGHT = 10\n",
    "stab_titles, stab_methods, stab_dict = sosutils.get_turbpy_schemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df_30Min = pd.DataFrame(\n",
    "    tidy_df.set_index('time').groupby(\n",
    "        ['measurement', 'variable', 'height',  'tower']\n",
    "    )['value'].resample('30Min').mean()\n",
    ").reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HELP\n",
    "Maybe its better to do these calculations with the original xarray dataset (like the calculations above). This would require that I explicitly declare all the variables used for modeled-flux calculations for each height/tower location which is probably better than the opaque things happening in sosutils.tidy_df_calculate_richardson_number_with_turbpy and sosutils.tidy_df_model_heat_fluxes_with_turbpy. Then I just need to come up with the new variable names and have those variable names parsed by the tidy_df functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tower in ['uw', 'ue', 'd', 'c']:\n",
    "    print(f\"Calculating modeled fluxes for tower {tower}\")\n",
    "    height_list = [2,3,5,10,20] if tower == 'c' else [1,3,10]\n",
    "    for height in height_list:\n",
    "        print(f\"for height {height}\")\n",
    "        print(\"calculating results\")\n",
    "        RiBulk = sosutils.tidy_df_calculate_richardson_number_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            tower = tower,\n",
    "            height = height,    \n",
    "            snowDepth = SNOW_DEPTH,\n",
    "            pressure_height = PRESSURE_HEIGHT\n",
    "        )\n",
    "\n",
    "        # run models and get results\n",
    "        (\n",
    "            stability_correction,\n",
    "            conductance_sensible,\n",
    "            conductance_latent,\n",
    "            sensible_heat,\n",
    "            latent_heat,\n",
    "            zeta\n",
    "        ) = sosutils.tidy_df_model_heat_fluxes_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            stab_titles, \n",
    "            stab_methods,\n",
    "            stab_dict,\n",
    "            tower, \n",
    "            height, \n",
    "            SNOW_DEPTH,\n",
    "            PRESSURE_HEIGHT\n",
    "        )\n",
    "\n",
    "        print(\"adding richardson number to dataset\")\n",
    "        # combine results into tidy_df and calculate:\n",
    "        # richardson number\n",
    "        tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "            tidy_df_30Min,\n",
    "            RiBulk,\n",
    "            f'Ri_{height}m_{tower}',\n",
    "            'Richardson Number',\n",
    "            height,\n",
    "            tower\n",
    "        )\n",
    "\n",
    "        print(\"adding modeled fluxes to dataset\")\n",
    "        # heat fluxes and the following calculations:\n",
    "        # *  vertical water vapor moisture flux (m/s * g/m^2) using the latent heat of sublimation\n",
    "        # Note that we use the opposite convention of turbpy - latent and sensible heat fluxes should be positive upward\n",
    "        # therefore there are negative signs below\n",
    "        for stab in stab_titles:\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab],\n",
    "                f'LH_modeled_{stab}_{height}m_{tower}',\n",
    "                f'latent heat flux modeled {stab}',\n",
    "                height,\n",
    "                tower,\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'w_h20_modeled_{stab}_{height}m_{tower}',\n",
    "                f'w_h2o_ modeled {stab}',\n",
    "                height,\n",
    "                tower,\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'SH_modeled_{stab}_{height}m_{tower}',\n",
    "                f'sensible heat flux modeled {stab}',\n",
    "                height,\n",
    "                tower,\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate RI and modeled fluxes using the fancy radiometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get turby schemes\n",
    "stab_titles, stab_methods, stab_dict = sosutils.get_turbpy_schemes()\n",
    "\n",
    "SURFACE_TEMP_COL = 'Tsurf_rad_d'\n",
    "\n",
    "for tower in ['uw', 'ue', 'd', 'c']:\n",
    "#     print(f\"Calculating modeled fluxes for tower {tower}\")\n",
    "#     height_list = [2,3,5,10,20] if\n",
    "    print(f\"Calculating modeled fluxes for tower {tower}\")\n",
    "    height_list = [2,3,5,10,20] if tower == 'c' else [1,3,10]\n",
    "    for height in height_list:\n",
    "        print(f\"for height {height}\")\n",
    "        \n",
    "        RiBulk = sosutils.tidy_df_calculate_richardson_number_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            tower = tower,\n",
    "            height = height,\n",
    "            snowDepth = 1,\n",
    "            pressure_height = 10,\n",
    "            fillna_method = 'ffill',\n",
    "            surface_temp_col_substitute = SURFACE_TEMP_COL\n",
    "        )\n",
    "\n",
    "        tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "            tidy_df_30Min,\n",
    "            RiBulk,\n",
    "            f'Ri_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "            f'Richardson Number using {SURFACE_TEMP_COL}',\n",
    "            height,\n",
    "            tower\n",
    "        )\n",
    "\n",
    "\n",
    "        # run models and get results\n",
    "        (\n",
    "            stability_correction,\n",
    "            conductance_sensible,\n",
    "            conductance_latent,\n",
    "            sensible_heat,\n",
    "            latent_heat,\n",
    "            zeta\n",
    "        ) = sosutils.tidy_df_model_heat_fluxes_with_turbpy(\n",
    "            tidy_df_30Min,\n",
    "            stab_titles, \n",
    "            stab_methods,\n",
    "            stab_dict,\n",
    "            tower, \n",
    "            height, \n",
    "            1,\n",
    "            10, \n",
    "            fillna_method='ffill',\n",
    "            surface_temp_col_substitute = SURFACE_TEMP_COL\n",
    "        )\n",
    "\n",
    "        # heat fluxes and the following calculations:\n",
    "        # *  vertical water vapor moisture flux (m/s * g/m^2) using the latent heat of sublimation\n",
    "        # Note that we use the opposite convention of turbpy - latent and sensible heat fluxes should be positive upward\n",
    "        # therefore there are negative signs below\n",
    "        for stab in stab_titles:\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab],\n",
    "                f'LH_modeled_{stab}_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "                f'latent heat flux modeled {stab} using {SURFACE_TEMP_COL}',\n",
    "                height,\n",
    "                tower\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'w_h20_modeled_{stab}_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "                f'w_h2o_ modeled {stab} using {SURFACE_TEMP_COL}',\n",
    "                height,\n",
    "                tower\n",
    "            )\n",
    "            tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "                tidy_df_30Min,\n",
    "                - latent_heat[stab]/(2838),\n",
    "                f'SH_modeled_{stab}_{height}m_{tower}_{SURFACE_TEMP_COL}',\n",
    "                'sensible heat flux modeled {stab} using {SURFACE_TEMP_COL}',\n",
    "                height,\n",
    "                tower\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sublimation cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__2m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    2,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__3m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    3,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__5m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    5,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__10m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    10,\n",
    "    'c'\n",
    ")\n",
    "\n",
    "tidy_df_30Min = sosutils.tidy_df_add_variable(\n",
    "    tidy_df_30Min,\n",
    "    np.cumsum(tidy_df_30Min.query(\"variable == 'w_h2o__20m_c'\")['value']*60*30).values*1000/(1e6),\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    \"cumulative sublimation (mm)\",\n",
    "    20,\n",
    "    'c'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache downloaded and processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLANAR_FIT:\n",
    "    tidy_df_30Min.to_csv(f'tidy_df_30Min_{start_date}_{end_date}_planar_fit.csv', index=False)\n",
    "else:\n",
    "    tidy_df_30Min.to_csv(f'tidy_df_30Min_{start_date}_{end_date}_noplanar_fit.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load disdrometer data and calculate \"days since precip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = act.discovery.download_data(\n",
    "    os.getenv(\"ARM_USERNAME\"),\n",
    "    os.getenv(\"ARM_TOKEN\"),\n",
    "    'gucldM1.b1',\n",
    "    start_date,\n",
    "    end_date,\n",
    "    output='/data2/elilouis/sublimationofsnow/gucldM1.b1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_ds = xr.open_mfdataset(files)\n",
    "disdro_df = disdro_ds.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df = disdro_df.set_index(\n",
    "    \"time\"\n",
    ")[['precip_rate']].resample(\n",
    "    \"1440Min\"\n",
    ").max().reset_index()\n",
    "\n",
    "disdro_daily_mean_precip_date_df = disdro_df.set_index(\n",
    "    \"time\"\n",
    ")[['precip_rate']].resample(\n",
    "    \"1440Min\"\n",
    ").max().reset_index()\n",
    "\n",
    "s = disdro_daily_max_precip_date_df.groupby(disdro_daily_max_precip_date_df['precip_rate'].ne(0).cumsum())['time'].transform('first')\n",
    "disdro_daily_max_precip_date_df['days_since_precip'] = (disdro_daily_max_precip_date_df['time'] - s).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_mean_precip_df = disdro_df.groupby(\"time\")['precip_rate'].max()\n",
    "\n",
    "daily_mean_precip_df = pd.DataFrame(daily_mean_precip_df.resample(\"1440Min\").mean()*24/10) # resample to one day in cm/hr SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df['daily_precip (cm)'] =  daily_mean_precip_df['precip_rate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Downloaded Disdrometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdro_daily_max_precip_date_df.to_csv(\"disdro_daily_max_precip_date_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
